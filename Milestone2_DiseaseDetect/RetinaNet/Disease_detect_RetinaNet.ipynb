{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitvikPrabhu/AutoCBC/blob/master/Milestone2_DiseaseDetect/RetinaNet/Disease_detect_RetinaNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**HemeAI: Disease Detect**\n",
        "\n",
        "## The following notebook attempts to identify diseases using RetinaNet\n",
        "\n",
        "###Author: Ritvik Prabhu"
      ],
      "metadata": {
        "id": "fcxQycVS_mPR"
      },
      "id": "fcxQycVS_mPR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let us import a tool that can clear extremely verbose outputs"
      ],
      "metadata": {
        "id": "BrmcRdiehLZh"
      },
      "id": "BrmcRdiehLZh"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output \n"
      ],
      "metadata": {
        "id": "gIMRVR3whKRJ"
      },
      "id": "gIMRVR3whKRJ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will clone our repository. The repository will contain the model files, annotated dataset and setup.py which are all necessary to train the model used for the first milestone of the project."
      ],
      "metadata": {
        "id": "N5xDXFsf__vy"
      },
      "id": "N5xDXFsf__vy"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "94940081",
      "metadata": {
        "id": "94940081"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/RitvikPrabhu/AutoCBC.git\n",
        "%cd AutoCBC\n",
        "!apt-get install tk-dev python-tk\n",
        "!pip install -r requirements.txt\n",
        "%cd Milestone2_DiseaseDetect/RetinaNet\n",
        "!git clone https://github.com/yhenon/pytorch-retinanet.git\n",
        "!pip install pandas\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python\n",
        "!pip install requests\n",
        "!pip install torch==1.13\n",
        "!pip install torchvision==0.14.1\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below will allows us to reset our directory without having to shutdown the entire runtime"
      ],
      "metadata": {
        "id": "m3vrLpY8BPJ9"
      },
      "id": "m3vrLpY8BPJ9"
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf AutoCBC/"
      ],
      "metadata": {
        "id": "PPHlYmbymxU4"
      },
      "id": "PPHlYmbymxU4",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain the Dataset (from Roboflow)"
      ],
      "metadata": {
        "id": "TGbjTBS-gVJh"
      },
      "id": "TGbjTBS-gVJh"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"k7t7R1s1qjS9eojgbD50\")\n",
        "project = rf.workspace().project(\"disease-detection-z1mqc\")\n",
        "dataset = project.version(3).download(\"retinanet\")\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "SVtM8fUHfyT2"
      },
      "id": "SVtM8fUHfyT2",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete empty lines in csv files"
      ],
      "metadata": {
        "id": "zinoQzNwJp5s"
      },
      "id": "zinoQzNwJp5s"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "#For train\n",
        "with open('Disease-Detection-3/train/_annotations.csv', 'r', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    rows = [row for row in reader if any(field.strip() for field in row)]\n",
        "\n",
        "with open('Disease-Detection-3/train/_annotations.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(rows)\n",
        "\n",
        "#For valid\n",
        "with open('Disease-Detection-3/valid/_annotations.csv', 'r', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    rows = [row for row in reader if any(field.strip() for field in row)]\n",
        "\n",
        "with open('Disease-Detection-3/valid/_annotations.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "id": "s8KKNmPeJspB"
      },
      "id": "s8KKNmPeJspB",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the coordinates in the annotations are rounded to the nearest integer"
      ],
      "metadata": {
        "id": "-VaLx0r8IRnI"
      },
      "id": "-VaLx0r8IRnI"
    },
    {
      "cell_type": "code",
      "source": [
        "#For train data\n",
        "with open('Disease-Detection-3/train/_annotations.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
        "    rows = []\n",
        "    for row in reader:\n",
        "        # Convert columns 2-5 to integers\n",
        "        row[1:5] = map(int, row[1:5])\n",
        "        rows.append(row)\n",
        "\n",
        "# Write back to the CSV file\n",
        "with open('Disease-Detection-3/train/_annotations.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    writer.writerows(rows)\n",
        "\n",
        "#For validation data\n",
        "with open('Disease-Detection-3/valid/_annotations.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
        "    rows = []\n",
        "    for row in reader:\n",
        "        # Convert columns 2-5 to integers\n",
        "        row[1:5] = map(int, row[1:5])\n",
        "        rows.append(row)\n",
        "\n",
        "# Write back to the CSV file\n",
        "with open('Disease-Detection-3/valid/_annotations.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "id": "sThAEN-mIRBV"
      },
      "id": "sThAEN-mIRBV",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the framework found here (https://github.com/yhenon/pytorch-retinanet)"
      ],
      "metadata": {
        "id": "WIEYOXSDFjw0"
      },
      "id": "WIEYOXSDFjw0"
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Disease-Detection-3/train/*.jpg pytorch-retinanet/\n",
        "!mv Disease-Detection-3/valid/*.jpg pytorch-retinanet/\n",
        "%cd pytorch-retinanet/\n",
        "!python train.py --dataset csv --csv_train ../Disease-Detection-3/train/_annotations.csv  --csv_classes ../class_list.csv  --csv_val ../Disease-Detection-3/valid/_annotations.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3taxT0HCibb",
        "outputId": "50e74dca-bf75-46cf-ea1a-9d1584d556b3"
      },
      "id": "R3taxT0HCibb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 44 | Iteration: 115 | Classification loss: 0.00026 | Regression loss: 0.00661 | Running loss: 0.01002\n",
            "Epoch: 44 | Iteration: 116 | Classification loss: 0.00006 | Regression loss: 0.00318 | Running loss: 0.01002\n",
            "Epoch: 44 | Iteration: 117 | Classification loss: 0.00014 | Regression loss: 0.01235 | Running loss: 0.01004\n",
            "Epoch: 44 | Iteration: 118 | Classification loss: 0.00006 | Regression loss: 0.00614 | Running loss: 0.00999\n",
            "Epoch: 44 | Iteration: 119 | Classification loss: 0.00096 | Regression loss: 0.01881 | Running loss: 0.01002\n",
            "Epoch: 44 | Iteration: 120 | Classification loss: 0.00017 | Regression loss: 0.01286 | Running loss: 0.01004\n",
            "Epoch: 44 | Iteration: 121 | Classification loss: 0.00145 | Regression loss: 0.02148 | Running loss: 0.01007\n",
            "Epoch: 44 | Iteration: 122 | Classification loss: 0.00010 | Regression loss: 0.00316 | Running loss: 0.01007\n",
            "Epoch: 44 | Iteration: 123 | Classification loss: 0.00007 | Regression loss: 0.01370 | Running loss: 0.01006\n",
            "Epoch: 44 | Iteration: 124 | Classification loss: 0.00028 | Regression loss: 0.00411 | Running loss: 0.01005\n",
            "Epoch: 44 | Iteration: 125 | Classification loss: 0.00015 | Regression loss: 0.00469 | Running loss: 0.00991\n",
            "Epoch: 44 | Iteration: 126 | Classification loss: 0.00004 | Regression loss: 0.00447 | Running loss: 0.00989\n",
            "Epoch: 44 | Iteration: 127 | Classification loss: 0.00004 | Regression loss: 0.00521 | Running loss: 0.00987\n",
            "Epoch: 44 | Iteration: 128 | Classification loss: 0.00014 | Regression loss: 0.00410 | Running loss: 0.00986\n",
            "Epoch: 44 | Iteration: 129 | Classification loss: 0.00005 | Regression loss: 0.00558 | Running loss: 0.00985\n",
            "Epoch: 44 | Iteration: 130 | Classification loss: 0.00510 | Regression loss: 0.06095 | Running loss: 0.00994\n",
            "Epoch: 44 | Iteration: 131 | Classification loss: 0.00007 | Regression loss: 0.00490 | Running loss: 0.00994\n",
            "Epoch: 44 | Iteration: 132 | Classification loss: 0.00021 | Regression loss: 0.00272 | Running loss: 0.00994\n",
            "Epoch: 44 | Iteration: 133 | Classification loss: 0.00025 | Regression loss: 0.02873 | Running loss: 0.00997\n",
            "Epoch: 44 | Iteration: 134 | Classification loss: 0.00010 | Regression loss: 0.00524 | Running loss: 0.00996\n",
            "Epoch: 44 | Iteration: 135 | Classification loss: 0.00020 | Regression loss: 0.00655 | Running loss: 0.00996\n",
            "Epoch: 44 | Iteration: 136 | Classification loss: 0.00012 | Regression loss: 0.00377 | Running loss: 0.00992\n",
            "Epoch: 44 | Iteration: 137 | Classification loss: 0.00007 | Regression loss: 0.00343 | Running loss: 0.00985\n",
            "Epoch: 44 | Iteration: 138 | Classification loss: 0.00032 | Regression loss: 0.00814 | Running loss: 0.00986\n",
            "Epoch: 44 | Iteration: 139 | Classification loss: 0.00003 | Regression loss: 0.00286 | Running loss: 0.00985\n",
            "Epoch: 44 | Iteration: 140 | Classification loss: 0.00017 | Regression loss: 0.00954 | Running loss: 0.00984\n",
            "Epoch: 44 | Iteration: 141 | Classification loss: 0.00008 | Regression loss: 0.00658 | Running loss: 0.00984\n",
            "Epoch: 44 | Iteration: 142 | Classification loss: 0.00012 | Regression loss: 0.00805 | Running loss: 0.00985\n",
            "Epoch: 44 | Iteration: 143 | Classification loss: 0.00017 | Regression loss: 0.00693 | Running loss: 0.00985\n",
            "Epoch: 44 | Iteration: 144 | Classification loss: 0.00005 | Regression loss: 0.00310 | Running loss: 0.00985\n",
            "Epoch: 44 | Iteration: 145 | Classification loss: 0.00008 | Regression loss: 0.00352 | Running loss: 0.00979\n",
            "Epoch: 44 | Iteration: 146 | Classification loss: 0.00049 | Regression loss: 0.00648 | Running loss: 0.00979\n",
            "Epoch: 44 | Iteration: 147 | Classification loss: 0.00040 | Regression loss: 0.00704 | Running loss: 0.00979\n",
            "Epoch: 44 | Iteration: 148 | Classification loss: 0.00014 | Regression loss: 0.00708 | Running loss: 0.00979\n",
            "Epoch: 44 | Iteration: 149 | Classification loss: 0.00010 | Regression loss: 0.00775 | Running loss: 0.00976\n",
            "Epoch: 44 | Iteration: 150 | Classification loss: 0.00006 | Regression loss: 0.00460 | Running loss: 0.00975\n",
            "Epoch: 44 | Iteration: 151 | Classification loss: 0.00008 | Regression loss: 0.00886 | Running loss: 0.00975\n",
            "Epoch: 44 | Iteration: 152 | Classification loss: 0.00023 | Regression loss: 0.00525 | Running loss: 0.00975\n",
            "Epoch: 44 | Iteration: 153 | Classification loss: 0.00003 | Regression loss: 0.00505 | Running loss: 0.00976\n",
            "Epoch: 44 | Iteration: 154 | Classification loss: 0.00013 | Regression loss: 0.00550 | Running loss: 0.00974\n",
            "Epoch: 44 | Iteration: 155 | Classification loss: 0.00015 | Regression loss: 0.00668 | Running loss: 0.00972\n",
            "Epoch: 44 | Iteration: 156 | Classification loss: 0.00026 | Regression loss: 0.00619 | Running loss: 0.00971\n",
            "Epoch: 44 | Iteration: 157 | Classification loss: 0.00002 | Regression loss: 0.00258 | Running loss: 0.00971\n",
            "Epoch: 44 | Iteration: 158 | Classification loss: 0.00010 | Regression loss: 0.00552 | Running loss: 0.00971\n",
            "Epoch: 44 | Iteration: 159 | Classification loss: 0.00019 | Regression loss: 0.00581 | Running loss: 0.00971\n",
            "Epoch: 44 | Iteration: 160 | Classification loss: 0.00013 | Regression loss: 0.00653 | Running loss: 0.00971\n",
            "Epoch: 44 | Iteration: 161 | Classification loss: 0.00059 | Regression loss: 0.00465 | Running loss: 0.00965\n",
            "Epoch: 44 | Iteration: 162 | Classification loss: 0.00003 | Regression loss: 0.01219 | Running loss: 0.00955\n",
            "Epoch: 44 | Iteration: 163 | Classification loss: 0.00008 | Regression loss: 0.00621 | Running loss: 0.00955\n",
            "Epoch: 44 | Iteration: 164 | Classification loss: 0.00041 | Regression loss: 0.00608 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 165 | Classification loss: 0.00018 | Regression loss: 0.00278 | Running loss: 0.00948\n",
            "Epoch: 44 | Iteration: 166 | Classification loss: 0.00013 | Regression loss: 0.00656 | Running loss: 0.00948\n",
            "Epoch: 44 | Iteration: 167 | Classification loss: 0.00007 | Regression loss: 0.03205 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 168 | Classification loss: 0.00015 | Regression loss: 0.00563 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 169 | Classification loss: 0.00031 | Regression loss: 0.00559 | Running loss: 0.00944\n",
            "Epoch: 44 | Iteration: 170 | Classification loss: 0.00005 | Regression loss: 0.00550 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 171 | Classification loss: 0.00002 | Regression loss: 0.00405 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 172 | Classification loss: 0.00011 | Regression loss: 0.00724 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 173 | Classification loss: 0.00002 | Regression loss: 0.00450 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 174 | Classification loss: 0.00034 | Regression loss: 0.00834 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 175 | Classification loss: 0.00065 | Regression loss: 0.00747 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 176 | Classification loss: 0.00007 | Regression loss: 0.00454 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 177 | Classification loss: 0.00002 | Regression loss: 0.00305 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 178 | Classification loss: 0.00002 | Regression loss: 0.00184 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 179 | Classification loss: 0.00038 | Regression loss: 0.01140 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 180 | Classification loss: 0.00027 | Regression loss: 0.00902 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 181 | Classification loss: 0.00010 | Regression loss: 0.00445 | Running loss: 0.00939\n",
            "Epoch: 44 | Iteration: 182 | Classification loss: 0.00010 | Regression loss: 0.00405 | Running loss: 0.00939\n",
            "Epoch: 44 | Iteration: 183 | Classification loss: 0.00026 | Regression loss: 0.02092 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 184 | Classification loss: 0.00018 | Regression loss: 0.00384 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 185 | Classification loss: 0.00131 | Regression loss: 0.01149 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 186 | Classification loss: 0.00096 | Regression loss: 0.01229 | Running loss: 0.00944\n",
            "Epoch: 44 | Iteration: 187 | Classification loss: 0.00044 | Regression loss: 0.01745 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 188 | Classification loss: 0.00014 | Regression loss: 0.00432 | Running loss: 0.00944\n",
            "Epoch: 44 | Iteration: 189 | Classification loss: 0.00037 | Regression loss: 0.01512 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 190 | Classification loss: 0.00182 | Regression loss: 0.01158 | Running loss: 0.00948\n",
            "Epoch: 44 | Iteration: 191 | Classification loss: 0.00004 | Regression loss: 0.00299 | Running loss: 0.00948\n",
            "Epoch: 44 | Iteration: 192 | Classification loss: 0.00013 | Regression loss: 0.00546 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 193 | Classification loss: 0.00020 | Regression loss: 0.00387 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 194 | Classification loss: 0.00006 | Regression loss: 0.00383 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 195 | Classification loss: 0.00019 | Regression loss: 0.00808 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 196 | Classification loss: 0.00004 | Regression loss: 0.00326 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 197 | Classification loss: 0.00067 | Regression loss: 0.01230 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 198 | Classification loss: 0.00006 | Regression loss: 0.00656 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 199 | Classification loss: 0.00017 | Regression loss: 0.01706 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 200 | Classification loss: 0.00009 | Regression loss: 0.00163 | Running loss: 0.00939\n",
            "Epoch: 44 | Iteration: 201 | Classification loss: 0.00013 | Regression loss: 0.00729 | Running loss: 0.00939\n",
            "Epoch: 44 | Iteration: 202 | Classification loss: 0.00009 | Regression loss: 0.00356 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 203 | Classification loss: 0.00011 | Regression loss: 0.00520 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 204 | Classification loss: 0.00022 | Regression loss: 0.01383 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 205 | Classification loss: 0.00025 | Regression loss: 0.00287 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 206 | Classification loss: 0.00112 | Regression loss: 0.01102 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 207 | Classification loss: 0.00018 | Regression loss: 0.00417 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 208 | Classification loss: 0.00011 | Regression loss: 0.00723 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 209 | Classification loss: 0.00077 | Regression loss: 0.02926 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 210 | Classification loss: 0.00043 | Regression loss: 0.01526 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 211 | Classification loss: 0.00017 | Regression loss: 0.00399 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 212 | Classification loss: 0.00010 | Regression loss: 0.00515 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 213 | Classification loss: 0.00002 | Regression loss: 0.00144 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 214 | Classification loss: 0.00003 | Regression loss: 0.00760 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 215 | Classification loss: 0.00022 | Regression loss: 0.00882 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 216 | Classification loss: 0.00009 | Regression loss: 0.00417 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 217 | Classification loss: 0.00017 | Regression loss: 0.00482 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 218 | Classification loss: 0.00002 | Regression loss: 0.00434 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 219 | Classification loss: 0.00002 | Regression loss: 0.00746 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 220 | Classification loss: 0.00020 | Regression loss: 0.01238 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 221 | Classification loss: 0.00002 | Regression loss: 0.00403 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 222 | Classification loss: 0.00005 | Regression loss: 0.00383 | Running loss: 0.00933\n",
            "Epoch: 44 | Iteration: 223 | Classification loss: 0.00004 | Regression loss: 0.00641 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 224 | Classification loss: 0.00002 | Regression loss: 0.00236 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 225 | Classification loss: 0.00006 | Regression loss: 0.02925 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 226 | Classification loss: 0.00019 | Regression loss: 0.00477 | Running loss: 0.00939\n",
            "Epoch: 44 | Iteration: 227 | Classification loss: 0.00005 | Regression loss: 0.00502 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 228 | Classification loss: 0.00007 | Regression loss: 0.00580 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 229 | Classification loss: 0.00050 | Regression loss: 0.01175 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 230 | Classification loss: 0.00004 | Regression loss: 0.00236 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 231 | Classification loss: 0.00003 | Regression loss: 0.00169 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 232 | Classification loss: 0.00041 | Regression loss: 0.00970 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 233 | Classification loss: 0.00013 | Regression loss: 0.01338 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 234 | Classification loss: 0.00021 | Regression loss: 0.00710 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 235 | Classification loss: 0.00007 | Regression loss: 0.00579 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 236 | Classification loss: 0.00017 | Regression loss: 0.00376 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 237 | Classification loss: 0.00041 | Regression loss: 0.01669 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 238 | Classification loss: 0.00016 | Regression loss: 0.00595 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 239 | Classification loss: 0.00111 | Regression loss: 0.06424 | Running loss: 0.00948\n",
            "Epoch: 44 | Iteration: 240 | Classification loss: 0.00016 | Regression loss: 0.00984 | Running loss: 0.00949\n",
            "Epoch: 44 | Iteration: 241 | Classification loss: 0.00082 | Regression loss: 0.01673 | Running loss: 0.00952\n",
            "Epoch: 44 | Iteration: 242 | Classification loss: 0.00025 | Regression loss: 0.02008 | Running loss: 0.00956\n",
            "Epoch: 44 | Iteration: 243 | Classification loss: 0.00025 | Regression loss: 0.00831 | Running loss: 0.00955\n",
            "Epoch: 44 | Iteration: 244 | Classification loss: 0.00014 | Regression loss: 0.01189 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 245 | Classification loss: 0.00010 | Regression loss: 0.00377 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 246 | Classification loss: 0.00008 | Regression loss: 0.00429 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 247 | Classification loss: 0.00010 | Regression loss: 0.00950 | Running loss: 0.00955\n",
            "Epoch: 44 | Iteration: 248 | Classification loss: 0.00003 | Regression loss: 0.00354 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 249 | Classification loss: 0.00275 | Regression loss: 0.01877 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 250 | Classification loss: 0.00025 | Regression loss: 0.00675 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 251 | Classification loss: 0.00020 | Regression loss: 0.01389 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 252 | Classification loss: 0.00004 | Regression loss: 0.00431 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 253 | Classification loss: 0.00012 | Regression loss: 0.00517 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 254 | Classification loss: 0.00020 | Regression loss: 0.00882 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 255 | Classification loss: 0.00022 | Regression loss: 0.00253 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 256 | Classification loss: 0.00002 | Regression loss: 0.01257 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 257 | Classification loss: 0.00002 | Regression loss: 0.00397 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 258 | Classification loss: 0.00017 | Regression loss: 0.00906 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 259 | Classification loss: 0.00043 | Regression loss: 0.00586 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 260 | Classification loss: 0.00007 | Regression loss: 0.00281 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 261 | Classification loss: 0.00005 | Regression loss: 0.00286 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 262 | Classification loss: 0.00006 | Regression loss: 0.00428 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 263 | Classification loss: 0.00005 | Regression loss: 0.00392 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 264 | Classification loss: 0.00018 | Regression loss: 0.00252 | Running loss: 0.00949\n",
            "Epoch: 44 | Iteration: 265 | Classification loss: 0.00001 | Regression loss: 0.00448 | Running loss: 0.00949\n",
            "Epoch: 44 | Iteration: 266 | Classification loss: 0.00008 | Regression loss: 0.00611 | Running loss: 0.00949\n",
            "Epoch: 44 | Iteration: 267 | Classification loss: 0.00053 | Regression loss: 0.00845 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 268 | Classification loss: 0.00017 | Regression loss: 0.00854 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 269 | Classification loss: 0.00010 | Regression loss: 0.00521 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 270 | Classification loss: 0.00005 | Regression loss: 0.00642 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 271 | Classification loss: 0.00007 | Regression loss: 0.00484 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 272 | Classification loss: 0.00022 | Regression loss: 0.00402 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 273 | Classification loss: 0.00012 | Regression loss: 0.00484 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 274 | Classification loss: 0.00007 | Regression loss: 0.00350 | Running loss: 0.00940\n",
            "Epoch: 44 | Iteration: 275 | Classification loss: 0.00003 | Regression loss: 0.00855 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 276 | Classification loss: 0.00012 | Regression loss: 0.01046 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 277 | Classification loss: 0.00036 | Regression loss: 0.07634 | Running loss: 0.00956\n",
            "Epoch: 44 | Iteration: 278 | Classification loss: 0.00018 | Regression loss: 0.00260 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 279 | Classification loss: 0.00038 | Regression loss: 0.01364 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 280 | Classification loss: 0.00009 | Regression loss: 0.00680 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 281 | Classification loss: 0.00025 | Regression loss: 0.00636 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 282 | Classification loss: 0.00015 | Regression loss: 0.00893 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 283 | Classification loss: 0.00032 | Regression loss: 0.00413 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 284 | Classification loss: 0.00033 | Regression loss: 0.01068 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 285 | Classification loss: 0.00241 | Regression loss: 0.02596 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 286 | Classification loss: 0.00013 | Regression loss: 0.00419 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 287 | Classification loss: 0.00087 | Regression loss: 0.00890 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 288 | Classification loss: 0.00008 | Regression loss: 0.00709 | Running loss: 0.00954\n",
            "Epoch: 44 | Iteration: 289 | Classification loss: 0.00003 | Regression loss: 0.00281 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 290 | Classification loss: 0.00005 | Regression loss: 0.00298 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 291 | Classification loss: 0.00007 | Regression loss: 0.00802 | Running loss: 0.00951\n",
            "Epoch: 44 | Iteration: 292 | Classification loss: 0.00004 | Regression loss: 0.00382 | Running loss: 0.00950\n",
            "Epoch: 44 | Iteration: 293 | Classification loss: 0.00194 | Regression loss: 0.03969 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 294 | Classification loss: 0.00098 | Regression loss: 0.01525 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 295 | Classification loss: 0.00006 | Regression loss: 0.00615 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 296 | Classification loss: 0.00007 | Regression loss: 0.00456 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 297 | Classification loss: 0.00109 | Regression loss: 0.02432 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 298 | Classification loss: 0.00014 | Regression loss: 0.00866 | Running loss: 0.00961\n",
            "Epoch: 44 | Iteration: 299 | Classification loss: 0.00007 | Regression loss: 0.00594 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 300 | Classification loss: 0.00015 | Regression loss: 0.02429 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 301 | Classification loss: 0.00061 | Regression loss: 0.00619 | Running loss: 0.00961\n",
            "Epoch: 44 | Iteration: 302 | Classification loss: 0.00018 | Regression loss: 0.00577 | Running loss: 0.00961\n",
            "Epoch: 44 | Iteration: 303 | Classification loss: 0.00006 | Regression loss: 0.00660 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 304 | Classification loss: 0.00001 | Regression loss: 0.00525 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 305 | Classification loss: 0.00016 | Regression loss: 0.00517 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 306 | Classification loss: 0.00003 | Regression loss: 0.00567 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 307 | Classification loss: 0.00005 | Regression loss: 0.00252 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 308 | Classification loss: 0.00003 | Regression loss: 0.00342 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 309 | Classification loss: 0.00002 | Regression loss: 0.00179 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 310 | Classification loss: 0.00002 | Regression loss: 0.00709 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 311 | Classification loss: 0.00001 | Regression loss: 0.00362 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 312 | Classification loss: 0.00072 | Regression loss: 0.01428 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 313 | Classification loss: 0.00005 | Regression loss: 0.00348 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 314 | Classification loss: 0.00022 | Regression loss: 0.02482 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 315 | Classification loss: 0.00046 | Regression loss: 0.00690 | Running loss: 0.00962\n",
            "Epoch: 44 | Iteration: 316 | Classification loss: 0.00027 | Regression loss: 0.00575 | Running loss: 0.00961\n",
            "Epoch: 44 | Iteration: 317 | Classification loss: 0.00002 | Regression loss: 0.00503 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 318 | Classification loss: 0.00004 | Regression loss: 0.00666 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 319 | Classification loss: 0.00017 | Regression loss: 0.00811 | Running loss: 0.00960\n",
            "Epoch: 44 | Iteration: 320 | Classification loss: 0.00048 | Regression loss: 0.00375 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 321 | Classification loss: 0.00007 | Regression loss: 0.00278 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 322 | Classification loss: 0.00011 | Regression loss: 0.00638 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 323 | Classification loss: 0.00018 | Regression loss: 0.00421 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 324 | Classification loss: 0.00015 | Regression loss: 0.00943 | Running loss: 0.00958\n",
            "Epoch: 44 | Iteration: 325 | Classification loss: 0.00016 | Regression loss: 0.00762 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 326 | Classification loss: 0.00004 | Regression loss: 0.01565 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 327 | Classification loss: 0.00013 | Regression loss: 0.00627 | Running loss: 0.00959\n",
            "Epoch: 44 | Iteration: 328 | Classification loss: 0.00005 | Regression loss: 0.00776 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 329 | Classification loss: 0.00002 | Regression loss: 0.00402 | Running loss: 0.00957\n",
            "Epoch: 44 | Iteration: 330 | Classification loss: 0.00008 | Regression loss: 0.00712 | Running loss: 0.00956\n",
            "Epoch: 44 | Iteration: 331 | Classification loss: 0.00011 | Regression loss: 0.00430 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 332 | Classification loss: 0.00088 | Regression loss: 0.00882 | Running loss: 0.00953\n",
            "Epoch: 44 | Iteration: 333 | Classification loss: 0.00004 | Regression loss: 0.00276 | Running loss: 0.00952\n",
            "Epoch: 44 | Iteration: 334 | Classification loss: 0.00027 | Regression loss: 0.00631 | Running loss: 0.00952\n",
            "Epoch: 44 | Iteration: 335 | Classification loss: 0.00031 | Regression loss: 0.00538 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 336 | Classification loss: 0.00002 | Regression loss: 0.00882 | Running loss: 0.00945\n",
            "Epoch: 44 | Iteration: 337 | Classification loss: 0.00011 | Regression loss: 0.01140 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 338 | Classification loss: 0.00010 | Regression loss: 0.00608 | Running loss: 0.00947\n",
            "Epoch: 44 | Iteration: 339 | Classification loss: 0.00009 | Regression loss: 0.00905 | Running loss: 0.00945\n",
            "Epoch: 44 | Iteration: 340 | Classification loss: 0.00042 | Regression loss: 0.00519 | Running loss: 0.00945\n",
            "Epoch: 44 | Iteration: 341 | Classification loss: 0.00027 | Regression loss: 0.01702 | Running loss: 0.00947\n",
            "Epoch: 44 | Iteration: 342 | Classification loss: 0.00002 | Regression loss: 0.01007 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 343 | Classification loss: 0.00039 | Regression loss: 0.00697 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 344 | Classification loss: 0.00016 | Regression loss: 0.01166 | Running loss: 0.00947\n",
            "Epoch: 44 | Iteration: 345 | Classification loss: 0.00018 | Regression loss: 0.00658 | Running loss: 0.00946\n",
            "Epoch: 44 | Iteration: 346 | Classification loss: 0.00022 | Regression loss: 0.00891 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 347 | Classification loss: 0.00013 | Regression loss: 0.00325 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 348 | Classification loss: 0.00067 | Regression loss: 0.01412 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 349 | Classification loss: 0.00011 | Regression loss: 0.00278 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 350 | Classification loss: 0.00027 | Regression loss: 0.00924 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 351 | Classification loss: 0.00028 | Regression loss: 0.00182 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 352 | Classification loss: 0.00010 | Regression loss: 0.01610 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 353 | Classification loss: 0.00010 | Regression loss: 0.00481 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 354 | Classification loss: 0.00039 | Regression loss: 0.00797 | Running loss: 0.00943\n",
            "Epoch: 44 | Iteration: 355 | Classification loss: 0.00002 | Regression loss: 0.00239 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 356 | Classification loss: 0.00003 | Regression loss: 0.00348 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 357 | Classification loss: 0.00001 | Regression loss: 0.01120 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 358 | Classification loss: 0.00022 | Regression loss: 0.00900 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 359 | Classification loss: 0.00031 | Regression loss: 0.00505 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 360 | Classification loss: 0.00012 | Regression loss: 0.01715 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 361 | Classification loss: 0.00007 | Regression loss: 0.01125 | Running loss: 0.00942\n",
            "Epoch: 44 | Iteration: 362 | Classification loss: 0.00015 | Regression loss: 0.01289 | Running loss: 0.00939\n",
            "Epoch: 44 | Iteration: 363 | Classification loss: 0.00014 | Regression loss: 0.01590 | Running loss: 0.00932\n",
            "Epoch: 44 | Iteration: 364 | Classification loss: 0.00060 | Regression loss: 0.04750 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 365 | Classification loss: 0.00004 | Regression loss: 0.00658 | Running loss: 0.00941\n",
            "Epoch: 44 | Iteration: 366 | Classification loss: 0.00006 | Regression loss: 0.00482 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 367 | Classification loss: 0.00002 | Regression loss: 0.00272 | Running loss: 0.00933\n",
            "Epoch: 44 | Iteration: 368 | Classification loss: 0.00010 | Regression loss: 0.01799 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 369 | Classification loss: 0.00018 | Regression loss: 0.00871 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 370 | Classification loss: 0.00027 | Regression loss: 0.01689 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 371 | Classification loss: 0.00052 | Regression loss: 0.01312 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 372 | Classification loss: 0.00015 | Regression loss: 0.00676 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 373 | Classification loss: 0.00006 | Regression loss: 0.00640 | Running loss: 0.00937\n",
            "Epoch: 44 | Iteration: 374 | Classification loss: 0.00092 | Regression loss: 0.01455 | Running loss: 0.00938\n",
            "Epoch: 44 | Iteration: 375 | Classification loss: 0.00025 | Regression loss: 0.00333 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 376 | Classification loss: 0.00033 | Regression loss: 0.00904 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 377 | Classification loss: 0.00033 | Regression loss: 0.01410 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 378 | Classification loss: 0.00001 | Regression loss: 0.00289 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 379 | Classification loss: 0.00005 | Regression loss: 0.00535 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 380 | Classification loss: 0.00004 | Regression loss: 0.00572 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 381 | Classification loss: 0.00015 | Regression loss: 0.00529 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 382 | Classification loss: 0.00020 | Regression loss: 0.00573 | Running loss: 0.00933\n",
            "Epoch: 44 | Iteration: 383 | Classification loss: 0.00008 | Regression loss: 0.00851 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 384 | Classification loss: 0.00002 | Regression loss: 0.00322 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 385 | Classification loss: 0.00023 | Regression loss: 0.00332 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 386 | Classification loss: 0.00037 | Regression loss: 0.00571 | Running loss: 0.00930\n",
            "Epoch: 44 | Iteration: 387 | Classification loss: 0.00003 | Regression loss: 0.00374 | Running loss: 0.00930\n",
            "Epoch: 44 | Iteration: 388 | Classification loss: 0.00030 | Regression loss: 0.01336 | Running loss: 0.00932\n",
            "Epoch: 44 | Iteration: 389 | Classification loss: 0.00050 | Regression loss: 0.01522 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 390 | Classification loss: 0.00009 | Regression loss: 0.01677 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 391 | Classification loss: 0.00006 | Regression loss: 0.00733 | Running loss: 0.00936\n",
            "Epoch: 44 | Iteration: 392 | Classification loss: 0.00002 | Regression loss: 0.00523 | Running loss: 0.00935\n",
            "Epoch: 44 | Iteration: 393 | Classification loss: 0.00022 | Regression loss: 0.00333 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 394 | Classification loss: 0.00030 | Regression loss: 0.00363 | Running loss: 0.00934\n",
            "Epoch: 44 | Iteration: 395 | Classification loss: 0.00002 | Regression loss: 0.00311 | Running loss: 0.00933\n",
            "Epoch: 44 | Iteration: 396 | Classification loss: 0.00032 | Regression loss: 0.01861 | Running loss: 0.00933\n",
            "Epoch: 44 | Iteration: 397 | Classification loss: 0.00006 | Regression loss: 0.00355 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 398 | Classification loss: 0.00012 | Regression loss: 0.00460 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 399 | Classification loss: 0.00019 | Regression loss: 0.00376 | Running loss: 0.00924\n",
            "Epoch: 44 | Iteration: 400 | Classification loss: 0.00002 | Regression loss: 0.00480 | Running loss: 0.00924\n",
            "Epoch: 44 | Iteration: 401 | Classification loss: 0.00149 | Regression loss: 0.02714 | Running loss: 0.00929\n",
            "Epoch: 44 | Iteration: 402 | Classification loss: 0.00010 | Regression loss: 0.00681 | Running loss: 0.00929\n",
            "Epoch: 44 | Iteration: 403 | Classification loss: 0.00013 | Regression loss: 0.00276 | Running loss: 0.00927\n",
            "Epoch: 44 | Iteration: 404 | Classification loss: 0.00003 | Regression loss: 0.00349 | Running loss: 0.00927\n",
            "Epoch: 44 | Iteration: 405 | Classification loss: 0.00016 | Regression loss: 0.01303 | Running loss: 0.00927\n",
            "Epoch: 44 | Iteration: 406 | Classification loss: 0.00001 | Regression loss: 0.00244 | Running loss: 0.00926\n",
            "Epoch: 44 | Iteration: 407 | Classification loss: 0.00024 | Regression loss: 0.00616 | Running loss: 0.00926\n",
            "Epoch: 44 | Iteration: 408 | Classification loss: 0.00005 | Regression loss: 0.00485 | Running loss: 0.00926\n",
            "Epoch: 44 | Iteration: 409 | Classification loss: 0.00016 | Regression loss: 0.02079 | Running loss: 0.00929\n",
            "Epoch: 44 | Iteration: 410 | Classification loss: 0.00012 | Regression loss: 0.00513 | Running loss: 0.00929\n",
            "Epoch: 44 | Iteration: 411 | Classification loss: 0.00026 | Regression loss: 0.00727 | Running loss: 0.00930\n",
            "Epoch: 44 | Iteration: 412 | Classification loss: 0.00021 | Regression loss: 0.00367 | Running loss: 0.00929\n",
            "Epoch: 44 | Iteration: 413 | Classification loss: 0.00026 | Regression loss: 0.00568 | Running loss: 0.00929\n",
            "Epoch: 44 | Iteration: 414 | Classification loss: 0.00015 | Regression loss: 0.00209 | Running loss: 0.00928\n",
            "Epoch: 44 | Iteration: 415 | Classification loss: 0.00005 | Regression loss: 0.00713 | Running loss: 0.00928\n",
            "Epoch: 44 | Iteration: 416 | Classification loss: 0.00006 | Regression loss: 0.00986 | Running loss: 0.00930\n",
            "Epoch: 44 | Iteration: 417 | Classification loss: 0.00002 | Regression loss: 0.00182 | Running loss: 0.00928\n",
            "Epoch: 44 | Iteration: 418 | Classification loss: 0.00029 | Regression loss: 0.01968 | Running loss: 0.00927\n",
            "Epoch: 44 | Iteration: 419 | Classification loss: 0.00003 | Regression loss: 0.00326 | Running loss: 0.00927\n",
            "Epoch: 44 | Iteration: 420 | Classification loss: 0.00007 | Regression loss: 0.00982 | Running loss: 0.00926\n",
            "Epoch: 44 | Iteration: 421 | Classification loss: 0.00057 | Regression loss: 0.01678 | Running loss: 0.00928\n",
            "Epoch: 44 | Iteration: 422 | Classification loss: 0.00005 | Regression loss: 0.00533 | Running loss: 0.00927\n",
            "Epoch: 44 | Iteration: 423 | Classification loss: 0.00005 | Regression loss: 0.01770 | Running loss: 0.00923\n",
            "Epoch: 44 | Iteration: 424 | Classification loss: 0.00008 | Regression loss: 0.00443 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 425 | Classification loss: 0.00036 | Regression loss: 0.00498 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 426 | Classification loss: 0.00008 | Regression loss: 0.00530 | Running loss: 0.00917\n",
            "Epoch: 44 | Iteration: 427 | Classification loss: 0.00006 | Regression loss: 0.00560 | Running loss: 0.00917\n",
            "Epoch: 44 | Iteration: 428 | Classification loss: 0.00045 | Regression loss: 0.00872 | Running loss: 0.00917\n",
            "Epoch: 44 | Iteration: 429 | Classification loss: 0.00004 | Regression loss: 0.00527 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 430 | Classification loss: 0.00023 | Regression loss: 0.04081 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 431 | Classification loss: 0.00008 | Regression loss: 0.00416 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 432 | Classification loss: 0.00004 | Regression loss: 0.00500 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 433 | Classification loss: 0.00009 | Regression loss: 0.00459 | Running loss: 0.00923\n",
            "Epoch: 44 | Iteration: 434 | Classification loss: 0.00002 | Regression loss: 0.01004 | Running loss: 0.00924\n",
            "Epoch: 44 | Iteration: 435 | Classification loss: 0.00008 | Regression loss: 0.00831 | Running loss: 0.00924\n",
            "Epoch: 44 | Iteration: 436 | Classification loss: 0.00011 | Regression loss: 0.00491 | Running loss: 0.00924\n",
            "Epoch: 44 | Iteration: 437 | Classification loss: 0.00008 | Regression loss: 0.00608 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 438 | Classification loss: 0.00011 | Regression loss: 0.00334 | Running loss: 0.00917\n",
            "Epoch: 44 | Iteration: 439 | Classification loss: 0.00013 | Regression loss: 0.01001 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 440 | Classification loss: 0.00022 | Regression loss: 0.00356 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 441 | Classification loss: 0.00002 | Regression loss: 0.00496 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 442 | Classification loss: 0.00013 | Regression loss: 0.00782 | Running loss: 0.00915\n",
            "Epoch: 44 | Iteration: 443 | Classification loss: 0.00009 | Regression loss: 0.00318 | Running loss: 0.00914\n",
            "Epoch: 44 | Iteration: 444 | Classification loss: 0.00025 | Regression loss: 0.00815 | Running loss: 0.00914\n",
            "Epoch: 44 | Iteration: 445 | Classification loss: 0.00006 | Regression loss: 0.03139 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 446 | Classification loss: 0.00008 | Regression loss: 0.00556 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 447 | Classification loss: 0.00145 | Regression loss: 0.00786 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 448 | Classification loss: 0.00053 | Regression loss: 0.00767 | Running loss: 0.00919\n",
            "Epoch: 44 | Iteration: 449 | Classification loss: 0.00041 | Regression loss: 0.00981 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 450 | Classification loss: 0.00012 | Regression loss: 0.00438 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 451 | Classification loss: 0.00047 | Regression loss: 0.00767 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 452 | Classification loss: 0.00247 | Regression loss: 0.06074 | Running loss: 0.00926\n",
            "Epoch: 44 | Iteration: 453 | Classification loss: 0.00019 | Regression loss: 0.00284 | Running loss: 0.00926\n",
            "Epoch: 44 | Iteration: 454 | Classification loss: 0.00001 | Regression loss: 0.00427 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 455 | Classification loss: 0.00024 | Regression loss: 0.00619 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 456 | Classification loss: 0.00009 | Regression loss: 0.00783 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 457 | Classification loss: 0.00004 | Regression loss: 0.00554 | Running loss: 0.00924\n",
            "Epoch: 44 | Iteration: 458 | Classification loss: 0.00020 | Regression loss: 0.01658 | Running loss: 0.00925\n",
            "Epoch: 44 | Iteration: 459 | Classification loss: 0.00002 | Regression loss: 0.00362 | Running loss: 0.00923\n",
            "Epoch: 44 | Iteration: 460 | Classification loss: 0.00011 | Regression loss: 0.00942 | Running loss: 0.00923\n",
            "Epoch: 44 | Iteration: 461 | Classification loss: 0.00022 | Regression loss: 0.00531 | Running loss: 0.00923\n",
            "Epoch: 44 | Iteration: 462 | Classification loss: 0.00004 | Regression loss: 0.00459 | Running loss: 0.00920\n",
            "Epoch: 44 | Iteration: 463 | Classification loss: 0.00016 | Regression loss: 0.01470 | Running loss: 0.00921\n",
            "Epoch: 44 | Iteration: 464 | Classification loss: 0.00001 | Regression loss: 0.00590 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 465 | Classification loss: 0.00003 | Regression loss: 0.00354 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 466 | Classification loss: 0.00004 | Regression loss: 0.00631 | Running loss: 0.00918\n",
            "Epoch: 44 | Iteration: 467 | Classification loss: 0.00311 | Regression loss: 0.03130 | Running loss: 0.00924\n",
            "Evaluating dataset\n",
            "\n",
            "mAP:\n",
            "monocyte: 0.9918417674481452\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6867705546243715\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.3367206076969616\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.4674000088979846\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5365730700519356\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 45 | Iteration: 0 | Classification loss: 0.00002 | Regression loss: 0.01007 | Running loss: 0.00925\n",
            "Epoch: 45 | Iteration: 1 | Classification loss: 0.00005 | Regression loss: 0.00613 | Running loss: 0.00925\n",
            "Epoch: 45 | Iteration: 2 | Classification loss: 0.00010 | Regression loss: 0.00224 | Running loss: 0.00923\n",
            "Epoch: 45 | Iteration: 3 | Classification loss: 0.00022 | Regression loss: 0.00257 | Running loss: 0.00923\n",
            "Epoch: 45 | Iteration: 4 | Classification loss: 0.00006 | Regression loss: 0.00436 | Running loss: 0.00922\n",
            "Epoch: 45 | Iteration: 5 | Classification loss: 0.00002 | Regression loss: 0.00454 | Running loss: 0.00920\n",
            "Epoch: 45 | Iteration: 6 | Classification loss: 0.00014 | Regression loss: 0.00252 | Running loss: 0.00918\n",
            "Epoch: 45 | Iteration: 7 | Classification loss: 0.00003 | Regression loss: 0.00698 | Running loss: 0.00917\n",
            "Epoch: 45 | Iteration: 8 | Classification loss: 0.00004 | Regression loss: 0.00397 | Running loss: 0.00913\n",
            "Epoch: 45 | Iteration: 9 | Classification loss: 0.00009 | Regression loss: 0.01077 | Running loss: 0.00914\n",
            "Epoch: 45 | Iteration: 10 | Classification loss: 0.00005 | Regression loss: 0.00367 | Running loss: 0.00913\n",
            "Epoch: 45 | Iteration: 11 | Classification loss: 0.00004 | Regression loss: 0.00971 | Running loss: 0.00914\n",
            "Epoch: 45 | Iteration: 12 | Classification loss: 0.00009 | Regression loss: 0.00680 | Running loss: 0.00915\n",
            "Epoch: 45 | Iteration: 13 | Classification loss: 0.00188 | Regression loss: 0.02423 | Running loss: 0.00919\n",
            "Epoch: 45 | Iteration: 14 | Classification loss: 0.00009 | Regression loss: 0.00516 | Running loss: 0.00916\n",
            "Epoch: 45 | Iteration: 15 | Classification loss: 0.00009 | Regression loss: 0.00441 | Running loss: 0.00912\n",
            "Epoch: 45 | Iteration: 16 | Classification loss: 0.00023 | Regression loss: 0.04713 | Running loss: 0.00918\n",
            "Epoch: 45 | Iteration: 17 | Classification loss: 0.00002 | Regression loss: 0.00265 | Running loss: 0.00918\n",
            "Epoch: 45 | Iteration: 18 | Classification loss: 0.00004 | Regression loss: 0.00599 | Running loss: 0.00917\n",
            "Epoch: 45 | Iteration: 19 | Classification loss: 0.00023 | Regression loss: 0.00619 | Running loss: 0.00918\n",
            "Epoch: 45 | Iteration: 20 | Classification loss: 0.00008 | Regression loss: 0.00473 | Running loss: 0.00906\n",
            "Epoch: 45 | Iteration: 21 | Classification loss: 0.00006 | Regression loss: 0.00591 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 22 | Classification loss: 0.00041 | Regression loss: 0.01015 | Running loss: 0.00906\n",
            "Epoch: 45 | Iteration: 23 | Classification loss: 0.00002 | Regression loss: 0.00224 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 24 | Classification loss: 0.00021 | Regression loss: 0.00480 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 25 | Classification loss: 0.00009 | Regression loss: 0.00317 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 26 | Classification loss: 0.00014 | Regression loss: 0.00428 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 27 | Classification loss: 0.00003 | Regression loss: 0.00712 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 28 | Classification loss: 0.00020 | Regression loss: 0.00833 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 29 | Classification loss: 0.00014 | Regression loss: 0.00400 | Running loss: 0.00906\n",
            "Epoch: 45 | Iteration: 30 | Classification loss: 0.00005 | Regression loss: 0.00333 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 31 | Classification loss: 0.00010 | Regression loss: 0.01407 | Running loss: 0.00907\n",
            "Epoch: 45 | Iteration: 32 | Classification loss: 0.00009 | Regression loss: 0.00623 | Running loss: 0.00902\n",
            "Epoch: 45 | Iteration: 33 | Classification loss: 0.00018 | Regression loss: 0.00650 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 34 | Classification loss: 0.00012 | Regression loss: 0.00300 | Running loss: 0.00902\n",
            "Epoch: 45 | Iteration: 35 | Classification loss: 0.00014 | Regression loss: 0.01558 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 36 | Classification loss: 0.00127 | Regression loss: 0.00675 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 37 | Classification loss: 0.00013 | Regression loss: 0.00657 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 38 | Classification loss: 0.00013 | Regression loss: 0.00754 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 39 | Classification loss: 0.00028 | Regression loss: 0.00426 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 40 | Classification loss: 0.00015 | Regression loss: 0.00676 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 41 | Classification loss: 0.00010 | Regression loss: 0.01595 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 42 | Classification loss: 0.00011 | Regression loss: 0.00924 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 43 | Classification loss: 0.00003 | Regression loss: 0.00455 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 44 | Classification loss: 0.00005 | Regression loss: 0.01046 | Running loss: 0.00906\n",
            "Epoch: 45 | Iteration: 45 | Classification loss: 0.00005 | Regression loss: 0.01611 | Running loss: 0.00908\n",
            "Epoch: 45 | Iteration: 46 | Classification loss: 0.00002 | Regression loss: 0.00213 | Running loss: 0.00908\n",
            "Epoch: 45 | Iteration: 47 | Classification loss: 0.00001 | Regression loss: 0.00443 | Running loss: 0.00908\n",
            "Epoch: 45 | Iteration: 48 | Classification loss: 0.00002 | Regression loss: 0.00339 | Running loss: 0.00908\n",
            "Epoch: 45 | Iteration: 49 | Classification loss: 0.00002 | Regression loss: 0.00445 | Running loss: 0.00907\n",
            "Epoch: 45 | Iteration: 50 | Classification loss: 0.00003 | Regression loss: 0.00607 | Running loss: 0.00908\n",
            "Epoch: 45 | Iteration: 51 | Classification loss: 0.00001 | Regression loss: 0.00394 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 52 | Classification loss: 0.00019 | Regression loss: 0.00565 | Running loss: 0.00905\n",
            "Epoch: 45 | Iteration: 53 | Classification loss: 0.00003 | Regression loss: 0.00235 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 54 | Classification loss: 0.00025 | Regression loss: 0.00709 | Running loss: 0.00904\n",
            "Epoch: 45 | Iteration: 55 | Classification loss: 0.00037 | Regression loss: 0.00782 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 56 | Classification loss: 0.00001 | Regression loss: 0.00622 | Running loss: 0.00903\n",
            "Epoch: 45 | Iteration: 57 | Classification loss: 0.00012 | Regression loss: 0.00489 | Running loss: 0.00899\n",
            "Epoch: 45 | Iteration: 58 | Classification loss: 0.00008 | Regression loss: 0.00306 | Running loss: 0.00894\n",
            "Epoch: 45 | Iteration: 59 | Classification loss: 0.00009 | Regression loss: 0.00570 | Running loss: 0.00894\n",
            "Epoch: 45 | Iteration: 60 | Classification loss: 0.00005 | Regression loss: 0.00393 | Running loss: 0.00894\n",
            "Epoch: 45 | Iteration: 61 | Classification loss: 0.00005 | Regression loss: 0.00466 | Running loss: 0.00894\n",
            "Epoch: 45 | Iteration: 62 | Classification loss: 0.00001 | Regression loss: 0.00255 | Running loss: 0.00893\n",
            "Epoch: 45 | Iteration: 63 | Classification loss: 0.00004 | Regression loss: 0.00304 | Running loss: 0.00890\n",
            "Epoch: 45 | Iteration: 64 | Classification loss: 0.00001 | Regression loss: 0.00273 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 65 | Classification loss: 0.00031 | Regression loss: 0.01012 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 66 | Classification loss: 0.00070 | Regression loss: 0.00359 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 67 | Classification loss: 0.00010 | Regression loss: 0.01243 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 68 | Classification loss: 0.00002 | Regression loss: 0.00382 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 69 | Classification loss: 0.00003 | Regression loss: 0.00339 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 70 | Classification loss: 0.00001 | Regression loss: 0.00288 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 71 | Classification loss: 0.00011 | Regression loss: 0.00313 | Running loss: 0.00874\n",
            "Epoch: 45 | Iteration: 72 | Classification loss: 0.00005 | Regression loss: 0.00361 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 73 | Classification loss: 0.00034 | Regression loss: 0.00301 | Running loss: 0.00871\n",
            "Epoch: 45 | Iteration: 74 | Classification loss: 0.00006 | Regression loss: 0.01008 | Running loss: 0.00873\n",
            "Epoch: 45 | Iteration: 75 | Classification loss: 0.00018 | Regression loss: 0.00453 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 76 | Classification loss: 0.00007 | Regression loss: 0.00477 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 77 | Classification loss: 0.00019 | Regression loss: 0.00918 | Running loss: 0.00874\n",
            "Epoch: 45 | Iteration: 78 | Classification loss: 0.00002 | Regression loss: 0.00238 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 79 | Classification loss: 0.00003 | Regression loss: 0.00222 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 80 | Classification loss: 0.00024 | Regression loss: 0.00318 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 81 | Classification loss: 0.00017 | Regression loss: 0.00561 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 82 | Classification loss: 0.00012 | Regression loss: 0.00803 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 83 | Classification loss: 0.00014 | Regression loss: 0.00235 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 84 | Classification loss: 0.00019 | Regression loss: 0.00484 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 85 | Classification loss: 0.00073 | Regression loss: 0.00961 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 86 | Classification loss: 0.00041 | Regression loss: 0.01472 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 87 | Classification loss: 0.00011 | Regression loss: 0.00290 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 88 | Classification loss: 0.00056 | Regression loss: 0.00331 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 89 | Classification loss: 0.00024 | Regression loss: 0.00781 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 90 | Classification loss: 0.00214 | Regression loss: 0.01691 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 91 | Classification loss: 0.00022 | Regression loss: 0.00618 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 92 | Classification loss: 0.00012 | Regression loss: 0.02830 | Running loss: 0.00868\n",
            "Epoch: 45 | Iteration: 93 | Classification loss: 0.00179 | Regression loss: 0.02732 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 94 | Classification loss: 0.00002 | Regression loss: 0.00270 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 95 | Classification loss: 0.00006 | Regression loss: 0.00442 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 96 | Classification loss: 0.00069 | Regression loss: 0.01315 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 97 | Classification loss: 0.00007 | Regression loss: 0.00913 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 98 | Classification loss: 0.00002 | Regression loss: 0.00503 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 99 | Classification loss: 0.00001 | Regression loss: 0.01259 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 100 | Classification loss: 0.00027 | Regression loss: 0.03206 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 101 | Classification loss: 0.00018 | Regression loss: 0.00464 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 102 | Classification loss: 0.00012 | Regression loss: 0.00480 | Running loss: 0.00871\n",
            "Epoch: 45 | Iteration: 103 | Classification loss: 0.00007 | Regression loss: 0.00478 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 104 | Classification loss: 0.00016 | Regression loss: 0.01452 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 105 | Classification loss: 0.00006 | Regression loss: 0.00433 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 106 | Classification loss: 0.00011 | Regression loss: 0.04819 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 107 | Classification loss: 0.00007 | Regression loss: 0.00668 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 108 | Classification loss: 0.00020 | Regression loss: 0.05274 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 109 | Classification loss: 0.00127 | Regression loss: 0.01984 | Running loss: 0.00890\n",
            "Epoch: 45 | Iteration: 110 | Classification loss: 0.00030 | Regression loss: 0.00850 | Running loss: 0.00890\n",
            "Epoch: 45 | Iteration: 111 | Classification loss: 0.00052 | Regression loss: 0.02249 | Running loss: 0.00894\n",
            "Epoch: 45 | Iteration: 112 | Classification loss: 0.00010 | Regression loss: 0.01436 | Running loss: 0.00896\n",
            "Epoch: 45 | Iteration: 113 | Classification loss: 0.00005 | Regression loss: 0.00550 | Running loss: 0.00897\n",
            "Epoch: 45 | Iteration: 114 | Classification loss: 0.00026 | Regression loss: 0.00395 | Running loss: 0.00892\n",
            "Epoch: 45 | Iteration: 115 | Classification loss: 0.00002 | Regression loss: 0.00184 | Running loss: 0.00892\n",
            "Epoch: 45 | Iteration: 116 | Classification loss: 0.00026 | Regression loss: 0.00408 | Running loss: 0.00892\n",
            "Epoch: 45 | Iteration: 117 | Classification loss: 0.00008 | Regression loss: 0.01059 | Running loss: 0.00893\n",
            "Epoch: 45 | Iteration: 118 | Classification loss: 0.00012 | Regression loss: 0.00776 | Running loss: 0.00894\n",
            "Epoch: 45 | Iteration: 119 | Classification loss: 0.00002 | Regression loss: 0.00871 | Running loss: 0.00893\n",
            "Epoch: 45 | Iteration: 120 | Classification loss: 0.00016 | Regression loss: 0.00548 | Running loss: 0.00892\n",
            "Epoch: 45 | Iteration: 121 | Classification loss: 0.00011 | Regression loss: 0.00378 | Running loss: 0.00892\n",
            "Epoch: 45 | Iteration: 122 | Classification loss: 0.00003 | Regression loss: 0.00341 | Running loss: 0.00890\n",
            "Epoch: 45 | Iteration: 123 | Classification loss: 0.00011 | Regression loss: 0.00295 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 124 | Classification loss: 0.00033 | Regression loss: 0.00555 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 125 | Classification loss: 0.00007 | Regression loss: 0.01681 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 126 | Classification loss: 0.00002 | Regression loss: 0.00252 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 127 | Classification loss: 0.00008 | Regression loss: 0.00646 | Running loss: 0.00889\n",
            "Epoch: 45 | Iteration: 128 | Classification loss: 0.00008 | Regression loss: 0.00717 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 129 | Classification loss: 0.00010 | Regression loss: 0.00327 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 130 | Classification loss: 0.00010 | Regression loss: 0.00310 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 131 | Classification loss: 0.00010 | Regression loss: 0.00525 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 132 | Classification loss: 0.00008 | Regression loss: 0.00820 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 133 | Classification loss: 0.00005 | Regression loss: 0.00214 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 134 | Classification loss: 0.00003 | Regression loss: 0.00343 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 135 | Classification loss: 0.00004 | Regression loss: 0.02843 | Running loss: 0.00877\n",
            "Epoch: 45 | Iteration: 136 | Classification loss: 0.00030 | Regression loss: 0.01414 | Running loss: 0.00877\n",
            "Epoch: 45 | Iteration: 137 | Classification loss: 0.00140 | Regression loss: 0.00680 | Running loss: 0.00877\n",
            "Epoch: 45 | Iteration: 138 | Classification loss: 0.00012 | Regression loss: 0.00643 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 139 | Classification loss: 0.00004 | Regression loss: 0.00652 | Running loss: 0.00877\n",
            "Epoch: 45 | Iteration: 140 | Classification loss: 0.00009 | Regression loss: 0.00594 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 141 | Classification loss: 0.00042 | Regression loss: 0.02992 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 142 | Classification loss: 0.00064 | Regression loss: 0.02223 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 143 | Classification loss: 0.00078 | Regression loss: 0.00596 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 144 | Classification loss: 0.00029 | Regression loss: 0.00543 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 145 | Classification loss: 0.00023 | Regression loss: 0.00453 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 146 | Classification loss: 0.00019 | Regression loss: 0.01815 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 147 | Classification loss: 0.00027 | Regression loss: 0.00600 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 148 | Classification loss: 0.00034 | Regression loss: 0.00507 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 149 | Classification loss: 0.00056 | Regression loss: 0.01369 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 150 | Classification loss: 0.00008 | Regression loss: 0.00330 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 151 | Classification loss: 0.00004 | Regression loss: 0.00432 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 152 | Classification loss: 0.00010 | Regression loss: 0.00701 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 153 | Classification loss: 0.00013 | Regression loss: 0.00221 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 154 | Classification loss: 0.00003 | Regression loss: 0.00361 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 155 | Classification loss: 0.00021 | Regression loss: 0.00716 | Running loss: 0.00877\n",
            "Epoch: 45 | Iteration: 156 | Classification loss: 0.00025 | Regression loss: 0.00771 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 157 | Classification loss: 0.00033 | Regression loss: 0.03895 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 158 | Classification loss: 0.00005 | Regression loss: 0.01124 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 159 | Classification loss: 0.00004 | Regression loss: 0.00465 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 160 | Classification loss: 0.00033 | Regression loss: 0.00761 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 161 | Classification loss: 0.00019 | Regression loss: 0.00668 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 162 | Classification loss: 0.00019 | Regression loss: 0.00838 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 163 | Classification loss: 0.00004 | Regression loss: 0.00453 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 164 | Classification loss: 0.00059 | Regression loss: 0.01694 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 165 | Classification loss: 0.00003 | Regression loss: 0.00474 | Running loss: 0.00874\n",
            "Epoch: 45 | Iteration: 166 | Classification loss: 0.00016 | Regression loss: 0.01220 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 167 | Classification loss: 0.00033 | Regression loss: 0.00455 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 168 | Classification loss: 0.00012 | Regression loss: 0.00487 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 169 | Classification loss: 0.00003 | Regression loss: 0.00418 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 170 | Classification loss: 0.00002 | Regression loss: 0.00209 | Running loss: 0.00874\n",
            "Epoch: 45 | Iteration: 171 | Classification loss: 0.00018 | Regression loss: 0.00452 | Running loss: 0.00874\n",
            "Epoch: 45 | Iteration: 172 | Classification loss: 0.00009 | Regression loss: 0.00387 | Running loss: 0.00873\n",
            "Epoch: 45 | Iteration: 173 | Classification loss: 0.00004 | Regression loss: 0.00274 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 174 | Classification loss: 0.00008 | Regression loss: 0.00735 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 175 | Classification loss: 0.00015 | Regression loss: 0.00315 | Running loss: 0.00871\n",
            "Epoch: 45 | Iteration: 176 | Classification loss: 0.00000 | Regression loss: 0.00474 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 177 | Classification loss: 0.00004 | Regression loss: 0.00266 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 178 | Classification loss: 0.00001 | Regression loss: 0.00252 | Running loss: 0.00871\n",
            "Epoch: 45 | Iteration: 179 | Classification loss: 0.00005 | Regression loss: 0.00600 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 180 | Classification loss: 0.00023 | Regression loss: 0.01149 | Running loss: 0.00871\n",
            "Epoch: 45 | Iteration: 181 | Classification loss: 0.00001 | Regression loss: 0.00265 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 182 | Classification loss: 0.00033 | Regression loss: 0.07618 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 183 | Classification loss: 0.00058 | Regression loss: 0.00666 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 184 | Classification loss: 0.00027 | Regression loss: 0.01086 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 185 | Classification loss: 0.00015 | Regression loss: 0.00992 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 186 | Classification loss: 0.00032 | Regression loss: 0.00810 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 187 | Classification loss: 0.00016 | Regression loss: 0.00702 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 188 | Classification loss: 0.00041 | Regression loss: 0.01145 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 189 | Classification loss: 0.00005 | Regression loss: 0.00498 | Running loss: 0.00889\n",
            "Epoch: 45 | Iteration: 190 | Classification loss: 0.00014 | Regression loss: 0.00399 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 191 | Classification loss: 0.00002 | Regression loss: 0.00697 | Running loss: 0.00889\n",
            "Epoch: 45 | Iteration: 192 | Classification loss: 0.00006 | Regression loss: 0.00557 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 193 | Classification loss: 0.00038 | Regression loss: 0.00457 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 194 | Classification loss: 0.00013 | Regression loss: 0.00188 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 195 | Classification loss: 0.00016 | Regression loss: 0.00861 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 196 | Classification loss: 0.00061 | Regression loss: 0.00471 | Running loss: 0.00886\n",
            "Epoch: 45 | Iteration: 197 | Classification loss: 0.00006 | Regression loss: 0.00770 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 198 | Classification loss: 0.00023 | Regression loss: 0.00492 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 199 | Classification loss: 0.00071 | Regression loss: 0.01403 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 200 | Classification loss: 0.00010 | Regression loss: 0.00494 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 201 | Classification loss: 0.00006 | Regression loss: 0.00603 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 202 | Classification loss: 0.00002 | Regression loss: 0.00495 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 203 | Classification loss: 0.00087 | Regression loss: 0.01009 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 204 | Classification loss: 0.00010 | Regression loss: 0.00301 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 205 | Classification loss: 0.00041 | Regression loss: 0.02378 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 206 | Classification loss: 0.00023 | Regression loss: 0.00692 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 207 | Classification loss: 0.00018 | Regression loss: 0.00500 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 208 | Classification loss: 0.00074 | Regression loss: 0.00465 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 209 | Classification loss: 0.00011 | Regression loss: 0.00397 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 210 | Classification loss: 0.00062 | Regression loss: 0.01292 | Running loss: 0.00890\n",
            "Epoch: 45 | Iteration: 211 | Classification loss: 0.00014 | Regression loss: 0.01006 | Running loss: 0.00889\n",
            "Epoch: 45 | Iteration: 212 | Classification loss: 0.00010 | Regression loss: 0.00416 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 213 | Classification loss: 0.00004 | Regression loss: 0.00491 | Running loss: 0.00888\n",
            "Epoch: 45 | Iteration: 214 | Classification loss: 0.00004 | Regression loss: 0.02381 | Running loss: 0.00892\n",
            "Epoch: 45 | Iteration: 215 | Classification loss: 0.00023 | Regression loss: 0.00454 | Running loss: 0.00889\n",
            "Epoch: 45 | Iteration: 216 | Classification loss: 0.00008 | Regression loss: 0.00256 | Running loss: 0.00889\n",
            "Epoch: 45 | Iteration: 217 | Classification loss: 0.00005 | Regression loss: 0.00470 | Running loss: 0.00887\n",
            "Epoch: 45 | Iteration: 218 | Classification loss: 0.00014 | Regression loss: 0.00316 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 219 | Classification loss: 0.00013 | Regression loss: 0.00387 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 220 | Classification loss: 0.00015 | Regression loss: 0.00596 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 221 | Classification loss: 0.00003 | Regression loss: 0.00706 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 222 | Classification loss: 0.00001 | Regression loss: 0.00652 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 223 | Classification loss: 0.00009 | Regression loss: 0.00479 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 224 | Classification loss: 0.00011 | Regression loss: 0.02042 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 225 | Classification loss: 0.00008 | Regression loss: 0.00359 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 226 | Classification loss: 0.00016 | Regression loss: 0.00208 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 227 | Classification loss: 0.00016 | Regression loss: 0.00315 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 228 | Classification loss: 0.00032 | Regression loss: 0.00345 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 229 | Classification loss: 0.00039 | Regression loss: 0.00679 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 230 | Classification loss: 0.00023 | Regression loss: 0.00246 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 231 | Classification loss: 0.00366 | Regression loss: 0.01638 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 232 | Classification loss: 0.00018 | Regression loss: 0.00551 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 233 | Classification loss: 0.00005 | Regression loss: 0.00495 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 234 | Classification loss: 0.00037 | Regression loss: 0.00544 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 235 | Classification loss: 0.00003 | Regression loss: 0.00399 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 236 | Classification loss: 0.00001 | Regression loss: 0.00292 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 237 | Classification loss: 0.00004 | Regression loss: 0.00578 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 238 | Classification loss: 0.00027 | Regression loss: 0.00427 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 239 | Classification loss: 0.00003 | Regression loss: 0.00607 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 240 | Classification loss: 0.00021 | Regression loss: 0.01054 | Running loss: 0.00879\n",
            "Epoch: 45 | Iteration: 241 | Classification loss: 0.00060 | Regression loss: 0.00855 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 242 | Classification loss: 0.00076 | Regression loss: 0.03371 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 243 | Classification loss: 0.00033 | Regression loss: 0.02237 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 244 | Classification loss: 0.00006 | Regression loss: 0.00265 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 245 | Classification loss: 0.00008 | Regression loss: 0.00513 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 246 | Classification loss: 0.00009 | Regression loss: 0.00759 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 247 | Classification loss: 0.00024 | Regression loss: 0.01359 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 248 | Classification loss: 0.00027 | Regression loss: 0.00630 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 249 | Classification loss: 0.00023 | Regression loss: 0.00487 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 250 | Classification loss: 0.00048 | Regression loss: 0.00645 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 251 | Classification loss: 0.00032 | Regression loss: 0.00843 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 252 | Classification loss: 0.00012 | Regression loss: 0.00428 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 253 | Classification loss: 0.00025 | Regression loss: 0.01027 | Running loss: 0.00884\n",
            "Epoch: 45 | Iteration: 254 | Classification loss: 0.00018 | Regression loss: 0.00630 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 255 | Classification loss: 0.00015 | Regression loss: 0.00949 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 256 | Classification loss: 0.00002 | Regression loss: 0.00238 | Running loss: 0.00885\n",
            "Epoch: 45 | Iteration: 257 | Classification loss: 0.00011 | Regression loss: 0.00815 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 258 | Classification loss: 0.00002 | Regression loss: 0.01133 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 259 | Classification loss: 0.00004 | Regression loss: 0.00651 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 260 | Classification loss: 0.00006 | Regression loss: 0.00463 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 261 | Classification loss: 0.00027 | Regression loss: 0.00769 | Running loss: 0.00882\n",
            "Epoch: 45 | Iteration: 262 | Classification loss: 0.00005 | Regression loss: 0.00934 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 263 | Classification loss: 0.00010 | Regression loss: 0.00385 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 264 | Classification loss: 0.00012 | Regression loss: 0.00735 | Running loss: 0.00883\n",
            "Epoch: 45 | Iteration: 265 | Classification loss: 0.00009 | Regression loss: 0.00223 | Running loss: 0.00881\n",
            "Epoch: 45 | Iteration: 266 | Classification loss: 0.00002 | Regression loss: 0.00473 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 267 | Classification loss: 0.00013 | Regression loss: 0.00371 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 268 | Classification loss: 0.00038 | Regression loss: 0.00619 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 269 | Classification loss: 0.00039 | Regression loss: 0.01747 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 270 | Classification loss: 0.00003 | Regression loss: 0.00245 | Running loss: 0.00880\n",
            "Epoch: 45 | Iteration: 271 | Classification loss: 0.00003 | Regression loss: 0.00347 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 272 | Classification loss: 0.00007 | Regression loss: 0.00518 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 273 | Classification loss: 0.00014 | Regression loss: 0.00356 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 274 | Classification loss: 0.00008 | Regression loss: 0.00345 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 275 | Classification loss: 0.00022 | Regression loss: 0.01378 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 276 | Classification loss: 0.00012 | Regression loss: 0.00847 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 277 | Classification loss: 0.00003 | Regression loss: 0.00821 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 278 | Classification loss: 0.00009 | Regression loss: 0.00889 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 279 | Classification loss: 0.00004 | Regression loss: 0.00596 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 280 | Classification loss: 0.00016 | Regression loss: 0.01008 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 281 | Classification loss: 0.00007 | Regression loss: 0.00762 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 282 | Classification loss: 0.00003 | Regression loss: 0.00302 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 283 | Classification loss: 0.00024 | Regression loss: 0.00510 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 284 | Classification loss: 0.00101 | Regression loss: 0.01444 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 285 | Classification loss: 0.00007 | Regression loss: 0.00411 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 286 | Classification loss: 0.00017 | Regression loss: 0.00275 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 287 | Classification loss: 0.00016 | Regression loss: 0.00668 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 288 | Classification loss: 0.00231 | Regression loss: 0.03888 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 289 | Classification loss: 0.00047 | Regression loss: 0.00281 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 290 | Classification loss: 0.00002 | Regression loss: 0.00692 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 291 | Classification loss: 0.00003 | Regression loss: 0.00288 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 292 | Classification loss: 0.00027 | Regression loss: 0.00765 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 293 | Classification loss: 0.00026 | Regression loss: 0.00344 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 294 | Classification loss: 0.00009 | Regression loss: 0.00842 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 295 | Classification loss: 0.00002 | Regression loss: 0.00327 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 296 | Classification loss: 0.00018 | Regression loss: 0.02385 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 297 | Classification loss: 0.00031 | Regression loss: 0.00376 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 298 | Classification loss: 0.00001 | Regression loss: 0.00364 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 299 | Classification loss: 0.00028 | Regression loss: 0.01240 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 300 | Classification loss: 0.00026 | Regression loss: 0.00360 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 301 | Classification loss: 0.00043 | Regression loss: 0.00335 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 302 | Classification loss: 0.00001 | Regression loss: 0.00475 | Running loss: 0.00868\n",
            "Epoch: 45 | Iteration: 303 | Classification loss: 0.00002 | Regression loss: 0.00540 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 304 | Classification loss: 0.00006 | Regression loss: 0.00869 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 305 | Classification loss: 0.00011 | Regression loss: 0.00826 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 306 | Classification loss: 0.00005 | Regression loss: 0.00396 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 307 | Classification loss: 0.00022 | Regression loss: 0.00644 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 308 | Classification loss: 0.00072 | Regression loss: 0.01639 | Running loss: 0.00871\n",
            "Epoch: 45 | Iteration: 309 | Classification loss: 0.00001 | Regression loss: 0.00243 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 310 | Classification loss: 0.00010 | Regression loss: 0.00279 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 311 | Classification loss: 0.00029 | Regression loss: 0.01090 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 312 | Classification loss: 0.00048 | Regression loss: 0.00554 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 313 | Classification loss: 0.00148 | Regression loss: 0.03818 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 314 | Classification loss: 0.00006 | Regression loss: 0.00740 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 315 | Classification loss: 0.00005 | Regression loss: 0.00564 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 316 | Classification loss: 0.00015 | Regression loss: 0.01424 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 317 | Classification loss: 0.00240 | Regression loss: 0.02586 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 318 | Classification loss: 0.00002 | Regression loss: 0.00558 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 319 | Classification loss: 0.00005 | Regression loss: 0.00269 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 320 | Classification loss: 0.00004 | Regression loss: 0.00540 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 321 | Classification loss: 0.00004 | Regression loss: 0.00663 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 322 | Classification loss: 0.00013 | Regression loss: 0.00435 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 323 | Classification loss: 0.00022 | Regression loss: 0.00772 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 324 | Classification loss: 0.00007 | Regression loss: 0.00460 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 325 | Classification loss: 0.00004 | Regression loss: 0.00568 | Running loss: 0.00855\n",
            "Epoch: 45 | Iteration: 326 | Classification loss: 0.00070 | Regression loss: 0.02188 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 327 | Classification loss: 0.00001 | Regression loss: 0.00357 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 328 | Classification loss: 0.00012 | Regression loss: 0.00225 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 329 | Classification loss: 0.00119 | Regression loss: 0.02425 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 330 | Classification loss: 0.00002 | Regression loss: 0.00412 | Running loss: 0.00855\n",
            "Epoch: 45 | Iteration: 331 | Classification loss: 0.00006 | Regression loss: 0.00493 | Running loss: 0.00854\n",
            "Epoch: 45 | Iteration: 332 | Classification loss: 0.00019 | Regression loss: 0.01211 | Running loss: 0.00852\n",
            "Epoch: 45 | Iteration: 333 | Classification loss: 0.00046 | Regression loss: 0.01204 | Running loss: 0.00853\n",
            "Epoch: 45 | Iteration: 334 | Classification loss: 0.00012 | Regression loss: 0.02765 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 335 | Classification loss: 0.00003 | Regression loss: 0.00277 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 336 | Classification loss: 0.00026 | Regression loss: 0.01405 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 337 | Classification loss: 0.00018 | Regression loss: 0.00322 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 338 | Classification loss: 0.00003 | Regression loss: 0.01022 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 339 | Classification loss: 0.00013 | Regression loss: 0.00794 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 340 | Classification loss: 0.00017 | Regression loss: 0.01227 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 341 | Classification loss: 0.00007 | Regression loss: 0.00504 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 342 | Classification loss: 0.00001 | Regression loss: 0.00178 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 343 | Classification loss: 0.00007 | Regression loss: 0.00658 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 344 | Classification loss: 0.00003 | Regression loss: 0.00764 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 345 | Classification loss: 0.00003 | Regression loss: 0.00346 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 346 | Classification loss: 0.00016 | Regression loss: 0.00908 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 347 | Classification loss: 0.00001 | Regression loss: 0.00377 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 348 | Classification loss: 0.00009 | Regression loss: 0.00741 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 349 | Classification loss: 0.00033 | Regression loss: 0.00605 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 350 | Classification loss: 0.00009 | Regression loss: 0.00346 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 351 | Classification loss: 0.00004 | Regression loss: 0.00459 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 352 | Classification loss: 0.00024 | Regression loss: 0.01115 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 353 | Classification loss: 0.00005 | Regression loss: 0.00442 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 354 | Classification loss: 0.00003 | Regression loss: 0.00957 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 355 | Classification loss: 0.00369 | Regression loss: 0.01858 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 356 | Classification loss: 0.00018 | Regression loss: 0.00587 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 357 | Classification loss: 0.00035 | Regression loss: 0.00763 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 358 | Classification loss: 0.00289 | Regression loss: 0.06557 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 359 | Classification loss: 0.00023 | Regression loss: 0.02262 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 360 | Classification loss: 0.00033 | Regression loss: 0.00495 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 361 | Classification loss: 0.00015 | Regression loss: 0.00771 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 362 | Classification loss: 0.00041 | Regression loss: 0.00740 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 363 | Classification loss: 0.00042 | Regression loss: 0.01493 | Running loss: 0.00878\n",
            "Epoch: 45 | Iteration: 364 | Classification loss: 0.00022 | Regression loss: 0.00330 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 365 | Classification loss: 0.00002 | Regression loss: 0.00254 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 366 | Classification loss: 0.00011 | Regression loss: 0.00530 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 367 | Classification loss: 0.00011 | Regression loss: 0.00349 | Running loss: 0.00876\n",
            "Epoch: 45 | Iteration: 368 | Classification loss: 0.00002 | Regression loss: 0.00281 | Running loss: 0.00875\n",
            "Epoch: 45 | Iteration: 369 | Classification loss: 0.00004 | Regression loss: 0.00413 | Running loss: 0.00873\n",
            "Epoch: 45 | Iteration: 370 | Classification loss: 0.00163 | Regression loss: 0.00825 | Running loss: 0.00874\n",
            "Epoch: 45 | Iteration: 371 | Classification loss: 0.00002 | Regression loss: 0.00255 | Running loss: 0.00873\n",
            "Epoch: 45 | Iteration: 372 | Classification loss: 0.00002 | Regression loss: 0.00343 | Running loss: 0.00872\n",
            "Epoch: 45 | Iteration: 373 | Classification loss: 0.00007 | Regression loss: 0.00478 | Running loss: 0.00870\n",
            "Epoch: 45 | Iteration: 374 | Classification loss: 0.00007 | Regression loss: 0.00503 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 375 | Classification loss: 0.00006 | Regression loss: 0.00907 | Running loss: 0.00869\n",
            "Epoch: 45 | Iteration: 376 | Classification loss: 0.00015 | Regression loss: 0.00332 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 377 | Classification loss: 0.00004 | Regression loss: 0.00429 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 378 | Classification loss: 0.00006 | Regression loss: 0.00612 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 379 | Classification loss: 0.00013 | Regression loss: 0.00676 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 380 | Classification loss: 0.00009 | Regression loss: 0.00389 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 381 | Classification loss: 0.00012 | Regression loss: 0.00723 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 382 | Classification loss: 0.00015 | Regression loss: 0.00694 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 383 | Classification loss: 0.00028 | Regression loss: 0.00406 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 384 | Classification loss: 0.00012 | Regression loss: 0.00702 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 385 | Classification loss: 0.00005 | Regression loss: 0.00379 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 386 | Classification loss: 0.00011 | Regression loss: 0.01699 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 387 | Classification loss: 0.00033 | Regression loss: 0.00538 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 388 | Classification loss: 0.00027 | Regression loss: 0.00413 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 389 | Classification loss: 0.00008 | Regression loss: 0.00498 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 390 | Classification loss: 0.00006 | Regression loss: 0.00434 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 391 | Classification loss: 0.00027 | Regression loss: 0.01004 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 392 | Classification loss: 0.00016 | Regression loss: 0.00369 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 393 | Classification loss: 0.00006 | Regression loss: 0.00401 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 394 | Classification loss: 0.00002 | Regression loss: 0.00528 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 395 | Classification loss: 0.00008 | Regression loss: 0.00458 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 396 | Classification loss: 0.00002 | Regression loss: 0.00308 | Running loss: 0.00848\n",
            "Epoch: 45 | Iteration: 397 | Classification loss: 0.00010 | Regression loss: 0.00716 | Running loss: 0.00848\n",
            "Epoch: 45 | Iteration: 398 | Classification loss: 0.00014 | Regression loss: 0.01003 | Running loss: 0.00849\n",
            "Epoch: 45 | Iteration: 399 | Classification loss: 0.00006 | Regression loss: 0.00647 | Running loss: 0.00850\n",
            "Epoch: 45 | Iteration: 400 | Classification loss: 0.00015 | Regression loss: 0.00599 | Running loss: 0.00848\n",
            "Epoch: 45 | Iteration: 401 | Classification loss: 0.00014 | Regression loss: 0.00409 | Running loss: 0.00847\n",
            "Epoch: 45 | Iteration: 402 | Classification loss: 0.00017 | Regression loss: 0.00374 | Running loss: 0.00844\n",
            "Epoch: 45 | Iteration: 403 | Classification loss: 0.00008 | Regression loss: 0.01187 | Running loss: 0.00844\n",
            "Epoch: 45 | Iteration: 404 | Classification loss: 0.00008 | Regression loss: 0.00368 | Running loss: 0.00843\n",
            "Epoch: 45 | Iteration: 405 | Classification loss: 0.00004 | Regression loss: 0.02950 | Running loss: 0.00848\n",
            "Epoch: 45 | Iteration: 406 | Classification loss: 0.00013 | Regression loss: 0.01011 | Running loss: 0.00847\n",
            "Epoch: 45 | Iteration: 407 | Classification loss: 0.00024 | Regression loss: 0.01354 | Running loss: 0.00849\n",
            "Epoch: 45 | Iteration: 408 | Classification loss: 0.00018 | Regression loss: 0.00607 | Running loss: 0.00848\n",
            "Epoch: 45 | Iteration: 409 | Classification loss: 0.00023 | Regression loss: 0.01834 | Running loss: 0.00849\n",
            "Epoch: 45 | Iteration: 410 | Classification loss: 0.00018 | Regression loss: 0.01703 | Running loss: 0.00852\n",
            "Epoch: 45 | Iteration: 411 | Classification loss: 0.00039 | Regression loss: 0.01157 | Running loss: 0.00853\n",
            "Epoch: 45 | Iteration: 412 | Classification loss: 0.00054 | Regression loss: 0.00577 | Running loss: 0.00853\n",
            "Epoch: 45 | Iteration: 413 | Classification loss: 0.00004 | Regression loss: 0.02137 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 414 | Classification loss: 0.00008 | Regression loss: 0.00428 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 415 | Classification loss: 0.00008 | Regression loss: 0.00544 | Running loss: 0.00855\n",
            "Epoch: 45 | Iteration: 416 | Classification loss: 0.00004 | Regression loss: 0.00311 | Running loss: 0.00855\n",
            "Epoch: 45 | Iteration: 417 | Classification loss: 0.00039 | Regression loss: 0.00360 | Running loss: 0.00855\n",
            "Epoch: 45 | Iteration: 418 | Classification loss: 0.00002 | Regression loss: 0.00898 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 419 | Classification loss: 0.00002 | Regression loss: 0.00534 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 420 | Classification loss: 0.00028 | Regression loss: 0.01498 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 421 | Classification loss: 0.00014 | Regression loss: 0.01020 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 422 | Classification loss: 0.00002 | Regression loss: 0.00407 | Running loss: 0.00853\n",
            "Epoch: 45 | Iteration: 423 | Classification loss: 0.00013 | Regression loss: 0.00499 | Running loss: 0.00853\n",
            "Epoch: 45 | Iteration: 424 | Classification loss: 0.00122 | Regression loss: 0.02261 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 425 | Classification loss: 0.00011 | Regression loss: 0.00275 | Running loss: 0.00856\n",
            "Epoch: 45 | Iteration: 426 | Classification loss: 0.00002 | Regression loss: 0.00584 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 427 | Classification loss: 0.00137 | Regression loss: 0.02706 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 428 | Classification loss: 0.00008 | Regression loss: 0.00637 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 429 | Classification loss: 0.00004 | Regression loss: 0.00343 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 430 | Classification loss: 0.00017 | Regression loss: 0.00548 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 431 | Classification loss: 0.00026 | Regression loss: 0.01496 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 432 | Classification loss: 0.00005 | Regression loss: 0.00398 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 433 | Classification loss: 0.00009 | Regression loss: 0.00912 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 434 | Classification loss: 0.00025 | Regression loss: 0.00283 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 435 | Classification loss: 0.00003 | Regression loss: 0.00366 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 436 | Classification loss: 0.00028 | Regression loss: 0.01110 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 437 | Classification loss: 0.00022 | Regression loss: 0.00493 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 438 | Classification loss: 0.00018 | Regression loss: 0.00495 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 439 | Classification loss: 0.00004 | Regression loss: 0.00416 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 440 | Classification loss: 0.00002 | Regression loss: 0.00292 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 441 | Classification loss: 0.00059 | Regression loss: 0.02443 | Running loss: 0.00857\n",
            "Epoch: 45 | Iteration: 442 | Classification loss: 0.00162 | Regression loss: 0.02781 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 443 | Classification loss: 0.00080 | Regression loss: 0.01192 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 444 | Classification loss: 0.00003 | Regression loss: 0.00629 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 445 | Classification loss: 0.00001 | Regression loss: 0.00375 | Running loss: 0.00863\n",
            "Epoch: 45 | Iteration: 446 | Classification loss: 0.00013 | Regression loss: 0.01103 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 447 | Classification loss: 0.00040 | Regression loss: 0.01976 | Running loss: 0.00868\n",
            "Epoch: 45 | Iteration: 448 | Classification loss: 0.00011 | Regression loss: 0.00434 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 449 | Classification loss: 0.00010 | Regression loss: 0.00877 | Running loss: 0.00868\n",
            "Epoch: 45 | Iteration: 450 | Classification loss: 0.00005 | Regression loss: 0.00480 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 451 | Classification loss: 0.00014 | Regression loss: 0.00530 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 452 | Classification loss: 0.00003 | Regression loss: 0.00473 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 453 | Classification loss: 0.00009 | Regression loss: 0.00560 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 454 | Classification loss: 0.00020 | Regression loss: 0.01300 | Running loss: 0.00864\n",
            "Epoch: 45 | Iteration: 455 | Classification loss: 0.00034 | Regression loss: 0.00868 | Running loss: 0.00862\n",
            "Epoch: 45 | Iteration: 456 | Classification loss: 0.00022 | Regression loss: 0.01857 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 457 | Classification loss: 0.00023 | Regression loss: 0.00436 | Running loss: 0.00865\n",
            "Epoch: 45 | Iteration: 458 | Classification loss: 0.00016 | Regression loss: 0.01553 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 459 | Classification loss: 0.00013 | Regression loss: 0.00385 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 460 | Classification loss: 0.00008 | Regression loss: 0.00688 | Running loss: 0.00866\n",
            "Epoch: 45 | Iteration: 461 | Classification loss: 0.00058 | Regression loss: 0.00828 | Running loss: 0.00867\n",
            "Epoch: 45 | Iteration: 462 | Classification loss: 0.00001 | Regression loss: 0.00168 | Running loss: 0.00859\n",
            "Epoch: 45 | Iteration: 463 | Classification loss: 0.00014 | Regression loss: 0.01390 | Running loss: 0.00861\n",
            "Epoch: 45 | Iteration: 464 | Classification loss: 0.00002 | Regression loss: 0.00354 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 465 | Classification loss: 0.00021 | Regression loss: 0.00386 | Running loss: 0.00860\n",
            "Epoch: 45 | Iteration: 466 | Classification loss: 0.00002 | Regression loss: 0.00109 | Running loss: 0.00858\n",
            "Epoch: 45 | Iteration: 467 | Classification loss: 0.00012 | Regression loss: 0.00442 | Running loss: 0.00858\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6697835936800195\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.3429792470362646\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.46668007260543914\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5345824418605432\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.3783783783783784\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 46 | Iteration: 0 | Classification loss: 0.00002 | Regression loss: 0.00500 | Running loss: 0.00858\n",
            "Epoch: 46 | Iteration: 1 | Classification loss: 0.00002 | Regression loss: 0.00652 | Running loss: 0.00858\n",
            "Epoch: 46 | Iteration: 2 | Classification loss: 0.00003 | Regression loss: 0.00393 | Running loss: 0.00858\n",
            "Epoch: 46 | Iteration: 3 | Classification loss: 0.00003 | Regression loss: 0.00401 | Running loss: 0.00857\n",
            "Epoch: 46 | Iteration: 4 | Classification loss: 0.00002 | Regression loss: 0.00253 | Running loss: 0.00856\n",
            "Epoch: 46 | Iteration: 5 | Classification loss: 0.00002 | Regression loss: 0.00351 | Running loss: 0.00856\n",
            "Epoch: 46 | Iteration: 6 | Classification loss: 0.00009 | Regression loss: 0.00563 | Running loss: 0.00856\n",
            "Epoch: 46 | Iteration: 7 | Classification loss: 0.00015 | Regression loss: 0.00767 | Running loss: 0.00857\n",
            "Epoch: 46 | Iteration: 8 | Classification loss: 0.00004 | Regression loss: 0.00427 | Running loss: 0.00856\n",
            "Epoch: 46 | Iteration: 9 | Classification loss: 0.00002 | Regression loss: 0.00300 | Running loss: 0.00850\n",
            "Epoch: 46 | Iteration: 10 | Classification loss: 0.00001 | Regression loss: 0.00374 | Running loss: 0.00850\n",
            "Epoch: 46 | Iteration: 11 | Classification loss: 0.00010 | Regression loss: 0.00193 | Running loss: 0.00848\n",
            "Epoch: 46 | Iteration: 12 | Classification loss: 0.00034 | Regression loss: 0.01519 | Running loss: 0.00850\n",
            "Epoch: 46 | Iteration: 13 | Classification loss: 0.00003 | Regression loss: 0.02560 | Running loss: 0.00853\n",
            "Epoch: 46 | Iteration: 14 | Classification loss: 0.00015 | Regression loss: 0.00753 | Running loss: 0.00853\n",
            "Epoch: 46 | Iteration: 15 | Classification loss: 0.00019 | Regression loss: 0.01263 | Running loss: 0.00854\n",
            "Epoch: 46 | Iteration: 16 | Classification loss: 0.00028 | Regression loss: 0.02390 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 17 | Classification loss: 0.00019 | Regression loss: 0.00690 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 18 | Classification loss: 0.00002 | Regression loss: 0.00264 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 19 | Classification loss: 0.00006 | Regression loss: 0.00827 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 20 | Classification loss: 0.00003 | Regression loss: 0.00279 | Running loss: 0.00846\n",
            "Epoch: 46 | Iteration: 21 | Classification loss: 0.00002 | Regression loss: 0.00274 | Running loss: 0.00846\n",
            "Epoch: 46 | Iteration: 22 | Classification loss: 0.00032 | Regression loss: 0.01271 | Running loss: 0.00845\n",
            "Epoch: 46 | Iteration: 23 | Classification loss: 0.00062 | Regression loss: 0.01369 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 24 | Classification loss: 0.00034 | Regression loss: 0.00803 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 25 | Classification loss: 0.00014 | Regression loss: 0.00510 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 26 | Classification loss: 0.00005 | Regression loss: 0.00743 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 27 | Classification loss: 0.00003 | Regression loss: 0.00443 | Running loss: 0.00845\n",
            "Epoch: 46 | Iteration: 28 | Classification loss: 0.00001 | Regression loss: 0.00243 | Running loss: 0.00845\n",
            "Epoch: 46 | Iteration: 29 | Classification loss: 0.00005 | Regression loss: 0.00566 | Running loss: 0.00845\n",
            "Epoch: 46 | Iteration: 30 | Classification loss: 0.00045 | Regression loss: 0.01311 | Running loss: 0.00847\n",
            "Epoch: 46 | Iteration: 31 | Classification loss: 0.00007 | Regression loss: 0.00491 | Running loss: 0.00841\n",
            "Epoch: 46 | Iteration: 32 | Classification loss: 0.00005 | Regression loss: 0.00332 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 33 | Classification loss: 0.00014 | Regression loss: 0.00440 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 34 | Classification loss: 0.00005 | Regression loss: 0.00359 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 35 | Classification loss: 0.00006 | Regression loss: 0.00414 | Running loss: 0.00840\n",
            "Epoch: 46 | Iteration: 36 | Classification loss: 0.00003 | Regression loss: 0.00370 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 37 | Classification loss: 0.00005 | Regression loss: 0.00215 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 38 | Classification loss: 0.00002 | Regression loss: 0.00537 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 39 | Classification loss: 0.00011 | Regression loss: 0.00244 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 40 | Classification loss: 0.00009 | Regression loss: 0.00359 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 41 | Classification loss: 0.00004 | Regression loss: 0.02891 | Running loss: 0.00842\n",
            "Epoch: 46 | Iteration: 42 | Classification loss: 0.00013 | Regression loss: 0.00520 | Running loss: 0.00842\n",
            "Epoch: 46 | Iteration: 43 | Classification loss: 0.00016 | Regression loss: 0.00326 | Running loss: 0.00841\n",
            "Epoch: 46 | Iteration: 44 | Classification loss: 0.00006 | Regression loss: 0.00367 | Running loss: 0.00841\n",
            "Epoch: 46 | Iteration: 45 | Classification loss: 0.00006 | Regression loss: 0.00401 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 46 | Classification loss: 0.00007 | Regression loss: 0.00415 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 47 | Classification loss: 0.00016 | Regression loss: 0.00655 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 48 | Classification loss: 0.00008 | Regression loss: 0.00219 | Running loss: 0.00827\n",
            "Epoch: 46 | Iteration: 49 | Classification loss: 0.00012 | Regression loss: 0.00283 | Running loss: 0.00827\n",
            "Epoch: 46 | Iteration: 50 | Classification loss: 0.00078 | Regression loss: 0.01054 | Running loss: 0.00828\n",
            "Epoch: 46 | Iteration: 51 | Classification loss: 0.00005 | Regression loss: 0.00315 | Running loss: 0.00828\n",
            "Epoch: 46 | Iteration: 52 | Classification loss: 0.00013 | Regression loss: 0.01068 | Running loss: 0.00829\n",
            "Epoch: 46 | Iteration: 53 | Classification loss: 0.00012 | Regression loss: 0.00830 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 54 | Classification loss: 0.00006 | Regression loss: 0.00483 | Running loss: 0.00828\n",
            "Epoch: 46 | Iteration: 55 | Classification loss: 0.00014 | Regression loss: 0.00261 | Running loss: 0.00829\n",
            "Epoch: 46 | Iteration: 56 | Classification loss: 0.00003 | Regression loss: 0.00194 | Running loss: 0.00828\n",
            "Epoch: 46 | Iteration: 57 | Classification loss: 0.00007 | Regression loss: 0.00917 | Running loss: 0.00829\n",
            "Epoch: 46 | Iteration: 58 | Classification loss: 0.00146 | Regression loss: 0.01503 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 59 | Classification loss: 0.00006 | Regression loss: 0.00530 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 60 | Classification loss: 0.00012 | Regression loss: 0.01180 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 61 | Classification loss: 0.00028 | Regression loss: 0.02509 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 62 | Classification loss: 0.00003 | Regression loss: 0.00217 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 63 | Classification loss: 0.00023 | Regression loss: 0.00522 | Running loss: 0.00834\n",
            "Epoch: 46 | Iteration: 64 | Classification loss: 0.00016 | Regression loss: 0.01342 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 65 | Classification loss: 0.00010 | Regression loss: 0.00543 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 66 | Classification loss: 0.00011 | Regression loss: 0.00204 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 67 | Classification loss: 0.00007 | Regression loss: 0.00673 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 68 | Classification loss: 0.00019 | Regression loss: 0.01108 | Running loss: 0.00834\n",
            "Epoch: 46 | Iteration: 69 | Classification loss: 0.00018 | Regression loss: 0.00531 | Running loss: 0.00834\n",
            "Epoch: 46 | Iteration: 70 | Classification loss: 0.00009 | Regression loss: 0.00270 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 71 | Classification loss: 0.00002 | Regression loss: 0.00656 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 72 | Classification loss: 0.00002 | Regression loss: 0.00269 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 73 | Classification loss: 0.00018 | Regression loss: 0.00461 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 74 | Classification loss: 0.00009 | Regression loss: 0.00382 | Running loss: 0.00829\n",
            "Epoch: 46 | Iteration: 75 | Classification loss: 0.00006 | Regression loss: 0.02817 | Running loss: 0.00834\n",
            "Epoch: 46 | Iteration: 76 | Classification loss: 0.00007 | Regression loss: 0.00414 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 77 | Classification loss: 0.00011 | Regression loss: 0.01289 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 78 | Classification loss: 0.00002 | Regression loss: 0.00482 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 79 | Classification loss: 0.00019 | Regression loss: 0.00572 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 80 | Classification loss: 0.00010 | Regression loss: 0.00815 | Running loss: 0.00834\n",
            "Epoch: 46 | Iteration: 81 | Classification loss: 0.00013 | Regression loss: 0.00907 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 82 | Classification loss: 0.00021 | Regression loss: 0.00874 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 83 | Classification loss: 0.00015 | Regression loss: 0.00522 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 84 | Classification loss: 0.00005 | Regression loss: 0.00657 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 85 | Classification loss: 0.00003 | Regression loss: 0.02631 | Running loss: 0.00840\n",
            "Epoch: 46 | Iteration: 86 | Classification loss: 0.00003 | Regression loss: 0.00416 | Running loss: 0.00840\n",
            "Epoch: 46 | Iteration: 87 | Classification loss: 0.00017 | Regression loss: 0.01779 | Running loss: 0.00842\n",
            "Epoch: 46 | Iteration: 88 | Classification loss: 0.00019 | Regression loss: 0.00569 | Running loss: 0.00842\n",
            "Epoch: 46 | Iteration: 89 | Classification loss: 0.00028 | Regression loss: 0.01208 | Running loss: 0.00843\n",
            "Epoch: 46 | Iteration: 90 | Classification loss: 0.00009 | Regression loss: 0.00331 | Running loss: 0.00843\n",
            "Epoch: 46 | Iteration: 91 | Classification loss: 0.00004 | Regression loss: 0.00639 | Running loss: 0.00843\n",
            "Epoch: 46 | Iteration: 92 | Classification loss: 0.00008 | Regression loss: 0.01000 | Running loss: 0.00844\n",
            "Epoch: 46 | Iteration: 93 | Classification loss: 0.00112 | Regression loss: 0.02531 | Running loss: 0.00849\n",
            "Epoch: 46 | Iteration: 94 | Classification loss: 0.00014 | Regression loss: 0.01127 | Running loss: 0.00851\n",
            "Epoch: 46 | Iteration: 95 | Classification loss: 0.00068 | Regression loss: 0.00622 | Running loss: 0.00851\n",
            "Epoch: 46 | Iteration: 96 | Classification loss: 0.00018 | Regression loss: 0.00526 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 97 | Classification loss: 0.00005 | Regression loss: 0.00718 | Running loss: 0.00851\n",
            "Epoch: 46 | Iteration: 98 | Classification loss: 0.00109 | Regression loss: 0.01248 | Running loss: 0.00853\n",
            "Epoch: 46 | Iteration: 99 | Classification loss: 0.00012 | Regression loss: 0.00212 | Running loss: 0.00851\n",
            "Epoch: 46 | Iteration: 100 | Classification loss: 0.00027 | Regression loss: 0.00468 | Running loss: 0.00851\n",
            "Epoch: 46 | Iteration: 101 | Classification loss: 0.00018 | Regression loss: 0.00485 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 102 | Classification loss: 0.00013 | Regression loss: 0.00239 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 103 | Classification loss: 0.00014 | Regression loss: 0.00720 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 104 | Classification loss: 0.00001 | Regression loss: 0.00169 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 105 | Classification loss: 0.00052 | Regression loss: 0.00493 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 106 | Classification loss: 0.00038 | Regression loss: 0.00975 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 107 | Classification loss: 0.00002 | Regression loss: 0.00259 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 108 | Classification loss: 0.00004 | Regression loss: 0.00873 | Running loss: 0.00853\n",
            "Epoch: 46 | Iteration: 109 | Classification loss: 0.00030 | Regression loss: 0.00387 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 110 | Classification loss: 0.00113 | Regression loss: 0.06440 | Running loss: 0.00864\n",
            "Epoch: 46 | Iteration: 111 | Classification loss: 0.00023 | Regression loss: 0.01180 | Running loss: 0.00866\n",
            "Epoch: 46 | Iteration: 112 | Classification loss: 0.00022 | Regression loss: 0.02562 | Running loss: 0.00871\n",
            "Epoch: 46 | Iteration: 113 | Classification loss: 0.00014 | Regression loss: 0.00969 | Running loss: 0.00872\n",
            "Epoch: 46 | Iteration: 114 | Classification loss: 0.00005 | Regression loss: 0.00566 | Running loss: 0.00871\n",
            "Epoch: 46 | Iteration: 115 | Classification loss: 0.00005 | Regression loss: 0.00335 | Running loss: 0.00871\n",
            "Epoch: 46 | Iteration: 116 | Classification loss: 0.00001 | Regression loss: 0.00491 | Running loss: 0.00871\n",
            "Epoch: 46 | Iteration: 117 | Classification loss: 0.00014 | Regression loss: 0.01408 | Running loss: 0.00872\n",
            "Epoch: 46 | Iteration: 118 | Classification loss: 0.00015 | Regression loss: 0.00329 | Running loss: 0.00870\n",
            "Epoch: 46 | Iteration: 119 | Classification loss: 0.00017 | Regression loss: 0.00338 | Running loss: 0.00870\n",
            "Epoch: 46 | Iteration: 120 | Classification loss: 0.00005 | Regression loss: 0.00396 | Running loss: 0.00870\n",
            "Epoch: 46 | Iteration: 121 | Classification loss: 0.00092 | Regression loss: 0.02331 | Running loss: 0.00873\n",
            "Epoch: 46 | Iteration: 122 | Classification loss: 0.00026 | Regression loss: 0.00764 | Running loss: 0.00871\n",
            "Epoch: 46 | Iteration: 123 | Classification loss: 0.00013 | Regression loss: 0.01192 | Running loss: 0.00872\n",
            "Epoch: 46 | Iteration: 124 | Classification loss: 0.00027 | Regression loss: 0.01222 | Running loss: 0.00869\n",
            "Epoch: 46 | Iteration: 125 | Classification loss: 0.00036 | Regression loss: 0.00647 | Running loss: 0.00864\n",
            "Epoch: 46 | Iteration: 126 | Classification loss: 0.00008 | Regression loss: 0.00413 | Running loss: 0.00865\n",
            "Epoch: 46 | Iteration: 127 | Classification loss: 0.00020 | Regression loss: 0.00228 | Running loss: 0.00864\n",
            "Epoch: 46 | Iteration: 128 | Classification loss: 0.00019 | Regression loss: 0.01023 | Running loss: 0.00864\n",
            "Epoch: 46 | Iteration: 129 | Classification loss: 0.00006 | Regression loss: 0.00771 | Running loss: 0.00863\n",
            "Epoch: 46 | Iteration: 130 | Classification loss: 0.00001 | Regression loss: 0.00246 | Running loss: 0.00863\n",
            "Epoch: 46 | Iteration: 131 | Classification loss: 0.00002 | Regression loss: 0.00573 | Running loss: 0.00861\n",
            "Epoch: 46 | Iteration: 132 | Classification loss: 0.00050 | Regression loss: 0.01369 | Running loss: 0.00858\n",
            "Epoch: 46 | Iteration: 133 | Classification loss: 0.00004 | Regression loss: 0.00241 | Running loss: 0.00857\n",
            "Epoch: 46 | Iteration: 134 | Classification loss: 0.00033 | Regression loss: 0.00568 | Running loss: 0.00857\n",
            "Epoch: 46 | Iteration: 135 | Classification loss: 0.00002 | Regression loss: 0.00157 | Running loss: 0.00857\n",
            "Epoch: 46 | Iteration: 136 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00855\n",
            "Epoch: 46 | Iteration: 137 | Classification loss: 0.00009 | Regression loss: 0.00746 | Running loss: 0.00855\n",
            "Epoch: 46 | Iteration: 138 | Classification loss: 0.00034 | Regression loss: 0.02767 | Running loss: 0.00851\n",
            "Epoch: 46 | Iteration: 139 | Classification loss: 0.00021 | Regression loss: 0.01001 | Running loss: 0.00852\n",
            "Epoch: 46 | Iteration: 140 | Classification loss: 0.00141 | Regression loss: 0.02993 | Running loss: 0.00848\n",
            "Epoch: 46 | Iteration: 141 | Classification loss: 0.00009 | Regression loss: 0.00343 | Running loss: 0.00844\n",
            "Epoch: 46 | Iteration: 142 | Classification loss: 0.00014 | Regression loss: 0.01083 | Running loss: 0.00845\n",
            "Epoch: 46 | Iteration: 143 | Classification loss: 0.00011 | Regression loss: 0.00559 | Running loss: 0.00841\n",
            "Epoch: 46 | Iteration: 144 | Classification loss: 0.00016 | Regression loss: 0.00374 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 145 | Classification loss: 0.00004 | Regression loss: 0.00635 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 146 | Classification loss: 0.00003 | Regression loss: 0.00450 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 147 | Classification loss: 0.00030 | Regression loss: 0.00372 | Running loss: 0.00840\n",
            "Epoch: 46 | Iteration: 148 | Classification loss: 0.00001 | Regression loss: 0.00291 | Running loss: 0.00839\n",
            "Epoch: 46 | Iteration: 149 | Classification loss: 0.00003 | Regression loss: 0.00359 | Running loss: 0.00838\n",
            "Epoch: 46 | Iteration: 150 | Classification loss: 0.00014 | Regression loss: 0.00365 | Running loss: 0.00837\n",
            "Epoch: 46 | Iteration: 151 | Classification loss: 0.00021 | Regression loss: 0.00258 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 152 | Classification loss: 0.00028 | Regression loss: 0.00397 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 153 | Classification loss: 0.00016 | Regression loss: 0.00351 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 154 | Classification loss: 0.00044 | Regression loss: 0.00488 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 155 | Classification loss: 0.00007 | Regression loss: 0.00336 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 156 | Classification loss: 0.00002 | Regression loss: 0.00186 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 157 | Classification loss: 0.00007 | Regression loss: 0.00364 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 158 | Classification loss: 0.00004 | Regression loss: 0.00238 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 159 | Classification loss: 0.00004 | Regression loss: 0.00427 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 160 | Classification loss: 0.00002 | Regression loss: 0.00273 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 161 | Classification loss: 0.00012 | Regression loss: 0.00353 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 162 | Classification loss: 0.00014 | Regression loss: 0.00129 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 163 | Classification loss: 0.00466 | Regression loss: 0.04679 | Running loss: 0.00840\n",
            "Epoch: 46 | Iteration: 164 | Classification loss: 0.00039 | Regression loss: 0.01496 | Running loss: 0.00842\n",
            "Epoch: 46 | Iteration: 165 | Classification loss: 0.00063 | Regression loss: 0.00526 | Running loss: 0.00842\n",
            "Epoch: 46 | Iteration: 166 | Classification loss: 0.00006 | Regression loss: 0.00563 | Running loss: 0.00843\n",
            "Epoch: 46 | Iteration: 167 | Classification loss: 0.00011 | Regression loss: 0.00627 | Running loss: 0.00838\n",
            "Epoch: 46 | Iteration: 168 | Classification loss: 0.00004 | Regression loss: 0.00320 | Running loss: 0.00836\n",
            "Epoch: 46 | Iteration: 169 | Classification loss: 0.00003 | Regression loss: 0.00283 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 170 | Classification loss: 0.00034 | Regression loss: 0.00409 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 171 | Classification loss: 0.00001 | Regression loss: 0.00279 | Running loss: 0.00834\n",
            "Epoch: 46 | Iteration: 172 | Classification loss: 0.00018 | Regression loss: 0.00271 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 173 | Classification loss: 0.00013 | Regression loss: 0.00125 | Running loss: 0.00827\n",
            "Epoch: 46 | Iteration: 174 | Classification loss: 0.00004 | Regression loss: 0.00329 | Running loss: 0.00824\n",
            "Epoch: 46 | Iteration: 175 | Classification loss: 0.00005 | Regression loss: 0.00363 | Running loss: 0.00823\n",
            "Epoch: 46 | Iteration: 176 | Classification loss: 0.00017 | Regression loss: 0.00635 | Running loss: 0.00823\n",
            "Epoch: 46 | Iteration: 177 | Classification loss: 0.00033 | Regression loss: 0.00563 | Running loss: 0.00823\n",
            "Epoch: 46 | Iteration: 178 | Classification loss: 0.00004 | Regression loss: 0.00293 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 179 | Classification loss: 0.00007 | Regression loss: 0.00386 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 180 | Classification loss: 0.00019 | Regression loss: 0.01013 | Running loss: 0.00821\n",
            "Epoch: 46 | Iteration: 181 | Classification loss: 0.00048 | Regression loss: 0.00524 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 182 | Classification loss: 0.00004 | Regression loss: 0.00496 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 183 | Classification loss: 0.00007 | Regression loss: 0.00520 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 184 | Classification loss: 0.00002 | Regression loss: 0.00753 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 185 | Classification loss: 0.00010 | Regression loss: 0.00856 | Running loss: 0.00821\n",
            "Epoch: 46 | Iteration: 186 | Classification loss: 0.00002 | Regression loss: 0.00543 | Running loss: 0.00821\n",
            "Epoch: 46 | Iteration: 187 | Classification loss: 0.00006 | Regression loss: 0.00344 | Running loss: 0.00821\n",
            "Epoch: 46 | Iteration: 188 | Classification loss: 0.00006 | Regression loss: 0.00417 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 189 | Classification loss: 0.00010 | Regression loss: 0.00553 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 190 | Classification loss: 0.00012 | Regression loss: 0.00579 | Running loss: 0.00812\n",
            "Epoch: 46 | Iteration: 191 | Classification loss: 0.00168 | Regression loss: 0.05300 | Running loss: 0.00822\n",
            "Epoch: 46 | Iteration: 192 | Classification loss: 0.00012 | Regression loss: 0.00390 | Running loss: 0.00821\n",
            "Epoch: 46 | Iteration: 193 | Classification loss: 0.00016 | Regression loss: 0.05389 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 194 | Classification loss: 0.00013 | Regression loss: 0.00972 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 195 | Classification loss: 0.00008 | Regression loss: 0.00259 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 196 | Classification loss: 0.00003 | Regression loss: 0.00601 | Running loss: 0.00828\n",
            "Epoch: 46 | Iteration: 197 | Classification loss: 0.00009 | Regression loss: 0.02299 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 198 | Classification loss: 0.00001 | Regression loss: 0.00338 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 199 | Classification loss: 0.00003 | Regression loss: 0.00289 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 200 | Classification loss: 0.00011 | Regression loss: 0.00381 | Running loss: 0.00829\n",
            "Epoch: 46 | Iteration: 201 | Classification loss: 0.00001 | Regression loss: 0.00895 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 202 | Classification loss: 0.00001 | Regression loss: 0.00323 | Running loss: 0.00831\n",
            "Epoch: 46 | Iteration: 203 | Classification loss: 0.00001 | Regression loss: 0.00359 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 204 | Classification loss: 0.00022 | Regression loss: 0.00393 | Running loss: 0.00830\n",
            "Epoch: 46 | Iteration: 205 | Classification loss: 0.00014 | Regression loss: 0.00932 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 206 | Classification loss: 0.00009 | Regression loss: 0.00969 | Running loss: 0.00832\n",
            "Epoch: 46 | Iteration: 207 | Classification loss: 0.00011 | Regression loss: 0.00860 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 208 | Classification loss: 0.00000 | Regression loss: 0.00371 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 209 | Classification loss: 0.00007 | Regression loss: 0.00976 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 210 | Classification loss: 0.00007 | Regression loss: 0.00308 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 211 | Classification loss: 0.00012 | Regression loss: 0.00518 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 212 | Classification loss: 0.00003 | Regression loss: 0.00358 | Running loss: 0.00833\n",
            "Epoch: 46 | Iteration: 213 | Classification loss: 0.00048 | Regression loss: 0.01121 | Running loss: 0.00835\n",
            "Epoch: 46 | Iteration: 214 | Classification loss: 0.00007 | Regression loss: 0.00301 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 215 | Classification loss: 0.00009 | Regression loss: 0.00810 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 216 | Classification loss: 0.00013 | Regression loss: 0.00565 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 217 | Classification loss: 0.00008 | Regression loss: 0.00541 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 218 | Classification loss: 0.00004 | Regression loss: 0.00432 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 219 | Classification loss: 0.00006 | Regression loss: 0.00246 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 220 | Classification loss: 0.00021 | Regression loss: 0.00383 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 221 | Classification loss: 0.00003 | Regression loss: 0.01955 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 222 | Classification loss: 0.00018 | Regression loss: 0.00373 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 223 | Classification loss: 0.00016 | Regression loss: 0.00353 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 224 | Classification loss: 0.00002 | Regression loss: 0.00483 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 225 | Classification loss: 0.00004 | Regression loss: 0.00695 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 226 | Classification loss: 0.00003 | Regression loss: 0.00369 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 227 | Classification loss: 0.00041 | Regression loss: 0.01136 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 228 | Classification loss: 0.00030 | Regression loss: 0.01323 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 229 | Classification loss: 0.00004 | Regression loss: 0.00336 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 230 | Classification loss: 0.00018 | Regression loss: 0.00427 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 231 | Classification loss: 0.00054 | Regression loss: 0.01737 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 232 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 233 | Classification loss: 0.00014 | Regression loss: 0.00525 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 234 | Classification loss: 0.00009 | Regression loss: 0.00418 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 235 | Classification loss: 0.00001 | Regression loss: 0.00900 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 236 | Classification loss: 0.00040 | Regression loss: 0.00538 | Running loss: 0.00819\n",
            "Epoch: 46 | Iteration: 237 | Classification loss: 0.00006 | Regression loss: 0.00497 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 238 | Classification loss: 0.00003 | Regression loss: 0.00387 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 239 | Classification loss: 0.00025 | Regression loss: 0.01026 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 240 | Classification loss: 0.00024 | Regression loss: 0.00576 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 241 | Classification loss: 0.00006 | Regression loss: 0.00340 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 242 | Classification loss: 0.00051 | Regression loss: 0.01546 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 243 | Classification loss: 0.00022 | Regression loss: 0.00771 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 244 | Classification loss: 0.00014 | Regression loss: 0.00382 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 245 | Classification loss: 0.00001 | Regression loss: 0.00295 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 246 | Classification loss: 0.00002 | Regression loss: 0.00437 | Running loss: 0.00811\n",
            "Epoch: 46 | Iteration: 247 | Classification loss: 0.00004 | Regression loss: 0.00719 | Running loss: 0.00812\n",
            "Epoch: 46 | Iteration: 248 | Classification loss: 0.00060 | Regression loss: 0.01096 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 249 | Classification loss: 0.00014 | Regression loss: 0.00391 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 250 | Classification loss: 0.00008 | Regression loss: 0.00421 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 251 | Classification loss: 0.00004 | Regression loss: 0.00345 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 252 | Classification loss: 0.00010 | Regression loss: 0.00605 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 253 | Classification loss: 0.00008 | Regression loss: 0.00408 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 254 | Classification loss: 0.00005 | Regression loss: 0.00436 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 255 | Classification loss: 0.00027 | Regression loss: 0.00655 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 256 | Classification loss: 0.00052 | Regression loss: 0.01756 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 257 | Classification loss: 0.00008 | Regression loss: 0.00306 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 258 | Classification loss: 0.00007 | Regression loss: 0.00282 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 259 | Classification loss: 0.00019 | Regression loss: 0.00495 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 260 | Classification loss: 0.00019 | Regression loss: 0.01528 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 261 | Classification loss: 0.00085 | Regression loss: 0.01671 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 262 | Classification loss: 0.00003 | Regression loss: 0.00356 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 263 | Classification loss: 0.00020 | Regression loss: 0.01682 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 264 | Classification loss: 0.00025 | Regression loss: 0.00432 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 265 | Classification loss: 0.00003 | Regression loss: 0.00490 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 266 | Classification loss: 0.00091 | Regression loss: 0.00431 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 267 | Classification loss: 0.00012 | Regression loss: 0.00290 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 268 | Classification loss: 0.00024 | Regression loss: 0.00652 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 269 | Classification loss: 0.00011 | Regression loss: 0.00328 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 270 | Classification loss: 0.00001 | Regression loss: 0.00210 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 271 | Classification loss: 0.00009 | Regression loss: 0.00371 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 272 | Classification loss: 0.00010 | Regression loss: 0.01106 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 273 | Classification loss: 0.00011 | Regression loss: 0.00728 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 274 | Classification loss: 0.00016 | Regression loss: 0.00489 | Running loss: 0.00810\n",
            "Epoch: 46 | Iteration: 275 | Classification loss: 0.00012 | Regression loss: 0.00329 | Running loss: 0.00806\n",
            "Epoch: 46 | Iteration: 276 | Classification loss: 0.00001 | Regression loss: 0.00404 | Running loss: 0.00806\n",
            "Epoch: 46 | Iteration: 277 | Classification loss: 0.00004 | Regression loss: 0.00456 | Running loss: 0.00806\n",
            "Epoch: 46 | Iteration: 278 | Classification loss: 0.00001 | Regression loss: 0.00268 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 279 | Classification loss: 0.00240 | Regression loss: 0.06035 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 280 | Classification loss: 0.00009 | Regression loss: 0.00361 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 281 | Classification loss: 0.00024 | Regression loss: 0.01160 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 282 | Classification loss: 0.00005 | Regression loss: 0.01109 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 283 | Classification loss: 0.00009 | Regression loss: 0.00568 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 284 | Classification loss: 0.00009 | Regression loss: 0.01158 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 285 | Classification loss: 0.00005 | Regression loss: 0.00335 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 286 | Classification loss: 0.00007 | Regression loss: 0.01270 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 287 | Classification loss: 0.00001 | Regression loss: 0.00377 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 288 | Classification loss: 0.00002 | Regression loss: 0.00385 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 289 | Classification loss: 0.00012 | Regression loss: 0.01017 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 290 | Classification loss: 0.00002 | Regression loss: 0.00358 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 291 | Classification loss: 0.00026 | Regression loss: 0.00442 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 292 | Classification loss: 0.00022 | Regression loss: 0.00362 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 293 | Classification loss: 0.00006 | Regression loss: 0.00633 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 294 | Classification loss: 0.00061 | Regression loss: 0.01849 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 295 | Classification loss: 0.00004 | Regression loss: 0.00360 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 296 | Classification loss: 0.00030 | Regression loss: 0.00953 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 297 | Classification loss: 0.00019 | Regression loss: 0.00824 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 298 | Classification loss: 0.00006 | Regression loss: 0.00575 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 299 | Classification loss: 0.00006 | Regression loss: 0.00502 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 300 | Classification loss: 0.00006 | Regression loss: 0.00370 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 301 | Classification loss: 0.00002 | Regression loss: 0.00234 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 302 | Classification loss: 0.00018 | Regression loss: 0.00317 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 303 | Classification loss: 0.00006 | Regression loss: 0.00341 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 304 | Classification loss: 0.00004 | Regression loss: 0.00248 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 305 | Classification loss: 0.00026 | Regression loss: 0.00436 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 306 | Classification loss: 0.00002 | Regression loss: 0.00371 | Running loss: 0.00814\n",
            "Epoch: 46 | Iteration: 307 | Classification loss: 0.00013 | Regression loss: 0.00529 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 308 | Classification loss: 0.00004 | Regression loss: 0.00345 | Running loss: 0.00812\n",
            "Epoch: 46 | Iteration: 309 | Classification loss: 0.00022 | Regression loss: 0.07866 | Running loss: 0.00826\n",
            "Epoch: 46 | Iteration: 310 | Classification loss: 0.00023 | Regression loss: 0.00483 | Running loss: 0.00825\n",
            "Epoch: 46 | Iteration: 311 | Classification loss: 0.00001 | Regression loss: 0.00285 | Running loss: 0.00824\n",
            "Epoch: 46 | Iteration: 312 | Classification loss: 0.00023 | Regression loss: 0.01055 | Running loss: 0.00824\n",
            "Epoch: 46 | Iteration: 313 | Classification loss: 0.00011 | Regression loss: 0.00664 | Running loss: 0.00824\n",
            "Epoch: 46 | Iteration: 314 | Classification loss: 0.00036 | Regression loss: 0.00525 | Running loss: 0.00825\n",
            "Epoch: 46 | Iteration: 315 | Classification loss: 0.00007 | Regression loss: 0.00549 | Running loss: 0.00825\n",
            "Epoch: 46 | Iteration: 316 | Classification loss: 0.00012 | Regression loss: 0.00963 | Running loss: 0.00824\n",
            "Epoch: 46 | Iteration: 317 | Classification loss: 0.00013 | Regression loss: 0.01445 | Running loss: 0.00826\n",
            "Epoch: 46 | Iteration: 318 | Classification loss: 0.00002 | Regression loss: 0.00342 | Running loss: 0.00826\n",
            "Epoch: 46 | Iteration: 319 | Classification loss: 0.00022 | Regression loss: 0.00310 | Running loss: 0.00825\n",
            "Epoch: 46 | Iteration: 320 | Classification loss: 0.00020 | Regression loss: 0.00530 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 321 | Classification loss: 0.00009 | Regression loss: 0.00560 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 322 | Classification loss: 0.00002 | Regression loss: 0.00217 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 323 | Classification loss: 0.00075 | Regression loss: 0.00398 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 324 | Classification loss: 0.00005 | Regression loss: 0.00230 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 325 | Classification loss: 0.00010 | Regression loss: 0.00598 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 326 | Classification loss: 0.00011 | Regression loss: 0.00588 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 327 | Classification loss: 0.00068 | Regression loss: 0.01816 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 328 | Classification loss: 0.00021 | Regression loss: 0.00984 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 329 | Classification loss: 0.00004 | Regression loss: 0.00392 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 330 | Classification loss: 0.00008 | Regression loss: 0.00741 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 331 | Classification loss: 0.00006 | Regression loss: 0.00566 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 332 | Classification loss: 0.00024 | Regression loss: 0.00871 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 333 | Classification loss: 0.00005 | Regression loss: 0.00276 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 334 | Classification loss: 0.00005 | Regression loss: 0.00329 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 335 | Classification loss: 0.00004 | Regression loss: 0.00222 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 336 | Classification loss: 0.00049 | Regression loss: 0.01308 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 337 | Classification loss: 0.00007 | Regression loss: 0.00592 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 338 | Classification loss: 0.00014 | Regression loss: 0.00533 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 339 | Classification loss: 0.00021 | Regression loss: 0.01237 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 340 | Classification loss: 0.00009 | Regression loss: 0.01578 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 341 | Classification loss: 0.00014 | Regression loss: 0.00449 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 342 | Classification loss: 0.00049 | Regression loss: 0.00831 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 343 | Classification loss: 0.00004 | Regression loss: 0.01599 | Running loss: 0.00821\n",
            "Epoch: 46 | Iteration: 344 | Classification loss: 0.00008 | Regression loss: 0.00477 | Running loss: 0.00820\n",
            "Epoch: 46 | Iteration: 345 | Classification loss: 0.00210 | Regression loss: 0.02207 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 346 | Classification loss: 0.00002 | Regression loss: 0.00221 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 347 | Classification loss: 0.00010 | Regression loss: 0.00234 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 348 | Classification loss: 0.00076 | Regression loss: 0.01355 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 349 | Classification loss: 0.00006 | Regression loss: 0.00406 | Running loss: 0.00811\n",
            "Epoch: 46 | Iteration: 350 | Classification loss: 0.00025 | Regression loss: 0.04081 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 351 | Classification loss: 0.00009 | Regression loss: 0.00238 | Running loss: 0.00818\n",
            "Epoch: 46 | Iteration: 352 | Classification loss: 0.00002 | Regression loss: 0.00317 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 353 | Classification loss: 0.00001 | Regression loss: 0.00320 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 354 | Classification loss: 0.00004 | Regression loss: 0.00260 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 355 | Classification loss: 0.00017 | Regression loss: 0.00220 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 356 | Classification loss: 0.00010 | Regression loss: 0.01060 | Running loss: 0.00816\n",
            "Epoch: 46 | Iteration: 357 | Classification loss: 0.00017 | Regression loss: 0.00731 | Running loss: 0.00817\n",
            "Epoch: 46 | Iteration: 358 | Classification loss: 0.00001 | Regression loss: 0.00239 | Running loss: 0.00813\n",
            "Epoch: 46 | Iteration: 359 | Classification loss: 0.00022 | Regression loss: 0.01524 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 360 | Classification loss: 0.00020 | Regression loss: 0.00303 | Running loss: 0.00815\n",
            "Epoch: 46 | Iteration: 361 | Classification loss: 0.00005 | Regression loss: 0.00202 | Running loss: 0.00811\n",
            "Epoch: 46 | Iteration: 362 | Classification loss: 0.00106 | Regression loss: 0.00468 | Running loss: 0.00811\n",
            "Epoch: 46 | Iteration: 363 | Classification loss: 0.00006 | Regression loss: 0.00331 | Running loss: 0.00811\n",
            "Epoch: 46 | Iteration: 364 | Classification loss: 0.00004 | Regression loss: 0.00272 | Running loss: 0.00809\n",
            "Epoch: 46 | Iteration: 365 | Classification loss: 0.00009 | Regression loss: 0.00611 | Running loss: 0.00807\n",
            "Epoch: 46 | Iteration: 366 | Classification loss: 0.00011 | Regression loss: 0.00798 | Running loss: 0.00803\n",
            "Epoch: 46 | Iteration: 367 | Classification loss: 0.00008 | Regression loss: 0.00722 | Running loss: 0.00804\n",
            "Epoch: 46 | Iteration: 368 | Classification loss: 0.00097 | Regression loss: 0.02209 | Running loss: 0.00806\n",
            "Epoch: 46 | Iteration: 369 | Classification loss: 0.00021 | Regression loss: 0.01289 | Running loss: 0.00808\n",
            "Epoch: 46 | Iteration: 370 | Classification loss: 0.00026 | Regression loss: 0.00733 | Running loss: 0.00808\n",
            "Epoch: 46 | Iteration: 371 | Classification loss: 0.00002 | Regression loss: 0.00209 | Running loss: 0.00806\n",
            "Epoch: 46 | Iteration: 372 | Classification loss: 0.00023 | Regression loss: 0.00446 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 373 | Classification loss: 0.00006 | Regression loss: 0.00438 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 374 | Classification loss: 0.00006 | Regression loss: 0.00253 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 375 | Classification loss: 0.00002 | Regression loss: 0.00282 | Running loss: 0.00804\n",
            "Epoch: 46 | Iteration: 376 | Classification loss: 0.00004 | Regression loss: 0.00786 | Running loss: 0.00804\n",
            "Epoch: 46 | Iteration: 377 | Classification loss: 0.00007 | Regression loss: 0.00358 | Running loss: 0.00804\n",
            "Epoch: 46 | Iteration: 378 | Classification loss: 0.00097 | Regression loss: 0.02416 | Running loss: 0.00807\n",
            "Epoch: 46 | Iteration: 379 | Classification loss: 0.00013 | Regression loss: 0.00657 | Running loss: 0.00808\n",
            "Epoch: 46 | Iteration: 380 | Classification loss: 0.00004 | Regression loss: 0.00406 | Running loss: 0.00807\n",
            "Epoch: 46 | Iteration: 381 | Classification loss: 0.00016 | Regression loss: 0.00408 | Running loss: 0.00807\n",
            "Epoch: 46 | Iteration: 382 | Classification loss: 0.00002 | Regression loss: 0.00419 | Running loss: 0.00807\n",
            "Epoch: 46 | Iteration: 383 | Classification loss: 0.00004 | Regression loss: 0.00519 | Running loss: 0.00807\n",
            "Epoch: 46 | Iteration: 384 | Classification loss: 0.00002 | Regression loss: 0.00351 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 385 | Classification loss: 0.00005 | Regression loss: 0.00317 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 386 | Classification loss: 0.00002 | Regression loss: 0.00506 | Running loss: 0.00804\n",
            "Epoch: 46 | Iteration: 387 | Classification loss: 0.00058 | Regression loss: 0.02443 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 388 | Classification loss: 0.00006 | Regression loss: 0.00664 | Running loss: 0.00805\n",
            "Epoch: 46 | Iteration: 389 | Classification loss: 0.00001 | Regression loss: 0.00329 | Running loss: 0.00804\n",
            "Epoch: 46 | Iteration: 390 | Classification loss: 0.00006 | Regression loss: 0.00358 | Running loss: 0.00791\n",
            "Epoch: 46 | Iteration: 391 | Classification loss: 0.00023 | Regression loss: 0.00440 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 392 | Classification loss: 0.00001 | Regression loss: 0.00182 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 393 | Classification loss: 0.00012 | Regression loss: 0.00316 | Running loss: 0.00786\n",
            "Epoch: 46 | Iteration: 394 | Classification loss: 0.00010 | Regression loss: 0.00704 | Running loss: 0.00786\n",
            "Epoch: 46 | Iteration: 395 | Classification loss: 0.00094 | Regression loss: 0.01351 | Running loss: 0.00786\n",
            "Epoch: 46 | Iteration: 396 | Classification loss: 0.00005 | Regression loss: 0.00638 | Running loss: 0.00786\n",
            "Epoch: 46 | Iteration: 397 | Classification loss: 0.00006 | Regression loss: 0.00507 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 398 | Classification loss: 0.00002 | Regression loss: 0.00359 | Running loss: 0.00786\n",
            "Epoch: 46 | Iteration: 399 | Classification loss: 0.00015 | Regression loss: 0.00612 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 400 | Classification loss: 0.00011 | Regression loss: 0.01279 | Running loss: 0.00789\n",
            "Epoch: 46 | Iteration: 401 | Classification loss: 0.00006 | Regression loss: 0.00469 | Running loss: 0.00789\n",
            "Epoch: 46 | Iteration: 402 | Classification loss: 0.00023 | Regression loss: 0.00228 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 403 | Classification loss: 0.00009 | Regression loss: 0.00302 | Running loss: 0.00788\n",
            "Epoch: 46 | Iteration: 404 | Classification loss: 0.00002 | Regression loss: 0.00466 | Running loss: 0.00788\n",
            "Epoch: 46 | Iteration: 405 | Classification loss: 0.00014 | Regression loss: 0.00350 | Running loss: 0.00788\n",
            "Epoch: 46 | Iteration: 406 | Classification loss: 0.00030 | Regression loss: 0.00380 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 407 | Classification loss: 0.00001 | Regression loss: 0.00311 | Running loss: 0.00786\n",
            "Epoch: 46 | Iteration: 408 | Classification loss: 0.00007 | Regression loss: 0.00981 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 409 | Classification loss: 0.00008 | Regression loss: 0.01750 | Running loss: 0.00790\n",
            "Epoch: 46 | Iteration: 410 | Classification loss: 0.00010 | Regression loss: 0.00504 | Running loss: 0.00790\n",
            "Epoch: 46 | Iteration: 411 | Classification loss: 0.00033 | Regression loss: 0.01696 | Running loss: 0.00792\n",
            "Epoch: 46 | Iteration: 412 | Classification loss: 0.00022 | Regression loss: 0.00290 | Running loss: 0.00792\n",
            "Epoch: 46 | Iteration: 413 | Classification loss: 0.00026 | Regression loss: 0.00781 | Running loss: 0.00792\n",
            "Epoch: 46 | Iteration: 414 | Classification loss: 0.00023 | Regression loss: 0.00296 | Running loss: 0.00791\n",
            "Epoch: 46 | Iteration: 415 | Classification loss: 0.00009 | Regression loss: 0.01425 | Running loss: 0.00793\n",
            "Epoch: 46 | Iteration: 416 | Classification loss: 0.00009 | Regression loss: 0.01009 | Running loss: 0.00794\n",
            "Epoch: 46 | Iteration: 417 | Classification loss: 0.00048 | Regression loss: 0.01033 | Running loss: 0.00795\n",
            "Epoch: 46 | Iteration: 418 | Classification loss: 0.00005 | Regression loss: 0.00314 | Running loss: 0.00792\n",
            "Epoch: 46 | Iteration: 419 | Classification loss: 0.00004 | Regression loss: 0.00395 | Running loss: 0.00792\n",
            "Epoch: 46 | Iteration: 420 | Classification loss: 0.00158 | Regression loss: 0.01946 | Running loss: 0.00795\n",
            "Epoch: 46 | Iteration: 421 | Classification loss: 0.00045 | Regression loss: 0.00751 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 422 | Classification loss: 0.00007 | Regression loss: 0.00367 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 423 | Classification loss: 0.00002 | Regression loss: 0.00368 | Running loss: 0.00794\n",
            "Epoch: 46 | Iteration: 424 | Classification loss: 0.00018 | Regression loss: 0.01292 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 425 | Classification loss: 0.00001 | Regression loss: 0.00318 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 426 | Classification loss: 0.00014 | Regression loss: 0.00311 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 427 | Classification loss: 0.00013 | Regression loss: 0.00465 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 428 | Classification loss: 0.00001 | Regression loss: 0.00373 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 429 | Classification loss: 0.00031 | Regression loss: 0.00551 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 430 | Classification loss: 0.00036 | Regression loss: 0.00611 | Running loss: 0.00795\n",
            "Epoch: 46 | Iteration: 431 | Classification loss: 0.00021 | Regression loss: 0.01264 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 432 | Classification loss: 0.00007 | Regression loss: 0.00459 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 433 | Classification loss: 0.00001 | Regression loss: 0.00672 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 434 | Classification loss: 0.00008 | Regression loss: 0.00513 | Running loss: 0.00797\n",
            "Epoch: 46 | Iteration: 435 | Classification loss: 0.00009 | Regression loss: 0.01086 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 436 | Classification loss: 0.00014 | Regression loss: 0.00351 | Running loss: 0.00796\n",
            "Epoch: 46 | Iteration: 437 | Classification loss: 0.00013 | Regression loss: 0.00234 | Running loss: 0.00791\n",
            "Epoch: 46 | Iteration: 438 | Classification loss: 0.00002 | Regression loss: 0.00358 | Running loss: 0.00790\n",
            "Epoch: 46 | Iteration: 439 | Classification loss: 0.00001 | Regression loss: 0.00294 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 440 | Classification loss: 0.00005 | Regression loss: 0.00371 | Running loss: 0.00787\n",
            "Epoch: 46 | Iteration: 441 | Classification loss: 0.00030 | Regression loss: 0.01035 | Running loss: 0.00785\n",
            "Epoch: 46 | Iteration: 442 | Classification loss: 0.00026 | Regression loss: 0.00587 | Running loss: 0.00783\n",
            "Epoch: 46 | Iteration: 443 | Classification loss: 0.00129 | Regression loss: 0.01554 | Running loss: 0.00784\n",
            "Epoch: 46 | Iteration: 444 | Classification loss: 0.00016 | Regression loss: 0.00722 | Running loss: 0.00784\n",
            "Epoch: 46 | Iteration: 445 | Classification loss: 0.00016 | Regression loss: 0.00827 | Running loss: 0.00782\n",
            "Epoch: 46 | Iteration: 446 | Classification loss: 0.00018 | Regression loss: 0.00557 | Running loss: 0.00782\n",
            "Epoch: 46 | Iteration: 447 | Classification loss: 0.00002 | Regression loss: 0.00159 | Running loss: 0.00781\n",
            "Epoch: 46 | Iteration: 448 | Classification loss: 0.00003 | Regression loss: 0.01221 | Running loss: 0.00783\n",
            "Epoch: 46 | Iteration: 449 | Classification loss: 0.00003 | Regression loss: 0.00352 | Running loss: 0.00783\n",
            "Epoch: 46 | Iteration: 450 | Classification loss: 0.00002 | Regression loss: 0.00307 | Running loss: 0.00782\n",
            "Epoch: 46 | Iteration: 451 | Classification loss: 0.00005 | Regression loss: 0.01109 | Running loss: 0.00783\n",
            "Epoch: 46 | Iteration: 452 | Classification loss: 0.00014 | Regression loss: 0.00415 | Running loss: 0.00781\n",
            "Epoch: 46 | Iteration: 453 | Classification loss: 0.00011 | Regression loss: 0.00937 | Running loss: 0.00781\n",
            "Epoch: 46 | Iteration: 454 | Classification loss: 0.00032 | Regression loss: 0.00511 | Running loss: 0.00781\n",
            "Epoch: 46 | Iteration: 455 | Classification loss: 0.00058 | Regression loss: 0.01654 | Running loss: 0.00783\n",
            "Epoch: 46 | Iteration: 456 | Classification loss: 0.00002 | Regression loss: 0.00358 | Running loss: 0.00779\n",
            "Epoch: 46 | Iteration: 457 | Classification loss: 0.00001 | Regression loss: 0.00349 | Running loss: 0.00779\n",
            "Epoch: 46 | Iteration: 458 | Classification loss: 0.00003 | Regression loss: 0.00550 | Running loss: 0.00779\n",
            "Epoch: 46 | Iteration: 459 | Classification loss: 0.00023 | Regression loss: 0.00232 | Running loss: 0.00774\n",
            "Epoch: 46 | Iteration: 460 | Classification loss: 0.00129 | Regression loss: 0.00667 | Running loss: 0.00774\n",
            "Epoch: 46 | Iteration: 461 | Classification loss: 0.00009 | Regression loss: 0.00490 | Running loss: 0.00775\n",
            "Epoch: 46 | Iteration: 462 | Classification loss: 0.00009 | Regression loss: 0.00303 | Running loss: 0.00774\n",
            "Epoch: 46 | Iteration: 463 | Classification loss: 0.00024 | Regression loss: 0.00336 | Running loss: 0.00772\n",
            "Epoch: 46 | Iteration: 464 | Classification loss: 0.00046 | Regression loss: 0.01371 | Running loss: 0.00774\n",
            "Epoch: 46 | Iteration: 465 | Classification loss: 0.00005 | Regression loss: 0.00418 | Running loss: 0.00773\n",
            "Epoch: 46 | Iteration: 466 | Classification loss: 0.00038 | Regression loss: 0.01192 | Running loss: 0.00775\n",
            "Epoch: 46 | Iteration: 467 | Classification loss: 0.00513 | Regression loss: 0.03690 | Running loss: 0.00782\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6721433633616761\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.3435545935545936\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.46542194842888246\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5304843461546223\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 47 | Iteration: 0 | Classification loss: 0.00002 | Regression loss: 0.00157 | Running loss: 0.00780\n",
            "Epoch: 47 | Iteration: 1 | Classification loss: 0.00014 | Regression loss: 0.00521 | Running loss: 0.00781\n",
            "Epoch: 47 | Iteration: 2 | Classification loss: 0.00004 | Regression loss: 0.00389 | Running loss: 0.00780\n",
            "Epoch: 47 | Iteration: 3 | Classification loss: 0.00010 | Regression loss: 0.00277 | Running loss: 0.00780\n",
            "Epoch: 47 | Iteration: 4 | Classification loss: 0.00015 | Regression loss: 0.00585 | Running loss: 0.00781\n",
            "Epoch: 47 | Iteration: 5 | Classification loss: 0.00004 | Regression loss: 0.00270 | Running loss: 0.00776\n",
            "Epoch: 47 | Iteration: 6 | Classification loss: 0.00047 | Regression loss: 0.00668 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 7 | Classification loss: 0.00004 | Regression loss: 0.00403 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 8 | Classification loss: 0.00010 | Regression loss: 0.00675 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 9 | Classification loss: 0.00008 | Regression loss: 0.00658 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 10 | Classification loss: 0.00021 | Regression loss: 0.01703 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 11 | Classification loss: 0.00003 | Regression loss: 0.00326 | Running loss: 0.00769\n",
            "Epoch: 47 | Iteration: 12 | Classification loss: 0.00002 | Regression loss: 0.00365 | Running loss: 0.00768\n",
            "Epoch: 47 | Iteration: 13 | Classification loss: 0.00004 | Regression loss: 0.00391 | Running loss: 0.00767\n",
            "Epoch: 47 | Iteration: 14 | Classification loss: 0.00008 | Regression loss: 0.00250 | Running loss: 0.00767\n",
            "Epoch: 47 | Iteration: 15 | Classification loss: 0.00018 | Regression loss: 0.01094 | Running loss: 0.00768\n",
            "Epoch: 47 | Iteration: 16 | Classification loss: 0.00003 | Regression loss: 0.00599 | Running loss: 0.00768\n",
            "Epoch: 47 | Iteration: 17 | Classification loss: 0.00015 | Regression loss: 0.00426 | Running loss: 0.00768\n",
            "Epoch: 47 | Iteration: 18 | Classification loss: 0.00007 | Regression loss: 0.00551 | Running loss: 0.00767\n",
            "Epoch: 47 | Iteration: 19 | Classification loss: 0.00005 | Regression loss: 0.00341 | Running loss: 0.00765\n",
            "Epoch: 47 | Iteration: 20 | Classification loss: 0.00011 | Regression loss: 0.00298 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 21 | Classification loss: 0.00003 | Regression loss: 0.00742 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 22 | Classification loss: 0.00023 | Regression loss: 0.00662 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 23 | Classification loss: 0.00007 | Regression loss: 0.00578 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 24 | Classification loss: 0.00080 | Regression loss: 0.01286 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 25 | Classification loss: 0.00004 | Regression loss: 0.00387 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 26 | Classification loss: 0.00040 | Regression loss: 0.00437 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 27 | Classification loss: 0.00004 | Regression loss: 0.00396 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 28 | Classification loss: 0.00015 | Regression loss: 0.00273 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 29 | Classification loss: 0.00001 | Regression loss: 0.00144 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 30 | Classification loss: 0.00002 | Regression loss: 0.00315 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 31 | Classification loss: 0.00011 | Regression loss: 0.00999 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 32 | Classification loss: 0.00013 | Regression loss: 0.00485 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 33 | Classification loss: 0.00005 | Regression loss: 0.00272 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 34 | Classification loss: 0.00033 | Regression loss: 0.04577 | Running loss: 0.00769\n",
            "Epoch: 47 | Iteration: 35 | Classification loss: 0.00007 | Regression loss: 0.00843 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 36 | Classification loss: 0.00014 | Regression loss: 0.00757 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 37 | Classification loss: 0.00004 | Regression loss: 0.00531 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 38 | Classification loss: 0.00012 | Regression loss: 0.00771 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 39 | Classification loss: 0.00004 | Regression loss: 0.00463 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 40 | Classification loss: 0.00001 | Regression loss: 0.00203 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 41 | Classification loss: 0.00002 | Regression loss: 0.00261 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 42 | Classification loss: 0.00026 | Regression loss: 0.00484 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 43 | Classification loss: 0.00013 | Regression loss: 0.00315 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 44 | Classification loss: 0.00024 | Regression loss: 0.00324 | Running loss: 0.00769\n",
            "Epoch: 47 | Iteration: 45 | Classification loss: 0.00039 | Regression loss: 0.00393 | Running loss: 0.00764\n",
            "Epoch: 47 | Iteration: 46 | Classification loss: 0.00006 | Regression loss: 0.00354 | Running loss: 0.00764\n",
            "Epoch: 47 | Iteration: 47 | Classification loss: 0.00009 | Regression loss: 0.00343 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 48 | Classification loss: 0.00010 | Regression loss: 0.00466 | Running loss: 0.00758\n",
            "Epoch: 47 | Iteration: 49 | Classification loss: 0.00064 | Regression loss: 0.02004 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 50 | Classification loss: 0.00003 | Regression loss: 0.00358 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 51 | Classification loss: 0.00012 | Regression loss: 0.00554 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 52 | Classification loss: 0.00028 | Regression loss: 0.00610 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 53 | Classification loss: 0.00011 | Regression loss: 0.00504 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 54 | Classification loss: 0.00010 | Regression loss: 0.00632 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 55 | Classification loss: 0.00021 | Regression loss: 0.00843 | Running loss: 0.00759\n",
            "Epoch: 47 | Iteration: 56 | Classification loss: 0.00010 | Regression loss: 0.00174 | Running loss: 0.00758\n",
            "Epoch: 47 | Iteration: 57 | Classification loss: 0.00020 | Regression loss: 0.00374 | Running loss: 0.00757\n",
            "Epoch: 47 | Iteration: 58 | Classification loss: 0.00002 | Regression loss: 0.00407 | Running loss: 0.00757\n",
            "Epoch: 47 | Iteration: 59 | Classification loss: 0.00022 | Regression loss: 0.00316 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 60 | Classification loss: 0.00005 | Regression loss: 0.00266 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 61 | Classification loss: 0.00021 | Regression loss: 0.00377 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 62 | Classification loss: 0.00002 | Regression loss: 0.01209 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 63 | Classification loss: 0.00007 | Regression loss: 0.00399 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 64 | Classification loss: 0.00006 | Regression loss: 0.01890 | Running loss: 0.00759\n",
            "Epoch: 47 | Iteration: 65 | Classification loss: 0.00017 | Regression loss: 0.01092 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 66 | Classification loss: 0.00043 | Regression loss: 0.01049 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 67 | Classification loss: 0.00008 | Regression loss: 0.00387 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 68 | Classification loss: 0.00004 | Regression loss: 0.00375 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 69 | Classification loss: 0.00001 | Regression loss: 0.00314 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 70 | Classification loss: 0.00004 | Regression loss: 0.00433 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 71 | Classification loss: 0.00013 | Regression loss: 0.00643 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 72 | Classification loss: 0.00005 | Regression loss: 0.00435 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 73 | Classification loss: 0.00002 | Regression loss: 0.00283 | Running loss: 0.00757\n",
            "Epoch: 47 | Iteration: 74 | Classification loss: 0.00019 | Regression loss: 0.06880 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 75 | Classification loss: 0.00003 | Regression loss: 0.00356 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 76 | Classification loss: 0.00022 | Regression loss: 0.01000 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 77 | Classification loss: 0.00018 | Regression loss: 0.00993 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 78 | Classification loss: 0.00001 | Regression loss: 0.00400 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 79 | Classification loss: 0.00092 | Regression loss: 0.00485 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 80 | Classification loss: 0.00011 | Regression loss: 0.00260 | Running loss: 0.00772\n",
            "Epoch: 47 | Iteration: 81 | Classification loss: 0.00005 | Regression loss: 0.00423 | Running loss: 0.00773\n",
            "Epoch: 47 | Iteration: 82 | Classification loss: 0.00002 | Regression loss: 0.00297 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 83 | Classification loss: 0.00006 | Regression loss: 0.00304 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 84 | Classification loss: 0.00021 | Regression loss: 0.00389 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 85 | Classification loss: 0.00002 | Regression loss: 0.00275 | Running loss: 0.00768\n",
            "Epoch: 47 | Iteration: 86 | Classification loss: 0.00042 | Regression loss: 0.00502 | Running loss: 0.00769\n",
            "Epoch: 47 | Iteration: 87 | Classification loss: 0.00004 | Regression loss: 0.00280 | Running loss: 0.00769\n",
            "Epoch: 47 | Iteration: 88 | Classification loss: 0.00035 | Regression loss: 0.01155 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 89 | Classification loss: 0.00078 | Regression loss: 0.01964 | Running loss: 0.00773\n",
            "Epoch: 47 | Iteration: 90 | Classification loss: 0.00022 | Regression loss: 0.00448 | Running loss: 0.00770\n",
            "Epoch: 47 | Iteration: 91 | Classification loss: 0.00022 | Regression loss: 0.00568 | Running loss: 0.00771\n",
            "Epoch: 47 | Iteration: 92 | Classification loss: 0.00006 | Regression loss: 0.00617 | Running loss: 0.00769\n",
            "Epoch: 47 | Iteration: 93 | Classification loss: 0.00080 | Regression loss: 0.00386 | Running loss: 0.00765\n",
            "Epoch: 47 | Iteration: 94 | Classification loss: 0.00003 | Regression loss: 0.00439 | Running loss: 0.00766\n",
            "Epoch: 47 | Iteration: 95 | Classification loss: 0.00005 | Regression loss: 0.00192 | Running loss: 0.00765\n",
            "Epoch: 47 | Iteration: 96 | Classification loss: 0.00010 | Regression loss: 0.00527 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 97 | Classification loss: 0.00004 | Regression loss: 0.00228 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 98 | Classification loss: 0.00008 | Regression loss: 0.00433 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 99 | Classification loss: 0.00003 | Regression loss: 0.00388 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 100 | Classification loss: 0.00017 | Regression loss: 0.00906 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 101 | Classification loss: 0.00023 | Regression loss: 0.00378 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 102 | Classification loss: 0.00015 | Regression loss: 0.00885 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 103 | Classification loss: 0.00011 | Regression loss: 0.00430 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 104 | Classification loss: 0.00031 | Regression loss: 0.00672 | Running loss: 0.00764\n",
            "Epoch: 47 | Iteration: 105 | Classification loss: 0.00002 | Regression loss: 0.00364 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 106 | Classification loss: 0.00001 | Regression loss: 0.00263 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 107 | Classification loss: 0.00006 | Regression loss: 0.00364 | Running loss: 0.00758\n",
            "Epoch: 47 | Iteration: 108 | Classification loss: 0.00004 | Regression loss: 0.00399 | Running loss: 0.00758\n",
            "Epoch: 47 | Iteration: 109 | Classification loss: 0.00026 | Regression loss: 0.00704 | Running loss: 0.00757\n",
            "Epoch: 47 | Iteration: 110 | Classification loss: 0.00057 | Regression loss: 0.01878 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 111 | Classification loss: 0.00008 | Regression loss: 0.00572 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 112 | Classification loss: 0.00009 | Regression loss: 0.00362 | Running loss: 0.00759\n",
            "Epoch: 47 | Iteration: 113 | Classification loss: 0.00039 | Regression loss: 0.01339 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 114 | Classification loss: 0.00008 | Regression loss: 0.00689 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 115 | Classification loss: 0.00007 | Regression loss: 0.00278 | Running loss: 0.00759\n",
            "Epoch: 47 | Iteration: 116 | Classification loss: 0.00001 | Regression loss: 0.00310 | Running loss: 0.00758\n",
            "Epoch: 47 | Iteration: 117 | Classification loss: 0.00009 | Regression loss: 0.00251 | Running loss: 0.00754\n",
            "Epoch: 47 | Iteration: 118 | Classification loss: 0.00100 | Regression loss: 0.06432 | Running loss: 0.00766\n",
            "Epoch: 47 | Iteration: 119 | Classification loss: 0.00034 | Regression loss: 0.00394 | Running loss: 0.00763\n",
            "Epoch: 47 | Iteration: 120 | Classification loss: 0.00006 | Regression loss: 0.00210 | Running loss: 0.00762\n",
            "Epoch: 47 | Iteration: 121 | Classification loss: 0.00000 | Regression loss: 0.00379 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 122 | Classification loss: 0.00001 | Regression loss: 0.00603 | Running loss: 0.00761\n",
            "Epoch: 47 | Iteration: 123 | Classification loss: 0.00010 | Regression loss: 0.00202 | Running loss: 0.00760\n",
            "Epoch: 47 | Iteration: 124 | Classification loss: 0.00009 | Regression loss: 0.00230 | Running loss: 0.00759\n",
            "Epoch: 47 | Iteration: 125 | Classification loss: 0.00003 | Regression loss: 0.00728 | Running loss: 0.00755\n",
            "Epoch: 47 | Iteration: 126 | Classification loss: 0.00019 | Regression loss: 0.01768 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 127 | Classification loss: 0.00002 | Regression loss: 0.00311 | Running loss: 0.00755\n",
            "Epoch: 47 | Iteration: 128 | Classification loss: 0.00005 | Regression loss: 0.00289 | Running loss: 0.00755\n",
            "Epoch: 47 | Iteration: 129 | Classification loss: 0.00001 | Regression loss: 0.00329 | Running loss: 0.00754\n",
            "Epoch: 47 | Iteration: 130 | Classification loss: 0.00011 | Regression loss: 0.00674 | Running loss: 0.00753\n",
            "Epoch: 47 | Iteration: 131 | Classification loss: 0.00017 | Regression loss: 0.00224 | Running loss: 0.00753\n",
            "Epoch: 47 | Iteration: 132 | Classification loss: 0.00000 | Regression loss: 0.00527 | Running loss: 0.00753\n",
            "Epoch: 47 | Iteration: 133 | Classification loss: 0.00007 | Regression loss: 0.00701 | Running loss: 0.00753\n",
            "Epoch: 47 | Iteration: 134 | Classification loss: 0.00006 | Regression loss: 0.00332 | Running loss: 0.00753\n",
            "Epoch: 47 | Iteration: 135 | Classification loss: 0.00003 | Regression loss: 0.00213 | Running loss: 0.00752\n",
            "Epoch: 47 | Iteration: 136 | Classification loss: 0.00021 | Regression loss: 0.00893 | Running loss: 0.00754\n",
            "Epoch: 47 | Iteration: 137 | Classification loss: 0.00002 | Regression loss: 0.00392 | Running loss: 0.00754\n",
            "Epoch: 47 | Iteration: 138 | Classification loss: 0.00005 | Regression loss: 0.00302 | Running loss: 0.00752\n",
            "Epoch: 47 | Iteration: 139 | Classification loss: 0.00004 | Regression loss: 0.00258 | Running loss: 0.00752\n",
            "Epoch: 47 | Iteration: 140 | Classification loss: 0.00125 | Regression loss: 0.02461 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 141 | Classification loss: 0.00006 | Regression loss: 0.00544 | Running loss: 0.00756\n",
            "Epoch: 47 | Iteration: 142 | Classification loss: 0.00003 | Regression loss: 0.00513 | Running loss: 0.00744\n",
            "Epoch: 47 | Iteration: 143 | Classification loss: 0.00014 | Regression loss: 0.00441 | Running loss: 0.00742\n",
            "Epoch: 47 | Iteration: 144 | Classification loss: 0.00006 | Regression loss: 0.00299 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 145 | Classification loss: 0.00108 | Regression loss: 0.01319 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 146 | Classification loss: 0.00046 | Regression loss: 0.00311 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 147 | Classification loss: 0.00028 | Regression loss: 0.01712 | Running loss: 0.00741\n",
            "Epoch: 47 | Iteration: 148 | Classification loss: 0.00016 | Regression loss: 0.00655 | Running loss: 0.00741\n",
            "Epoch: 47 | Iteration: 149 | Classification loss: 0.00003 | Regression loss: 0.00358 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 150 | Classification loss: 0.00001 | Regression loss: 0.00325 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 151 | Classification loss: 0.00006 | Regression loss: 0.00785 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 152 | Classification loss: 0.00010 | Regression loss: 0.00742 | Running loss: 0.00741\n",
            "Epoch: 47 | Iteration: 153 | Classification loss: 0.00017 | Regression loss: 0.00436 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 154 | Classification loss: 0.00034 | Regression loss: 0.00392 | Running loss: 0.00736\n",
            "Epoch: 47 | Iteration: 155 | Classification loss: 0.00005 | Regression loss: 0.02431 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 156 | Classification loss: 0.00012 | Regression loss: 0.00270 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 157 | Classification loss: 0.00009 | Regression loss: 0.00954 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 158 | Classification loss: 0.00006 | Regression loss: 0.00164 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 159 | Classification loss: 0.00006 | Regression loss: 0.00693 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 160 | Classification loss: 0.00001 | Regression loss: 0.00284 | Running loss: 0.00736\n",
            "Epoch: 47 | Iteration: 161 | Classification loss: 0.00142 | Regression loss: 0.02637 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 162 | Classification loss: 0.00000 | Regression loss: 0.00191 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 163 | Classification loss: 0.00063 | Regression loss: 0.00449 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 164 | Classification loss: 0.00006 | Regression loss: 0.00415 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 165 | Classification loss: 0.00009 | Regression loss: 0.00547 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 166 | Classification loss: 0.00001 | Regression loss: 0.00163 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 167 | Classification loss: 0.00019 | Regression loss: 0.00266 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 168 | Classification loss: 0.00009 | Regression loss: 0.00424 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 169 | Classification loss: 0.00014 | Regression loss: 0.00543 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 170 | Classification loss: 0.00015 | Regression loss: 0.00374 | Running loss: 0.00733\n",
            "Epoch: 47 | Iteration: 171 | Classification loss: 0.00006 | Regression loss: 0.00588 | Running loss: 0.00732\n",
            "Epoch: 47 | Iteration: 172 | Classification loss: 0.00004 | Regression loss: 0.00911 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 173 | Classification loss: 0.00004 | Regression loss: 0.00260 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 174 | Classification loss: 0.00003 | Regression loss: 0.00464 | Running loss: 0.00726\n",
            "Epoch: 47 | Iteration: 175 | Classification loss: 0.00022 | Regression loss: 0.00958 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 176 | Classification loss: 0.00002 | Regression loss: 0.00566 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 177 | Classification loss: 0.00016 | Regression loss: 0.01581 | Running loss: 0.00729\n",
            "Epoch: 47 | Iteration: 178 | Classification loss: 0.00067 | Regression loss: 0.01028 | Running loss: 0.00730\n",
            "Epoch: 47 | Iteration: 179 | Classification loss: 0.00004 | Regression loss: 0.00297 | Running loss: 0.00730\n",
            "Epoch: 47 | Iteration: 180 | Classification loss: 0.00009 | Regression loss: 0.01124 | Running loss: 0.00732\n",
            "Epoch: 47 | Iteration: 181 | Classification loss: 0.00005 | Regression loss: 0.00609 | Running loss: 0.00732\n",
            "Epoch: 47 | Iteration: 182 | Classification loss: 0.00001 | Regression loss: 0.00565 | Running loss: 0.00733\n",
            "Epoch: 47 | Iteration: 183 | Classification loss: 0.00008 | Regression loss: 0.00857 | Running loss: 0.00734\n",
            "Epoch: 47 | Iteration: 184 | Classification loss: 0.00001 | Regression loss: 0.00224 | Running loss: 0.00734\n",
            "Epoch: 47 | Iteration: 185 | Classification loss: 0.00002 | Regression loss: 0.00431 | Running loss: 0.00734\n",
            "Epoch: 47 | Iteration: 186 | Classification loss: 0.00008 | Regression loss: 0.00475 | Running loss: 0.00734\n",
            "Epoch: 47 | Iteration: 187 | Classification loss: 0.00022 | Regression loss: 0.02002 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 188 | Classification loss: 0.00001 | Regression loss: 0.00488 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 189 | Classification loss: 0.00002 | Regression loss: 0.00796 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 190 | Classification loss: 0.00009 | Regression loss: 0.00779 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 191 | Classification loss: 0.00014 | Regression loss: 0.00278 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 192 | Classification loss: 0.00004 | Regression loss: 0.00443 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 193 | Classification loss: 0.00005 | Regression loss: 0.00394 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 194 | Classification loss: 0.00007 | Regression loss: 0.00556 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 195 | Classification loss: 0.00002 | Regression loss: 0.00227 | Running loss: 0.00731\n",
            "Epoch: 47 | Iteration: 196 | Classification loss: 0.00005 | Regression loss: 0.00191 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 197 | Classification loss: 0.00011 | Regression loss: 0.00802 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 198 | Classification loss: 0.00015 | Regression loss: 0.00312 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 199 | Classification loss: 0.00035 | Regression loss: 0.00218 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 200 | Classification loss: 0.00032 | Regression loss: 0.00399 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 201 | Classification loss: 0.00001 | Regression loss: 0.00191 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 202 | Classification loss: 0.00008 | Regression loss: 0.00438 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 203 | Classification loss: 0.00011 | Regression loss: 0.00292 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 204 | Classification loss: 0.00012 | Regression loss: 0.00535 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 205 | Classification loss: 0.00001 | Regression loss: 0.00343 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 206 | Classification loss: 0.00002 | Regression loss: 0.00158 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 207 | Classification loss: 0.00007 | Regression loss: 0.00533 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 208 | Classification loss: 0.00032 | Regression loss: 0.00523 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 209 | Classification loss: 0.00009 | Regression loss: 0.00401 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 210 | Classification loss: 0.00029 | Regression loss: 0.05174 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 211 | Classification loss: 0.00001 | Regression loss: 0.00310 | Running loss: 0.00737\n",
            "Epoch: 47 | Iteration: 212 | Classification loss: 0.00015 | Regression loss: 0.00280 | Running loss: 0.00736\n",
            "Epoch: 47 | Iteration: 213 | Classification loss: 0.00009 | Regression loss: 0.00293 | Running loss: 0.00735\n",
            "Epoch: 47 | Iteration: 214 | Classification loss: 0.00003 | Regression loss: 0.00369 | Running loss: 0.00735\n",
            "Epoch: 47 | Iteration: 215 | Classification loss: 0.00007 | Regression loss: 0.00412 | Running loss: 0.00735\n",
            "Epoch: 47 | Iteration: 216 | Classification loss: 0.00015 | Regression loss: 0.00796 | Running loss: 0.00735\n",
            "Epoch: 47 | Iteration: 217 | Classification loss: 0.00006 | Regression loss: 0.00403 | Running loss: 0.00734\n",
            "Epoch: 47 | Iteration: 218 | Classification loss: 0.00004 | Regression loss: 0.02766 | Running loss: 0.00738\n",
            "Epoch: 47 | Iteration: 219 | Classification loss: 0.00017 | Regression loss: 0.01297 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 220 | Classification loss: 0.00006 | Regression loss: 0.00224 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 221 | Classification loss: 0.00016 | Regression loss: 0.00474 | Running loss: 0.00740\n",
            "Epoch: 47 | Iteration: 222 | Classification loss: 0.00012 | Regression loss: 0.00295 | Running loss: 0.00739\n",
            "Epoch: 47 | Iteration: 223 | Classification loss: 0.00013 | Regression loss: 0.00456 | Running loss: 0.00729\n",
            "Epoch: 47 | Iteration: 224 | Classification loss: 0.00010 | Regression loss: 0.00394 | Running loss: 0.00729\n",
            "Epoch: 47 | Iteration: 225 | Classification loss: 0.00188 | Regression loss: 0.02254 | Running loss: 0.00723\n",
            "Epoch: 47 | Iteration: 226 | Classification loss: 0.00020 | Regression loss: 0.03200 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 227 | Classification loss: 0.00011 | Regression loss: 0.00306 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 228 | Classification loss: 0.00058 | Regression loss: 0.01444 | Running loss: 0.00730\n",
            "Epoch: 47 | Iteration: 229 | Classification loss: 0.00022 | Regression loss: 0.00633 | Running loss: 0.00726\n",
            "Epoch: 47 | Iteration: 230 | Classification loss: 0.00009 | Regression loss: 0.00424 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 231 | Classification loss: 0.00007 | Regression loss: 0.00195 | Running loss: 0.00726\n",
            "Epoch: 47 | Iteration: 232 | Classification loss: 0.00003 | Regression loss: 0.00316 | Running loss: 0.00726\n",
            "Epoch: 47 | Iteration: 233 | Classification loss: 0.00023 | Regression loss: 0.00190 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 234 | Classification loss: 0.00013 | Regression loss: 0.00367 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 235 | Classification loss: 0.00002 | Regression loss: 0.00195 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 236 | Classification loss: 0.00060 | Regression loss: 0.00396 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 237 | Classification loss: 0.00006 | Regression loss: 0.00169 | Running loss: 0.00723\n",
            "Epoch: 47 | Iteration: 238 | Classification loss: 0.00002 | Regression loss: 0.00196 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 239 | Classification loss: 0.00009 | Regression loss: 0.00443 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 240 | Classification loss: 0.00001 | Regression loss: 0.00230 | Running loss: 0.00720\n",
            "Epoch: 47 | Iteration: 241 | Classification loss: 0.00010 | Regression loss: 0.00823 | Running loss: 0.00720\n",
            "Epoch: 47 | Iteration: 242 | Classification loss: 0.00020 | Regression loss: 0.00559 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 243 | Classification loss: 0.00001 | Regression loss: 0.00415 | Running loss: 0.00720\n",
            "Epoch: 47 | Iteration: 244 | Classification loss: 0.00002 | Regression loss: 0.00256 | Running loss: 0.00720\n",
            "Epoch: 47 | Iteration: 245 | Classification loss: 0.00030 | Regression loss: 0.01191 | Running loss: 0.00720\n",
            "Epoch: 47 | Iteration: 246 | Classification loss: 0.00012 | Regression loss: 0.01219 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 247 | Classification loss: 0.00048 | Regression loss: 0.03019 | Running loss: 0.00727\n",
            "Epoch: 47 | Iteration: 248 | Classification loss: 0.00068 | Regression loss: 0.01339 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 249 | Classification loss: 0.00016 | Regression loss: 0.01188 | Running loss: 0.00730\n",
            "Epoch: 47 | Iteration: 250 | Classification loss: 0.00002 | Regression loss: 0.00304 | Running loss: 0.00729\n",
            "Epoch: 47 | Iteration: 251 | Classification loss: 0.00036 | Regression loss: 0.01400 | Running loss: 0.00732\n",
            "Epoch: 47 | Iteration: 252 | Classification loss: 0.00003 | Regression loss: 0.00175 | Running loss: 0.00731\n",
            "Epoch: 47 | Iteration: 253 | Classification loss: 0.00021 | Regression loss: 0.00346 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 254 | Classification loss: 0.00006 | Regression loss: 0.00261 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 255 | Classification loss: 0.00002 | Regression loss: 0.00296 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 256 | Classification loss: 0.00006 | Regression loss: 0.00667 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 257 | Classification loss: 0.00029 | Regression loss: 0.00687 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 258 | Classification loss: 0.00019 | Regression loss: 0.00185 | Running loss: 0.00728\n",
            "Epoch: 47 | Iteration: 259 | Classification loss: 0.00025 | Regression loss: 0.00426 | Running loss: 0.00726\n",
            "Epoch: 47 | Iteration: 260 | Classification loss: 0.00009 | Regression loss: 0.00561 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 261 | Classification loss: 0.00040 | Regression loss: 0.00384 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 262 | Classification loss: 0.00009 | Regression loss: 0.00548 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 263 | Classification loss: 0.00009 | Regression loss: 0.00473 | Running loss: 0.00723\n",
            "Epoch: 47 | Iteration: 264 | Classification loss: 0.00010 | Regression loss: 0.00298 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 265 | Classification loss: 0.00004 | Regression loss: 0.00523 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 266 | Classification loss: 0.00011 | Regression loss: 0.00402 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 267 | Classification loss: 0.00005 | Regression loss: 0.00440 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 268 | Classification loss: 0.00006 | Regression loss: 0.00421 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 269 | Classification loss: 0.00011 | Regression loss: 0.00463 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 270 | Classification loss: 0.00011 | Regression loss: 0.00458 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 271 | Classification loss: 0.00163 | Regression loss: 0.02448 | Running loss: 0.00724\n",
            "Epoch: 47 | Iteration: 272 | Classification loss: 0.00002 | Regression loss: 0.00239 | Running loss: 0.00724\n",
            "Epoch: 47 | Iteration: 273 | Classification loss: 0.00006 | Regression loss: 0.00731 | Running loss: 0.00724\n",
            "Epoch: 47 | Iteration: 274 | Classification loss: 0.00006 | Regression loss: 0.00395 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 275 | Classification loss: 0.00001 | Regression loss: 0.00273 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 276 | Classification loss: 0.00005 | Regression loss: 0.00515 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 277 | Classification loss: 0.00010 | Regression loss: 0.00809 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 278 | Classification loss: 0.00019 | Regression loss: 0.00473 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 279 | Classification loss: 0.00002 | Regression loss: 0.00428 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 280 | Classification loss: 0.00008 | Regression loss: 0.00668 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 281 | Classification loss: 0.00004 | Regression loss: 0.00600 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 282 | Classification loss: 0.00006 | Regression loss: 0.00470 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 283 | Classification loss: 0.00022 | Regression loss: 0.00790 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 284 | Classification loss: 0.00018 | Regression loss: 0.00278 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 285 | Classification loss: 0.00036 | Regression loss: 0.01086 | Running loss: 0.00723\n",
            "Epoch: 47 | Iteration: 286 | Classification loss: 0.00013 | Regression loss: 0.01152 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 287 | Classification loss: 0.00038 | Regression loss: 0.00847 | Running loss: 0.00725\n",
            "Epoch: 47 | Iteration: 288 | Classification loss: 0.00018 | Regression loss: 0.00232 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 289 | Classification loss: 0.00003 | Regression loss: 0.00276 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 290 | Classification loss: 0.00019 | Regression loss: 0.00195 | Running loss: 0.00722\n",
            "Epoch: 47 | Iteration: 291 | Classification loss: 0.00030 | Regression loss: 0.01258 | Running loss: 0.00723\n",
            "Epoch: 47 | Iteration: 292 | Classification loss: 0.00003 | Regression loss: 0.00653 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 293 | Classification loss: 0.00007 | Regression loss: 0.00407 | Running loss: 0.00719\n",
            "Epoch: 47 | Iteration: 294 | Classification loss: 0.00009 | Regression loss: 0.00560 | Running loss: 0.00719\n",
            "Epoch: 47 | Iteration: 295 | Classification loss: 0.00007 | Regression loss: 0.00340 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 296 | Classification loss: 0.00006 | Regression loss: 0.00447 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 297 | Classification loss: 0.00002 | Regression loss: 0.00327 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 298 | Classification loss: 0.00009 | Regression loss: 0.00578 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 299 | Classification loss: 0.00023 | Regression loss: 0.00650 | Running loss: 0.00717\n",
            "Epoch: 47 | Iteration: 300 | Classification loss: 0.00001 | Regression loss: 0.00208 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 301 | Classification loss: 0.00002 | Regression loss: 0.00271 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 302 | Classification loss: 0.00003 | Regression loss: 0.00336 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 303 | Classification loss: 0.00017 | Regression loss: 0.00248 | Running loss: 0.00716\n",
            "Epoch: 47 | Iteration: 304 | Classification loss: 0.00023 | Regression loss: 0.00376 | Running loss: 0.00714\n",
            "Epoch: 47 | Iteration: 305 | Classification loss: 0.00008 | Regression loss: 0.01214 | Running loss: 0.00715\n",
            "Epoch: 47 | Iteration: 306 | Classification loss: 0.00003 | Regression loss: 0.00289 | Running loss: 0.00715\n",
            "Epoch: 47 | Iteration: 307 | Classification loss: 0.00014 | Regression loss: 0.01109 | Running loss: 0.00717\n",
            "Epoch: 47 | Iteration: 308 | Classification loss: 0.00004 | Regression loss: 0.00605 | Running loss: 0.00717\n",
            "Epoch: 47 | Iteration: 309 | Classification loss: 0.00004 | Regression loss: 0.00227 | Running loss: 0.00717\n",
            "Epoch: 47 | Iteration: 310 | Classification loss: 0.00002 | Regression loss: 0.00447 | Running loss: 0.00717\n",
            "Epoch: 47 | Iteration: 311 | Classification loss: 0.00004 | Regression loss: 0.00378 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 312 | Classification loss: 0.00026 | Regression loss: 0.00525 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 313 | Classification loss: 0.00001 | Regression loss: 0.00245 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 314 | Classification loss: 0.00034 | Regression loss: 0.00782 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 315 | Classification loss: 0.00033 | Regression loss: 0.00610 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 316 | Classification loss: 0.00002 | Regression loss: 0.00434 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 317 | Classification loss: 0.00012 | Regression loss: 0.00429 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 318 | Classification loss: 0.00004 | Regression loss: 0.00495 | Running loss: 0.00700\n",
            "Epoch: 47 | Iteration: 319 | Classification loss: 0.00041 | Regression loss: 0.00901 | Running loss: 0.00701\n",
            "Epoch: 47 | Iteration: 320 | Classification loss: 0.00001 | Regression loss: 0.00555 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 321 | Classification loss: 0.00001 | Regression loss: 0.00500 | Running loss: 0.00701\n",
            "Epoch: 47 | Iteration: 322 | Classification loss: 0.00019 | Regression loss: 0.03495 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 323 | Classification loss: 0.00017 | Regression loss: 0.00805 | Running loss: 0.00708\n",
            "Epoch: 47 | Iteration: 324 | Classification loss: 0.00004 | Regression loss: 0.00341 | Running loss: 0.00708\n",
            "Epoch: 47 | Iteration: 325 | Classification loss: 0.00004 | Regression loss: 0.00377 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 326 | Classification loss: 0.00002 | Regression loss: 0.00189 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 327 | Classification loss: 0.00011 | Regression loss: 0.00879 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 328 | Classification loss: 0.00004 | Regression loss: 0.00573 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 329 | Classification loss: 0.00001 | Regression loss: 0.00286 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 330 | Classification loss: 0.00008 | Regression loss: 0.00505 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 331 | Classification loss: 0.00051 | Regression loss: 0.01550 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 332 | Classification loss: 0.00003 | Regression loss: 0.00185 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 333 | Classification loss: 0.00010 | Regression loss: 0.00342 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 334 | Classification loss: 0.00003 | Regression loss: 0.00426 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 335 | Classification loss: 0.00036 | Regression loss: 0.01441 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 336 | Classification loss: 0.00067 | Regression loss: 0.01460 | Running loss: 0.00710\n",
            "Epoch: 47 | Iteration: 337 | Classification loss: 0.00012 | Regression loss: 0.00545 | Running loss: 0.00710\n",
            "Epoch: 47 | Iteration: 338 | Classification loss: 0.00223 | Regression loss: 0.05525 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 339 | Classification loss: 0.00002 | Regression loss: 0.00504 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 340 | Classification loss: 0.00003 | Regression loss: 0.00439 | Running loss: 0.00721\n",
            "Epoch: 47 | Iteration: 341 | Classification loss: 0.00023 | Regression loss: 0.00350 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 342 | Classification loss: 0.00001 | Regression loss: 0.00210 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 343 | Classification loss: 0.00059 | Regression loss: 0.00903 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 344 | Classification loss: 0.00003 | Regression loss: 0.00211 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 345 | Classification loss: 0.00002 | Regression loss: 0.00366 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 346 | Classification loss: 0.00006 | Regression loss: 0.00683 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 347 | Classification loss: 0.00033 | Regression loss: 0.00649 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 348 | Classification loss: 0.00094 | Regression loss: 0.02287 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 349 | Classification loss: 0.00010 | Regression loss: 0.00854 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 350 | Classification loss: 0.00002 | Regression loss: 0.00271 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 351 | Classification loss: 0.00008 | Regression loss: 0.00360 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 352 | Classification loss: 0.00063 | Regression loss: 0.01014 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 353 | Classification loss: 0.00002 | Regression loss: 0.00288 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 354 | Classification loss: 0.00001 | Regression loss: 0.00299 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 355 | Classification loss: 0.00015 | Regression loss: 0.00214 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 356 | Classification loss: 0.00023 | Regression loss: 0.00525 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 357 | Classification loss: 0.00020 | Regression loss: 0.00887 | Running loss: 0.00708\n",
            "Epoch: 47 | Iteration: 358 | Classification loss: 0.00014 | Regression loss: 0.00251 | Running loss: 0.00707\n",
            "Epoch: 47 | Iteration: 359 | Classification loss: 0.00009 | Regression loss: 0.01215 | Running loss: 0.00706\n",
            "Epoch: 47 | Iteration: 360 | Classification loss: 0.00015 | Regression loss: 0.00354 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 361 | Classification loss: 0.00006 | Regression loss: 0.00376 | Running loss: 0.00704\n",
            "Epoch: 47 | Iteration: 362 | Classification loss: 0.00006 | Regression loss: 0.00270 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 363 | Classification loss: 0.00006 | Regression loss: 0.00407 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 364 | Classification loss: 0.00006 | Regression loss: 0.00417 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 365 | Classification loss: 0.00003 | Regression loss: 0.00333 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 366 | Classification loss: 0.00009 | Regression loss: 0.00434 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 367 | Classification loss: 0.00005 | Regression loss: 0.00539 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 368 | Classification loss: 0.00006 | Regression loss: 0.00708 | Running loss: 0.00702\n",
            "Epoch: 47 | Iteration: 369 | Classification loss: 0.00015 | Regression loss: 0.02140 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 370 | Classification loss: 0.00006 | Regression loss: 0.00393 | Running loss: 0.00705\n",
            "Epoch: 47 | Iteration: 371 | Classification loss: 0.00004 | Regression loss: 0.00209 | Running loss: 0.00703\n",
            "Epoch: 47 | Iteration: 372 | Classification loss: 0.00029 | Regression loss: 0.00565 | Running loss: 0.00701\n",
            "Epoch: 47 | Iteration: 373 | Classification loss: 0.00020 | Regression loss: 0.00276 | Running loss: 0.00700\n",
            "Epoch: 47 | Iteration: 374 | Classification loss: 0.00005 | Regression loss: 0.00404 | Running loss: 0.00699\n",
            "Epoch: 47 | Iteration: 375 | Classification loss: 0.00012 | Regression loss: 0.01189 | Running loss: 0.00698\n",
            "Epoch: 47 | Iteration: 376 | Classification loss: 0.00001 | Regression loss: 0.00245 | Running loss: 0.00698\n",
            "Epoch: 47 | Iteration: 377 | Classification loss: 0.00002 | Regression loss: 0.00338 | Running loss: 0.00694\n",
            "Epoch: 47 | Iteration: 378 | Classification loss: 0.00004 | Regression loss: 0.00412 | Running loss: 0.00694\n",
            "Epoch: 47 | Iteration: 379 | Classification loss: 0.00005 | Regression loss: 0.00579 | Running loss: 0.00695\n",
            "Epoch: 47 | Iteration: 380 | Classification loss: 0.00010 | Regression loss: 0.00491 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 381 | Classification loss: 0.00002 | Regression loss: 0.00604 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 382 | Classification loss: 0.00001 | Regression loss: 0.00369 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 383 | Classification loss: 0.00009 | Regression loss: 0.01197 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 384 | Classification loss: 0.00004 | Regression loss: 0.00709 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 385 | Classification loss: 0.00003 | Regression loss: 0.00397 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 386 | Classification loss: 0.00002 | Regression loss: 0.00465 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 387 | Classification loss: 0.00007 | Regression loss: 0.00698 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 388 | Classification loss: 0.00052 | Regression loss: 0.00369 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 389 | Classification loss: 0.00004 | Regression loss: 0.00956 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 390 | Classification loss: 0.00001 | Regression loss: 0.00862 | Running loss: 0.00691\n",
            "Epoch: 47 | Iteration: 391 | Classification loss: 0.00009 | Regression loss: 0.00357 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 392 | Classification loss: 0.00004 | Regression loss: 0.00371 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 393 | Classification loss: 0.00014 | Regression loss: 0.00391 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 394 | Classification loss: 0.00028 | Regression loss: 0.00516 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 395 | Classification loss: 0.00007 | Regression loss: 0.00278 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 396 | Classification loss: 0.00001 | Regression loss: 0.00313 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 397 | Classification loss: 0.00003 | Regression loss: 0.00261 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 398 | Classification loss: 0.00027 | Regression loss: 0.00825 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 399 | Classification loss: 0.00001 | Regression loss: 0.00298 | Running loss: 0.00687\n",
            "Epoch: 47 | Iteration: 400 | Classification loss: 0.00009 | Regression loss: 0.00683 | Running loss: 0.00684\n",
            "Epoch: 47 | Iteration: 401 | Classification loss: 0.00032 | Regression loss: 0.01045 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 402 | Classification loss: 0.00012 | Regression loss: 0.00370 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 403 | Classification loss: 0.00006 | Regression loss: 0.00473 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 404 | Classification loss: 0.00046 | Regression loss: 0.02010 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 405 | Classification loss: 0.00011 | Regression loss: 0.00301 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 406 | Classification loss: 0.00002 | Regression loss: 0.00196 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 407 | Classification loss: 0.00031 | Regression loss: 0.00407 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 408 | Classification loss: 0.00022 | Regression loss: 0.00645 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 409 | Classification loss: 0.00011 | Regression loss: 0.01191 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 410 | Classification loss: 0.00004 | Regression loss: 0.00667 | Running loss: 0.00684\n",
            "Epoch: 47 | Iteration: 411 | Classification loss: 0.00008 | Regression loss: 0.00204 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 412 | Classification loss: 0.00012 | Regression loss: 0.00391 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 413 | Classification loss: 0.00001 | Regression loss: 0.00311 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 414 | Classification loss: 0.00008 | Regression loss: 0.00256 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 415 | Classification loss: 0.00010 | Regression loss: 0.00608 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 416 | Classification loss: 0.00001 | Regression loss: 0.00339 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 417 | Classification loss: 0.00002 | Regression loss: 0.00281 | Running loss: 0.00683\n",
            "Epoch: 47 | Iteration: 418 | Classification loss: 0.00006 | Regression loss: 0.00287 | Running loss: 0.00682\n",
            "Epoch: 47 | Iteration: 419 | Classification loss: 0.00407 | Regression loss: 0.03766 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 420 | Classification loss: 0.00011 | Regression loss: 0.00376 | Running loss: 0.00685\n",
            "Epoch: 47 | Iteration: 421 | Classification loss: 0.00013 | Regression loss: 0.01503 | Running loss: 0.00687\n",
            "Epoch: 47 | Iteration: 422 | Classification loss: 0.00006 | Regression loss: 0.00496 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 423 | Classification loss: 0.00022 | Regression loss: 0.00372 | Running loss: 0.00687\n",
            "Epoch: 47 | Iteration: 424 | Classification loss: 0.00011 | Regression loss: 0.00519 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 425 | Classification loss: 0.00016 | Regression loss: 0.00510 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 426 | Classification loss: 0.00003 | Regression loss: 0.00290 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 427 | Classification loss: 0.00004 | Regression loss: 0.00316 | Running loss: 0.00685\n",
            "Epoch: 47 | Iteration: 428 | Classification loss: 0.00018 | Regression loss: 0.00721 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 429 | Classification loss: 0.00002 | Regression loss: 0.00805 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 430 | Classification loss: 0.00014 | Regression loss: 0.00373 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 431 | Classification loss: 0.00002 | Regression loss: 0.00271 | Running loss: 0.00686\n",
            "Epoch: 47 | Iteration: 432 | Classification loss: 0.00030 | Regression loss: 0.02968 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 433 | Classification loss: 0.00161 | Regression loss: 0.02170 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 434 | Classification loss: 0.00005 | Regression loss: 0.00473 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 435 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 436 | Classification loss: 0.00022 | Regression loss: 0.00787 | Running loss: 0.00694\n",
            "Epoch: 47 | Iteration: 437 | Classification loss: 0.00004 | Regression loss: 0.00498 | Running loss: 0.00694\n",
            "Epoch: 47 | Iteration: 438 | Classification loss: 0.00013 | Regression loss: 0.01440 | Running loss: 0.00696\n",
            "Epoch: 47 | Iteration: 439 | Classification loss: 0.00019 | Regression loss: 0.00551 | Running loss: 0.00697\n",
            "Epoch: 47 | Iteration: 440 | Classification loss: 0.00001 | Regression loss: 0.00157 | Running loss: 0.00695\n",
            "Epoch: 47 | Iteration: 441 | Classification loss: 0.00008 | Regression loss: 0.00363 | Running loss: 0.00692\n",
            "Epoch: 47 | Iteration: 442 | Classification loss: 0.00036 | Regression loss: 0.00512 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 443 | Classification loss: 0.00002 | Regression loss: 0.00532 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 444 | Classification loss: 0.00001 | Regression loss: 0.00396 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 445 | Classification loss: 0.00047 | Regression loss: 0.00621 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 446 | Classification loss: 0.00017 | Regression loss: 0.00469 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 447 | Classification loss: 0.00017 | Regression loss: 0.02395 | Running loss: 0.00692\n",
            "Epoch: 47 | Iteration: 448 | Classification loss: 0.00005 | Regression loss: 0.00479 | Running loss: 0.00691\n",
            "Epoch: 47 | Iteration: 449 | Classification loss: 0.00019 | Regression loss: 0.01454 | Running loss: 0.00692\n",
            "Epoch: 47 | Iteration: 450 | Classification loss: 0.00029 | Regression loss: 0.00512 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 451 | Classification loss: 0.00018 | Regression loss: 0.00545 | Running loss: 0.00693\n",
            "Epoch: 47 | Iteration: 452 | Classification loss: 0.00001 | Regression loss: 0.00187 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 453 | Classification loss: 0.00003 | Regression loss: 0.01028 | Running loss: 0.00689\n",
            "Epoch: 47 | Iteration: 454 | Classification loss: 0.00013 | Regression loss: 0.00679 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 455 | Classification loss: 0.00018 | Regression loss: 0.00833 | Running loss: 0.00691\n",
            "Epoch: 47 | Iteration: 456 | Classification loss: 0.00032 | Regression loss: 0.00788 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 457 | Classification loss: 0.00007 | Regression loss: 0.00518 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 458 | Classification loss: 0.00002 | Regression loss: 0.00369 | Running loss: 0.00691\n",
            "Epoch: 47 | Iteration: 459 | Classification loss: 0.00001 | Regression loss: 0.00532 | Running loss: 0.00691\n",
            "Epoch: 47 | Iteration: 460 | Classification loss: 0.00025 | Regression loss: 0.00420 | Running loss: 0.00691\n",
            "Epoch: 47 | Iteration: 461 | Classification loss: 0.00007 | Regression loss: 0.00250 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 462 | Classification loss: 0.00007 | Regression loss: 0.00548 | Running loss: 0.00690\n",
            "Epoch: 47 | Iteration: 463 | Classification loss: 0.00004 | Regression loss: 0.00221 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 464 | Classification loss: 0.00002 | Regression loss: 0.00393 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 465 | Classification loss: 0.00005 | Regression loss: 0.00613 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 466 | Classification loss: 0.00008 | Regression loss: 0.00841 | Running loss: 0.00688\n",
            "Epoch: 47 | Iteration: 467 | Classification loss: 0.00004 | Regression loss: 0.00339 | Running loss: 0.00687\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9918417674481452\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6923297626680048\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.35055739467504177\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.4599781422655917\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5341556621749951\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.3835616438356164\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 48 | Iteration: 0 | Classification loss: 0.00004 | Regression loss: 0.00228 | Running loss: 0.00687\n",
            "Epoch: 48 | Iteration: 1 | Classification loss: 0.00014 | Regression loss: 0.00647 | Running loss: 0.00687\n",
            "Epoch: 48 | Iteration: 2 | Classification loss: 0.00003 | Regression loss: 0.00404 | Running loss: 0.00687\n",
            "Epoch: 48 | Iteration: 3 | Classification loss: 0.00016 | Regression loss: 0.00351 | Running loss: 0.00688\n",
            "Epoch: 48 | Iteration: 4 | Classification loss: 0.00006 | Regression loss: 0.00313 | Running loss: 0.00687\n",
            "Epoch: 48 | Iteration: 5 | Classification loss: 0.00001 | Regression loss: 0.00256 | Running loss: 0.00686\n",
            "Epoch: 48 | Iteration: 6 | Classification loss: 0.00002 | Regression loss: 0.00333 | Running loss: 0.00685\n",
            "Epoch: 48 | Iteration: 7 | Classification loss: 0.00001 | Regression loss: 0.00251 | Running loss: 0.00682\n",
            "Epoch: 48 | Iteration: 8 | Classification loss: 0.00030 | Regression loss: 0.00194 | Running loss: 0.00681\n",
            "Epoch: 48 | Iteration: 9 | Classification loss: 0.00002 | Regression loss: 0.00238 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 10 | Classification loss: 0.00008 | Regression loss: 0.00415 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 11 | Classification loss: 0.00033 | Regression loss: 0.01188 | Running loss: 0.00682\n",
            "Epoch: 48 | Iteration: 12 | Classification loss: 0.00005 | Regression loss: 0.00398 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 13 | Classification loss: 0.00009 | Regression loss: 0.00636 | Running loss: 0.00681\n",
            "Epoch: 48 | Iteration: 14 | Classification loss: 0.00007 | Regression loss: 0.00179 | Running loss: 0.00681\n",
            "Epoch: 48 | Iteration: 15 | Classification loss: 0.00010 | Regression loss: 0.00597 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 16 | Classification loss: 0.00014 | Regression loss: 0.00505 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 17 | Classification loss: 0.00001 | Regression loss: 0.00158 | Running loss: 0.00678\n",
            "Epoch: 48 | Iteration: 18 | Classification loss: 0.00015 | Regression loss: 0.00391 | Running loss: 0.00678\n",
            "Epoch: 48 | Iteration: 19 | Classification loss: 0.00017 | Regression loss: 0.00698 | Running loss: 0.00676\n",
            "Epoch: 48 | Iteration: 20 | Classification loss: 0.00002 | Regression loss: 0.00587 | Running loss: 0.00676\n",
            "Epoch: 48 | Iteration: 21 | Classification loss: 0.00004 | Regression loss: 0.00660 | Running loss: 0.00677\n",
            "Epoch: 48 | Iteration: 22 | Classification loss: 0.00003 | Regression loss: 0.01388 | Running loss: 0.00679\n",
            "Epoch: 48 | Iteration: 23 | Classification loss: 0.00008 | Regression loss: 0.00959 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 24 | Classification loss: 0.00055 | Regression loss: 0.01241 | Running loss: 0.00681\n",
            "Epoch: 48 | Iteration: 25 | Classification loss: 0.00004 | Regression loss: 0.00230 | Running loss: 0.00681\n",
            "Epoch: 48 | Iteration: 26 | Classification loss: 0.00010 | Regression loss: 0.00620 | Running loss: 0.00681\n",
            "Epoch: 48 | Iteration: 27 | Classification loss: 0.00020 | Regression loss: 0.00499 | Running loss: 0.00682\n",
            "Epoch: 48 | Iteration: 28 | Classification loss: 0.00002 | Regression loss: 0.00215 | Running loss: 0.00679\n",
            "Epoch: 48 | Iteration: 29 | Classification loss: 0.00020 | Regression loss: 0.00672 | Running loss: 0.00680\n",
            "Epoch: 48 | Iteration: 30 | Classification loss: 0.00003 | Regression loss: 0.00276 | Running loss: 0.00678\n",
            "Epoch: 48 | Iteration: 31 | Classification loss: 0.00009 | Regression loss: 0.00574 | Running loss: 0.00671\n",
            "Epoch: 48 | Iteration: 32 | Classification loss: 0.00003 | Regression loss: 0.00397 | Running loss: 0.00671\n",
            "Epoch: 48 | Iteration: 33 | Classification loss: 0.00002 | Regression loss: 0.00795 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 34 | Classification loss: 0.00007 | Regression loss: 0.00691 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 35 | Classification loss: 0.00002 | Regression loss: 0.00315 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 36 | Classification loss: 0.00015 | Regression loss: 0.00335 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 37 | Classification loss: 0.00046 | Regression loss: 0.00537 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 38 | Classification loss: 0.00006 | Regression loss: 0.00271 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 39 | Classification loss: 0.00003 | Regression loss: 0.00399 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 40 | Classification loss: 0.00017 | Regression loss: 0.01195 | Running loss: 0.00673\n",
            "Epoch: 48 | Iteration: 41 | Classification loss: 0.00002 | Regression loss: 0.00238 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 42 | Classification loss: 0.00005 | Regression loss: 0.00387 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 43 | Classification loss: 0.00002 | Regression loss: 0.00214 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 44 | Classification loss: 0.00001 | Regression loss: 0.00188 | Running loss: 0.00668\n",
            "Epoch: 48 | Iteration: 45 | Classification loss: 0.00008 | Regression loss: 0.00206 | Running loss: 0.00668\n",
            "Epoch: 48 | Iteration: 46 | Classification loss: 0.00001 | Regression loss: 0.00231 | Running loss: 0.00668\n",
            "Epoch: 48 | Iteration: 47 | Classification loss: 0.00002 | Regression loss: 0.00237 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 48 | Classification loss: 0.00020 | Regression loss: 0.01073 | Running loss: 0.00667\n",
            "Epoch: 48 | Iteration: 49 | Classification loss: 0.00024 | Regression loss: 0.00226 | Running loss: 0.00667\n",
            "Epoch: 48 | Iteration: 50 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 51 | Classification loss: 0.00018 | Regression loss: 0.00518 | Running loss: 0.00667\n",
            "Epoch: 48 | Iteration: 52 | Classification loss: 0.00004 | Regression loss: 0.00225 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 53 | Classification loss: 0.00003 | Regression loss: 0.02508 | Running loss: 0.00670\n",
            "Epoch: 48 | Iteration: 54 | Classification loss: 0.00010 | Regression loss: 0.00582 | Running loss: 0.00670\n",
            "Epoch: 48 | Iteration: 55 | Classification loss: 0.00004 | Regression loss: 0.00315 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 56 | Classification loss: 0.00031 | Regression loss: 0.00359 | Running loss: 0.00667\n",
            "Epoch: 48 | Iteration: 57 | Classification loss: 0.00002 | Regression loss: 0.00291 | Running loss: 0.00667\n",
            "Epoch: 48 | Iteration: 58 | Classification loss: 0.00010 | Regression loss: 0.00298 | Running loss: 0.00667\n",
            "Epoch: 48 | Iteration: 59 | Classification loss: 0.00003 | Regression loss: 0.01254 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 60 | Classification loss: 0.00062 | Regression loss: 0.00766 | Running loss: 0.00670\n",
            "Epoch: 48 | Iteration: 61 | Classification loss: 0.00002 | Regression loss: 0.00184 | Running loss: 0.00670\n",
            "Epoch: 48 | Iteration: 62 | Classification loss: 0.00131 | Regression loss: 0.02046 | Running loss: 0.00673\n",
            "Epoch: 48 | Iteration: 63 | Classification loss: 0.00004 | Regression loss: 0.00349 | Running loss: 0.00672\n",
            "Epoch: 48 | Iteration: 64 | Classification loss: 0.00015 | Regression loss: 0.00995 | Running loss: 0.00673\n",
            "Epoch: 48 | Iteration: 65 | Classification loss: 0.00005 | Regression loss: 0.00215 | Running loss: 0.00673\n",
            "Epoch: 48 | Iteration: 66 | Classification loss: 0.00011 | Regression loss: 0.00299 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 67 | Classification loss: 0.00001 | Regression loss: 0.00625 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 68 | Classification loss: 0.00003 | Regression loss: 0.00567 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 69 | Classification loss: 0.00008 | Regression loss: 0.00573 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 70 | Classification loss: 0.00012 | Regression loss: 0.00292 | Running loss: 0.00663\n",
            "Epoch: 48 | Iteration: 71 | Classification loss: 0.00019 | Regression loss: 0.00401 | Running loss: 0.00663\n",
            "Epoch: 48 | Iteration: 72 | Classification loss: 0.00003 | Regression loss: 0.00918 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 73 | Classification loss: 0.00005 | Regression loss: 0.00232 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 74 | Classification loss: 0.00025 | Regression loss: 0.00591 | Running loss: 0.00664\n",
            "Epoch: 48 | Iteration: 75 | Classification loss: 0.00044 | Regression loss: 0.01140 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 76 | Classification loss: 0.00014 | Regression loss: 0.00499 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 77 | Classification loss: 0.00011 | Regression loss: 0.00249 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 78 | Classification loss: 0.00002 | Regression loss: 0.00435 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 79 | Classification loss: 0.00021 | Regression loss: 0.00274 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 80 | Classification loss: 0.00001 | Regression loss: 0.00313 | Running loss: 0.00666\n",
            "Epoch: 48 | Iteration: 81 | Classification loss: 0.00023 | Regression loss: 0.00433 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 82 | Classification loss: 0.00003 | Regression loss: 0.00263 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 83 | Classification loss: 0.00005 | Regression loss: 0.00281 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 84 | Classification loss: 0.00016 | Regression loss: 0.00746 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 85 | Classification loss: 0.00005 | Regression loss: 0.00249 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 86 | Classification loss: 0.00007 | Regression loss: 0.00386 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 87 | Classification loss: 0.00045 | Regression loss: 0.00443 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 88 | Classification loss: 0.00014 | Regression loss: 0.00376 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 89 | Classification loss: 0.00003 | Regression loss: 0.00500 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 90 | Classification loss: 0.00001 | Regression loss: 0.00225 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 91 | Classification loss: 0.00002 | Regression loss: 0.00273 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 92 | Classification loss: 0.00002 | Regression loss: 0.00302 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 93 | Classification loss: 0.00006 | Regression loss: 0.00188 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 94 | Classification loss: 0.00025 | Regression loss: 0.00360 | Running loss: 0.00658\n",
            "Epoch: 48 | Iteration: 95 | Classification loss: 0.00008 | Regression loss: 0.00561 | Running loss: 0.00659\n",
            "Epoch: 48 | Iteration: 96 | Classification loss: 0.00015 | Regression loss: 0.00287 | Running loss: 0.00655\n",
            "Epoch: 48 | Iteration: 97 | Classification loss: 0.00017 | Regression loss: 0.00503 | Running loss: 0.00654\n",
            "Epoch: 48 | Iteration: 98 | Classification loss: 0.00010 | Regression loss: 0.00355 | Running loss: 0.00653\n",
            "Epoch: 48 | Iteration: 99 | Classification loss: 0.00003 | Regression loss: 0.00175 | Running loss: 0.00652\n",
            "Epoch: 48 | Iteration: 100 | Classification loss: 0.00009 | Regression loss: 0.00317 | Running loss: 0.00652\n",
            "Epoch: 48 | Iteration: 101 | Classification loss: 0.00014 | Regression loss: 0.00618 | Running loss: 0.00653\n",
            "Epoch: 48 | Iteration: 102 | Classification loss: 0.00018 | Regression loss: 0.00281 | Running loss: 0.00653\n",
            "Epoch: 48 | Iteration: 103 | Classification loss: 0.00014 | Regression loss: 0.00362 | Running loss: 0.00652\n",
            "Epoch: 48 | Iteration: 104 | Classification loss: 0.00013 | Regression loss: 0.00271 | Running loss: 0.00652\n",
            "Epoch: 48 | Iteration: 105 | Classification loss: 0.00024 | Regression loss: 0.01262 | Running loss: 0.00654\n",
            "Epoch: 48 | Iteration: 106 | Classification loss: 0.00001 | Regression loss: 0.00244 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 107 | Classification loss: 0.00015 | Regression loss: 0.00449 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 108 | Classification loss: 0.00000 | Regression loss: 0.00257 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 109 | Classification loss: 0.00020 | Regression loss: 0.00631 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 110 | Classification loss: 0.00005 | Regression loss: 0.00440 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 111 | Classification loss: 0.00011 | Regression loss: 0.00492 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 112 | Classification loss: 0.00006 | Regression loss: 0.00542 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 113 | Classification loss: 0.00003 | Regression loss: 0.00531 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 114 | Classification loss: 0.00007 | Regression loss: 0.00258 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 115 | Classification loss: 0.00003 | Regression loss: 0.00238 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 116 | Classification loss: 0.00113 | Regression loss: 0.02127 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 117 | Classification loss: 0.00005 | Regression loss: 0.00349 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 118 | Classification loss: 0.00035 | Regression loss: 0.01243 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 119 | Classification loss: 0.00028 | Regression loss: 0.00482 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 120 | Classification loss: 0.00015 | Regression loss: 0.00952 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 121 | Classification loss: 0.00007 | Regression loss: 0.00467 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 122 | Classification loss: 0.00001 | Regression loss: 0.00183 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 123 | Classification loss: 0.00003 | Regression loss: 0.00342 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 124 | Classification loss: 0.00013 | Regression loss: 0.01240 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 125 | Classification loss: 0.00093 | Regression loss: 0.02129 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 126 | Classification loss: 0.00064 | Regression loss: 0.00617 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 127 | Classification loss: 0.00008 | Regression loss: 0.00681 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 128 | Classification loss: 0.00023 | Regression loss: 0.01445 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 129 | Classification loss: 0.00006 | Regression loss: 0.00407 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 130 | Classification loss: 0.00013 | Regression loss: 0.00553 | Running loss: 0.00649\n",
            "Epoch: 48 | Iteration: 131 | Classification loss: 0.00016 | Regression loss: 0.00217 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 132 | Classification loss: 0.00005 | Regression loss: 0.00559 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 133 | Classification loss: 0.00007 | Regression loss: 0.00253 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 134 | Classification loss: 0.00011 | Regression loss: 0.00294 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 135 | Classification loss: 0.00012 | Regression loss: 0.00221 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 136 | Classification loss: 0.00009 | Regression loss: 0.00887 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 137 | Classification loss: 0.00004 | Regression loss: 0.00529 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 138 | Classification loss: 0.00010 | Regression loss: 0.00403 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 139 | Classification loss: 0.00023 | Regression loss: 0.00853 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 140 | Classification loss: 0.00017 | Regression loss: 0.00179 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 141 | Classification loss: 0.00005 | Regression loss: 0.00219 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 142 | Classification loss: 0.00007 | Regression loss: 0.01207 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 143 | Classification loss: 0.00006 | Regression loss: 0.00512 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 144 | Classification loss: 0.00004 | Regression loss: 0.00246 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 145 | Classification loss: 0.00010 | Regression loss: 0.00504 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 146 | Classification loss: 0.00001 | Regression loss: 0.00198 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 147 | Classification loss: 0.00002 | Regression loss: 0.00247 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 148 | Classification loss: 0.00006 | Regression loss: 0.00334 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 149 | Classification loss: 0.00001 | Regression loss: 0.00279 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 150 | Classification loss: 0.00002 | Regression loss: 0.00200 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 151 | Classification loss: 0.00014 | Regression loss: 0.01527 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 152 | Classification loss: 0.00011 | Regression loss: 0.00398 | Running loss: 0.00632\n",
            "Epoch: 48 | Iteration: 153 | Classification loss: 0.00003 | Regression loss: 0.00349 | Running loss: 0.00632\n",
            "Epoch: 48 | Iteration: 154 | Classification loss: 0.00013 | Regression loss: 0.00991 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 155 | Classification loss: 0.00011 | Regression loss: 0.00567 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 156 | Classification loss: 0.00001 | Regression loss: 0.00199 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 157 | Classification loss: 0.00006 | Regression loss: 0.00289 | Running loss: 0.00632\n",
            "Epoch: 48 | Iteration: 158 | Classification loss: 0.00007 | Regression loss: 0.00284 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 159 | Classification loss: 0.00009 | Regression loss: 0.00661 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 160 | Classification loss: 0.00345 | Regression loss: 0.02568 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 161 | Classification loss: 0.00011 | Regression loss: 0.00487 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 162 | Classification loss: 0.00010 | Regression loss: 0.00566 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 163 | Classification loss: 0.00005 | Regression loss: 0.00253 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 164 | Classification loss: 0.00001 | Regression loss: 0.00629 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 165 | Classification loss: 0.00002 | Regression loss: 0.00296 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 166 | Classification loss: 0.00003 | Regression loss: 0.00386 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 167 | Classification loss: 0.00002 | Regression loss: 0.02164 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 168 | Classification loss: 0.00002 | Regression loss: 0.00388 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 169 | Classification loss: 0.00001 | Regression loss: 0.00392 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 170 | Classification loss: 0.00006 | Regression loss: 0.00273 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 171 | Classification loss: 0.00001 | Regression loss: 0.00160 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 172 | Classification loss: 0.00002 | Regression loss: 0.00386 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 173 | Classification loss: 0.00004 | Regression loss: 0.00255 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 174 | Classification loss: 0.00004 | Regression loss: 0.00946 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 175 | Classification loss: 0.00017 | Regression loss: 0.00460 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 176 | Classification loss: 0.00002 | Regression loss: 0.00316 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 177 | Classification loss: 0.00021 | Regression loss: 0.01185 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 178 | Classification loss: 0.00007 | Regression loss: 0.00168 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 179 | Classification loss: 0.00016 | Regression loss: 0.00842 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 180 | Classification loss: 0.00010 | Regression loss: 0.00252 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 181 | Classification loss: 0.00024 | Regression loss: 0.01016 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 182 | Classification loss: 0.00001 | Regression loss: 0.00278 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 183 | Classification loss: 0.00003 | Regression loss: 0.00183 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 184 | Classification loss: 0.00001 | Regression loss: 0.00161 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 185 | Classification loss: 0.00010 | Regression loss: 0.00794 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 186 | Classification loss: 0.00070 | Regression loss: 0.01834 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 187 | Classification loss: 0.00012 | Regression loss: 0.00309 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 188 | Classification loss: 0.00009 | Regression loss: 0.00620 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 189 | Classification loss: 0.00009 | Regression loss: 0.00924 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 190 | Classification loss: 0.00035 | Regression loss: 0.01788 | Running loss: 0.00632\n",
            "Epoch: 48 | Iteration: 191 | Classification loss: 0.00003 | Regression loss: 0.00297 | Running loss: 0.00632\n",
            "Epoch: 48 | Iteration: 192 | Classification loss: 0.00012 | Regression loss: 0.00240 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 193 | Classification loss: 0.00008 | Regression loss: 0.00316 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 194 | Classification loss: 0.00050 | Regression loss: 0.01270 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 195 | Classification loss: 0.00001 | Regression loss: 0.00177 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 196 | Classification loss: 0.00062 | Regression loss: 0.01248 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 197 | Classification loss: 0.00003 | Regression loss: 0.00212 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 198 | Classification loss: 0.00010 | Regression loss: 0.00509 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 199 | Classification loss: 0.00074 | Regression loss: 0.00738 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 200 | Classification loss: 0.00015 | Regression loss: 0.00263 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 201 | Classification loss: 0.00002 | Regression loss: 0.00262 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 202 | Classification loss: 0.00011 | Regression loss: 0.00244 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 203 | Classification loss: 0.00010 | Regression loss: 0.00567 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 204 | Classification loss: 0.00015 | Regression loss: 0.00514 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 205 | Classification loss: 0.00003 | Regression loss: 0.00376 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 206 | Classification loss: 0.00004 | Regression loss: 0.00462 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 207 | Classification loss: 0.00011 | Regression loss: 0.00293 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 208 | Classification loss: 0.00046 | Regression loss: 0.01263 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 209 | Classification loss: 0.00036 | Regression loss: 0.00902 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 210 | Classification loss: 0.00012 | Regression loss: 0.00321 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 211 | Classification loss: 0.00011 | Regression loss: 0.00288 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 212 | Classification loss: 0.00021 | Regression loss: 0.00295 | Running loss: 0.00625\n",
            "Epoch: 48 | Iteration: 213 | Classification loss: 0.00006 | Regression loss: 0.00302 | Running loss: 0.00624\n",
            "Epoch: 48 | Iteration: 214 | Classification loss: 0.00012 | Regression loss: 0.00405 | Running loss: 0.00624\n",
            "Epoch: 48 | Iteration: 215 | Classification loss: 0.00125 | Regression loss: 0.01035 | Running loss: 0.00625\n",
            "Epoch: 48 | Iteration: 216 | Classification loss: 0.00162 | Regression loss: 0.02080 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 217 | Classification loss: 0.00001 | Regression loss: 0.00213 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 218 | Classification loss: 0.00025 | Regression loss: 0.01602 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 219 | Classification loss: 0.00001 | Regression loss: 0.00175 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 220 | Classification loss: 0.00007 | Regression loss: 0.00867 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 221 | Classification loss: 0.00026 | Regression loss: 0.00507 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 222 | Classification loss: 0.00015 | Regression loss: 0.00820 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 223 | Classification loss: 0.00014 | Regression loss: 0.00258 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 224 | Classification loss: 0.00021 | Regression loss: 0.02544 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 225 | Classification loss: 0.00010 | Regression loss: 0.00314 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 226 | Classification loss: 0.00015 | Regression loss: 0.01525 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 227 | Classification loss: 0.00005 | Regression loss: 0.00211 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 228 | Classification loss: 0.00011 | Regression loss: 0.00198 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 229 | Classification loss: 0.00009 | Regression loss: 0.00707 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 230 | Classification loss: 0.00016 | Regression loss: 0.00582 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 231 | Classification loss: 0.00008 | Regression loss: 0.02494 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 232 | Classification loss: 0.00008 | Regression loss: 0.00238 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 233 | Classification loss: 0.00016 | Regression loss: 0.00270 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 234 | Classification loss: 0.00001 | Regression loss: 0.00245 | Running loss: 0.00637\n",
            "Epoch: 48 | Iteration: 235 | Classification loss: 0.00002 | Regression loss: 0.00487 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 236 | Classification loss: 0.00002 | Regression loss: 0.00345 | Running loss: 0.00637\n",
            "Epoch: 48 | Iteration: 237 | Classification loss: 0.00007 | Regression loss: 0.00939 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 238 | Classification loss: 0.00003 | Regression loss: 0.00237 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 239 | Classification loss: 0.00005 | Regression loss: 0.00264 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 240 | Classification loss: 0.00002 | Regression loss: 0.00317 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 241 | Classification loss: 0.00007 | Regression loss: 0.00323 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 242 | Classification loss: 0.00020 | Regression loss: 0.00304 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 243 | Classification loss: 0.00079 | Regression loss: 0.06210 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 244 | Classification loss: 0.00001 | Regression loss: 0.00322 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 245 | Classification loss: 0.00006 | Regression loss: 0.00190 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 246 | Classification loss: 0.00044 | Regression loss: 0.01434 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 247 | Classification loss: 0.00014 | Regression loss: 0.00409 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 248 | Classification loss: 0.00005 | Regression loss: 0.00333 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 249 | Classification loss: 0.00024 | Regression loss: 0.00756 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 250 | Classification loss: 0.00008 | Regression loss: 0.00216 | Running loss: 0.00637\n",
            "Epoch: 48 | Iteration: 251 | Classification loss: 0.00012 | Regression loss: 0.00409 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 252 | Classification loss: 0.00007 | Regression loss: 0.00700 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 253 | Classification loss: 0.00004 | Regression loss: 0.00257 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 254 | Classification loss: 0.00006 | Regression loss: 0.00503 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 255 | Classification loss: 0.00005 | Regression loss: 0.00275 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 256 | Classification loss: 0.00011 | Regression loss: 0.00380 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 257 | Classification loss: 0.00003 | Regression loss: 0.00394 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 258 | Classification loss: 0.00040 | Regression loss: 0.01405 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 259 | Classification loss: 0.00024 | Regression loss: 0.04341 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 260 | Classification loss: 0.00001 | Regression loss: 0.00190 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 261 | Classification loss: 0.00065 | Regression loss: 0.01136 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 262 | Classification loss: 0.00012 | Regression loss: 0.00390 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 263 | Classification loss: 0.00019 | Regression loss: 0.00650 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 264 | Classification loss: 0.00026 | Regression loss: 0.00490 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 265 | Classification loss: 0.00007 | Regression loss: 0.00226 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 266 | Classification loss: 0.00002 | Regression loss: 0.00242 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 267 | Classification loss: 0.00002 | Regression loss: 0.00218 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 268 | Classification loss: 0.00009 | Regression loss: 0.00448 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 269 | Classification loss: 0.00005 | Regression loss: 0.00410 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 270 | Classification loss: 0.00002 | Regression loss: 0.00241 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 271 | Classification loss: 0.00005 | Regression loss: 0.00276 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 272 | Classification loss: 0.00004 | Regression loss: 0.00487 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 273 | Classification loss: 0.00001 | Regression loss: 0.00162 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 274 | Classification loss: 0.00004 | Regression loss: 0.00141 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 275 | Classification loss: 0.00008 | Regression loss: 0.00409 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 276 | Classification loss: 0.00007 | Regression loss: 0.00276 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 277 | Classification loss: 0.00003 | Regression loss: 0.00217 | Running loss: 0.00632\n",
            "Epoch: 48 | Iteration: 278 | Classification loss: 0.00019 | Regression loss: 0.00664 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 279 | Classification loss: 0.00008 | Regression loss: 0.00197 | Running loss: 0.00625\n",
            "Epoch: 48 | Iteration: 280 | Classification loss: 0.00001 | Regression loss: 0.00385 | Running loss: 0.00623\n",
            "Epoch: 48 | Iteration: 281 | Classification loss: 0.00001 | Regression loss: 0.00191 | Running loss: 0.00621\n",
            "Epoch: 48 | Iteration: 282 | Classification loss: 0.00003 | Regression loss: 0.00280 | Running loss: 0.00621\n",
            "Epoch: 48 | Iteration: 283 | Classification loss: 0.00005 | Regression loss: 0.00668 | Running loss: 0.00619\n",
            "Epoch: 48 | Iteration: 284 | Classification loss: 0.00007 | Regression loss: 0.00688 | Running loss: 0.00620\n",
            "Epoch: 48 | Iteration: 285 | Classification loss: 0.00007 | Regression loss: 0.00524 | Running loss: 0.00621\n",
            "Epoch: 48 | Iteration: 286 | Classification loss: 0.00009 | Regression loss: 0.00277 | Running loss: 0.00621\n",
            "Epoch: 48 | Iteration: 287 | Classification loss: 0.00012 | Regression loss: 0.00427 | Running loss: 0.00621\n",
            "Epoch: 48 | Iteration: 288 | Classification loss: 0.00004 | Regression loss: 0.02028 | Running loss: 0.00624\n",
            "Epoch: 48 | Iteration: 289 | Classification loss: 0.00008 | Regression loss: 0.01224 | Running loss: 0.00625\n",
            "Epoch: 48 | Iteration: 290 | Classification loss: 0.00003 | Regression loss: 0.00624 | Running loss: 0.00626\n",
            "Epoch: 48 | Iteration: 291 | Classification loss: 0.00030 | Regression loss: 0.01088 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 292 | Classification loss: 0.00004 | Regression loss: 0.01028 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 293 | Classification loss: 0.00005 | Regression loss: 0.01438 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 294 | Classification loss: 0.00014 | Regression loss: 0.00411 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 295 | Classification loss: 0.00002 | Regression loss: 0.00336 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 296 | Classification loss: 0.00082 | Regression loss: 0.02156 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 297 | Classification loss: 0.00011 | Regression loss: 0.00405 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 298 | Classification loss: 0.00006 | Regression loss: 0.01157 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 299 | Classification loss: 0.00005 | Regression loss: 0.00256 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 300 | Classification loss: 0.00010 | Regression loss: 0.00505 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 301 | Classification loss: 0.00001 | Regression loss: 0.00456 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 302 | Classification loss: 0.00010 | Regression loss: 0.00305 | Running loss: 0.00634\n",
            "Epoch: 48 | Iteration: 303 | Classification loss: 0.00002 | Regression loss: 0.00265 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 304 | Classification loss: 0.00025 | Regression loss: 0.00319 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 305 | Classification loss: 0.00001 | Regression loss: 0.00142 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 306 | Classification loss: 0.00001 | Regression loss: 0.00618 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 307 | Classification loss: 0.00005 | Regression loss: 0.00524 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 308 | Classification loss: 0.00003 | Regression loss: 0.00239 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 309 | Classification loss: 0.00033 | Regression loss: 0.00327 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 310 | Classification loss: 0.00003 | Regression loss: 0.00249 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 311 | Classification loss: 0.00001 | Regression loss: 0.00475 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 312 | Classification loss: 0.00013 | Regression loss: 0.01683 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 313 | Classification loss: 0.00005 | Regression loss: 0.00827 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 314 | Classification loss: 0.00015 | Regression loss: 0.00845 | Running loss: 0.00631\n",
            "Epoch: 48 | Iteration: 315 | Classification loss: 0.00002 | Regression loss: 0.00404 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 316 | Classification loss: 0.00001 | Regression loss: 0.00312 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 317 | Classification loss: 0.00008 | Regression loss: 0.00478 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 318 | Classification loss: 0.00022 | Regression loss: 0.01027 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 319 | Classification loss: 0.00007 | Regression loss: 0.00316 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 320 | Classification loss: 0.00002 | Regression loss: 0.00993 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 321 | Classification loss: 0.00002 | Regression loss: 0.00259 | Running loss: 0.00629\n",
            "Epoch: 48 | Iteration: 322 | Classification loss: 0.00008 | Regression loss: 0.00598 | Running loss: 0.00630\n",
            "Epoch: 48 | Iteration: 323 | Classification loss: 0.00004 | Regression loss: 0.00488 | Running loss: 0.00628\n",
            "Epoch: 48 | Iteration: 324 | Classification loss: 0.00035 | Regression loss: 0.00303 | Running loss: 0.00627\n",
            "Epoch: 48 | Iteration: 325 | Classification loss: 0.00009 | Regression loss: 0.05161 | Running loss: 0.00637\n",
            "Epoch: 48 | Iteration: 326 | Classification loss: 0.00001 | Regression loss: 0.00158 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 327 | Classification loss: 0.00020 | Regression loss: 0.00597 | Running loss: 0.00637\n",
            "Epoch: 48 | Iteration: 328 | Classification loss: 0.00002 | Regression loss: 0.00381 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 329 | Classification loss: 0.00226 | Regression loss: 0.05213 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 330 | Classification loss: 0.00105 | Regression loss: 0.02205 | Running loss: 0.00650\n",
            "Epoch: 48 | Iteration: 331 | Classification loss: 0.00001 | Regression loss: 0.01027 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 332 | Classification loss: 0.00002 | Regression loss: 0.00218 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 333 | Classification loss: 0.00001 | Regression loss: 0.00564 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 334 | Classification loss: 0.00002 | Regression loss: 0.00200 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 335 | Classification loss: 0.00016 | Regression loss: 0.02869 | Running loss: 0.00656\n",
            "Epoch: 48 | Iteration: 336 | Classification loss: 0.00006 | Regression loss: 0.00609 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 337 | Classification loss: 0.00042 | Regression loss: 0.01068 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 338 | Classification loss: 0.00009 | Regression loss: 0.00426 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 339 | Classification loss: 0.00004 | Regression loss: 0.00804 | Running loss: 0.00656\n",
            "Epoch: 48 | Iteration: 340 | Classification loss: 0.00001 | Regression loss: 0.00406 | Running loss: 0.00656\n",
            "Epoch: 48 | Iteration: 341 | Classification loss: 0.00008 | Regression loss: 0.01023 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 342 | Classification loss: 0.00006 | Regression loss: 0.00298 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 343 | Classification loss: 0.00007 | Regression loss: 0.01045 | Running loss: 0.00658\n",
            "Epoch: 48 | Iteration: 344 | Classification loss: 0.00010 | Regression loss: 0.00600 | Running loss: 0.00659\n",
            "Epoch: 48 | Iteration: 345 | Classification loss: 0.00005 | Regression loss: 0.00361 | Running loss: 0.00659\n",
            "Epoch: 48 | Iteration: 346 | Classification loss: 0.00006 | Regression loss: 0.00412 | Running loss: 0.00658\n",
            "Epoch: 48 | Iteration: 347 | Classification loss: 0.00008 | Regression loss: 0.00693 | Running loss: 0.00658\n",
            "Epoch: 48 | Iteration: 348 | Classification loss: 0.00031 | Regression loss: 0.00344 | Running loss: 0.00658\n",
            "Epoch: 48 | Iteration: 349 | Classification loss: 0.00000 | Regression loss: 0.00130 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 350 | Classification loss: 0.00005 | Regression loss: 0.00255 | Running loss: 0.00657\n",
            "Epoch: 48 | Iteration: 351 | Classification loss: 0.00024 | Regression loss: 0.07216 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 352 | Classification loss: 0.00004 | Regression loss: 0.00355 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 353 | Classification loss: 0.00043 | Regression loss: 0.00468 | Running loss: 0.00669\n",
            "Epoch: 48 | Iteration: 354 | Classification loss: 0.00003 | Regression loss: 0.00519 | Running loss: 0.00663\n",
            "Epoch: 48 | Iteration: 355 | Classification loss: 0.00021 | Regression loss: 0.00400 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 356 | Classification loss: 0.00007 | Regression loss: 0.00415 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 357 | Classification loss: 0.00010 | Regression loss: 0.00376 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 358 | Classification loss: 0.00016 | Regression loss: 0.00191 | Running loss: 0.00663\n",
            "Epoch: 48 | Iteration: 359 | Classification loss: 0.00005 | Regression loss: 0.00412 | Running loss: 0.00662\n",
            "Epoch: 48 | Iteration: 360 | Classification loss: 0.00008 | Regression loss: 0.00271 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 361 | Classification loss: 0.00020 | Regression loss: 0.00355 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 362 | Classification loss: 0.00007 | Regression loss: 0.00577 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 363 | Classification loss: 0.00022 | Regression loss: 0.00810 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 364 | Classification loss: 0.00014 | Regression loss: 0.00561 | Running loss: 0.00661\n",
            "Epoch: 48 | Iteration: 365 | Classification loss: 0.00001 | Regression loss: 0.00327 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 366 | Classification loss: 0.00006 | Regression loss: 0.00426 | Running loss: 0.00660\n",
            "Epoch: 48 | Iteration: 367 | Classification loss: 0.00008 | Regression loss: 0.00375 | Running loss: 0.00658\n",
            "Epoch: 48 | Iteration: 368 | Classification loss: 0.00005 | Regression loss: 0.00612 | Running loss: 0.00656\n",
            "Epoch: 48 | Iteration: 369 | Classification loss: 0.00003 | Regression loss: 0.00392 | Running loss: 0.00656\n",
            "Epoch: 48 | Iteration: 370 | Classification loss: 0.00006 | Regression loss: 0.00277 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 371 | Classification loss: 0.00003 | Regression loss: 0.00612 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 372 | Classification loss: 0.00004 | Regression loss: 0.00499 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 373 | Classification loss: 0.00004 | Regression loss: 0.00285 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 374 | Classification loss: 0.00022 | Regression loss: 0.00780 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 375 | Classification loss: 0.00005 | Regression loss: 0.00343 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 376 | Classification loss: 0.00009 | Regression loss: 0.00464 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 377 | Classification loss: 0.00002 | Regression loss: 0.00244 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 378 | Classification loss: 0.00008 | Regression loss: 0.00214 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 379 | Classification loss: 0.00001 | Regression loss: 0.00143 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 380 | Classification loss: 0.00005 | Regression loss: 0.00564 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 381 | Classification loss: 0.00025 | Regression loss: 0.00284 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 382 | Classification loss: 0.00003 | Regression loss: 0.00192 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 383 | Classification loss: 0.00004 | Regression loss: 0.00510 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 384 | Classification loss: 0.00008 | Regression loss: 0.01033 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 385 | Classification loss: 0.00017 | Regression loss: 0.00387 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 386 | Classification loss: 0.00059 | Regression loss: 0.01166 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 387 | Classification loss: 0.00050 | Regression loss: 0.02626 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 388 | Classification loss: 0.00003 | Regression loss: 0.00657 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 389 | Classification loss: 0.00001 | Regression loss: 0.00263 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 390 | Classification loss: 0.00003 | Regression loss: 0.00306 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 391 | Classification loss: 0.00001 | Regression loss: 0.00499 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 392 | Classification loss: 0.00010 | Regression loss: 0.02062 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 393 | Classification loss: 0.00000 | Regression loss: 0.00314 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 394 | Classification loss: 0.00004 | Regression loss: 0.00295 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 395 | Classification loss: 0.00006 | Regression loss: 0.00792 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 396 | Classification loss: 0.00007 | Regression loss: 0.00400 | Running loss: 0.00648\n",
            "Epoch: 48 | Iteration: 397 | Classification loss: 0.00008 | Regression loss: 0.02116 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 398 | Classification loss: 0.00005 | Regression loss: 0.00582 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 399 | Classification loss: 0.00003 | Regression loss: 0.00316 | Running loss: 0.00651\n",
            "Epoch: 48 | Iteration: 400 | Classification loss: 0.00002 | Regression loss: 0.00211 | Running loss: 0.00650\n",
            "Epoch: 48 | Iteration: 401 | Classification loss: 0.00004 | Regression loss: 0.00363 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 402 | Classification loss: 0.00002 | Regression loss: 0.00230 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 403 | Classification loss: 0.00001 | Regression loss: 0.00244 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 404 | Classification loss: 0.00009 | Regression loss: 0.00329 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 405 | Classification loss: 0.00001 | Regression loss: 0.00237 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 406 | Classification loss: 0.00004 | Regression loss: 0.00282 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 407 | Classification loss: 0.00005 | Regression loss: 0.00227 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 408 | Classification loss: 0.00001 | Regression loss: 0.00505 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 409 | Classification loss: 0.00019 | Regression loss: 0.00556 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 410 | Classification loss: 0.00009 | Regression loss: 0.00560 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 411 | Classification loss: 0.00027 | Regression loss: 0.00225 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 412 | Classification loss: 0.00016 | Regression loss: 0.00542 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 413 | Classification loss: 0.00012 | Regression loss: 0.00656 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 414 | Classification loss: 0.00006 | Regression loss: 0.00470 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 415 | Classification loss: 0.00020 | Regression loss: 0.00402 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 416 | Classification loss: 0.00011 | Regression loss: 0.02085 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 417 | Classification loss: 0.00002 | Regression loss: 0.00240 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 418 | Classification loss: 0.00001 | Regression loss: 0.00219 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 419 | Classification loss: 0.00008 | Regression loss: 0.00713 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 420 | Classification loss: 0.00000 | Regression loss: 0.00222 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 421 | Classification loss: 0.00020 | Regression loss: 0.01082 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 422 | Classification loss: 0.00013 | Regression loss: 0.00194 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 423 | Classification loss: 0.00008 | Regression loss: 0.00486 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 424 | Classification loss: 0.00002 | Regression loss: 0.00234 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 425 | Classification loss: 0.00067 | Regression loss: 0.00294 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 426 | Classification loss: 0.00037 | Regression loss: 0.01301 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 427 | Classification loss: 0.00008 | Regression loss: 0.00313 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 428 | Classification loss: 0.00003 | Regression loss: 0.00487 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 429 | Classification loss: 0.00003 | Regression loss: 0.00557 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 430 | Classification loss: 0.00015 | Regression loss: 0.00801 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 431 | Classification loss: 0.00013 | Regression loss: 0.00275 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 432 | Classification loss: 0.00014 | Regression loss: 0.01055 | Running loss: 0.00647\n",
            "Epoch: 48 | Iteration: 433 | Classification loss: 0.00001 | Regression loss: 0.00135 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 434 | Classification loss: 0.00008 | Regression loss: 0.00284 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 435 | Classification loss: 0.00001 | Regression loss: 0.00314 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 436 | Classification loss: 0.00002 | Regression loss: 0.00228 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 437 | Classification loss: 0.00002 | Regression loss: 0.00269 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 438 | Classification loss: 0.00004 | Regression loss: 0.00593 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 439 | Classification loss: 0.00008 | Regression loss: 0.00592 | Running loss: 0.00642\n",
            "Epoch: 48 | Iteration: 440 | Classification loss: 0.00001 | Regression loss: 0.00379 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 441 | Classification loss: 0.00001 | Regression loss: 0.00255 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 442 | Classification loss: 0.00025 | Regression loss: 0.00805 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 443 | Classification loss: 0.00006 | Regression loss: 0.00433 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 444 | Classification loss: 0.00013 | Regression loss: 0.00347 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 445 | Classification loss: 0.00006 | Regression loss: 0.01823 | Running loss: 0.00643\n",
            "Epoch: 48 | Iteration: 446 | Classification loss: 0.00028 | Regression loss: 0.01032 | Running loss: 0.00644\n",
            "Epoch: 48 | Iteration: 447 | Classification loss: 0.00019 | Regression loss: 0.00856 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 448 | Classification loss: 0.00002 | Regression loss: 0.00326 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 449 | Classification loss: 0.00003 | Regression loss: 0.00332 | Running loss: 0.00645\n",
            "Epoch: 48 | Iteration: 450 | Classification loss: 0.00038 | Regression loss: 0.00713 | Running loss: 0.00646\n",
            "Epoch: 48 | Iteration: 451 | Classification loss: 0.00001 | Regression loss: 0.00209 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 452 | Classification loss: 0.00004 | Regression loss: 0.00373 | Running loss: 0.00638\n",
            "Epoch: 48 | Iteration: 453 | Classification loss: 0.00015 | Regression loss: 0.00501 | Running loss: 0.00636\n",
            "Epoch: 48 | Iteration: 454 | Classification loss: 0.00190 | Regression loss: 0.02215 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 455 | Classification loss: 0.00012 | Regression loss: 0.00569 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 456 | Classification loss: 0.00018 | Regression loss: 0.00372 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 457 | Classification loss: 0.00000 | Regression loss: 0.00296 | Running loss: 0.00639\n",
            "Epoch: 48 | Iteration: 458 | Classification loss: 0.00009 | Regression loss: 0.00645 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 459 | Classification loss: 0.00000 | Regression loss: 0.00311 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 460 | Classification loss: 0.00051 | Regression loss: 0.00926 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 461 | Classification loss: 0.00003 | Regression loss: 0.00728 | Running loss: 0.00640\n",
            "Epoch: 48 | Iteration: 462 | Classification loss: 0.00039 | Regression loss: 0.00488 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 463 | Classification loss: 0.00011 | Regression loss: 0.00255 | Running loss: 0.00641\n",
            "Epoch: 48 | Iteration: 464 | Classification loss: 0.00002 | Regression loss: 0.00296 | Running loss: 0.00635\n",
            "Epoch: 48 | Iteration: 465 | Classification loss: 0.00019 | Regression loss: 0.00967 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 466 | Classification loss: 0.00015 | Regression loss: 0.00431 | Running loss: 0.00633\n",
            "Epoch: 48 | Iteration: 467 | Classification loss: 0.00001 | Regression loss: 0.00181 | Running loss: 0.00632\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6792674279710224\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.347346009110715\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.46699851683404314\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5340952585695491\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 49 | Iteration: 0 | Classification loss: 0.00005 | Regression loss: 0.00381 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 1 | Classification loss: 0.00008 | Regression loss: 0.00519 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 2 | Classification loss: 0.00187 | Regression loss: 0.05223 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 3 | Classification loss: 0.00003 | Regression loss: 0.00888 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 4 | Classification loss: 0.00001 | Regression loss: 0.00217 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 5 | Classification loss: 0.00004 | Regression loss: 0.00292 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 6 | Classification loss: 0.00008 | Regression loss: 0.00545 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 7 | Classification loss: 0.00006 | Regression loss: 0.00793 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 8 | Classification loss: 0.00006 | Regression loss: 0.00207 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 9 | Classification loss: 0.00017 | Regression loss: 0.01328 | Running loss: 0.00641\n",
            "Epoch: 49 | Iteration: 10 | Classification loss: 0.00016 | Regression loss: 0.06923 | Running loss: 0.00654\n",
            "Epoch: 49 | Iteration: 11 | Classification loss: 0.00006 | Regression loss: 0.02416 | Running loss: 0.00654\n",
            "Epoch: 49 | Iteration: 12 | Classification loss: 0.00010 | Regression loss: 0.00450 | Running loss: 0.00654\n",
            "Epoch: 49 | Iteration: 13 | Classification loss: 0.00002 | Regression loss: 0.00452 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 14 | Classification loss: 0.00003 | Regression loss: 0.00282 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 15 | Classification loss: 0.00006 | Regression loss: 0.00154 | Running loss: 0.00651\n",
            "Epoch: 49 | Iteration: 16 | Classification loss: 0.00008 | Regression loss: 0.00172 | Running loss: 0.00651\n",
            "Epoch: 49 | Iteration: 17 | Classification loss: 0.00003 | Regression loss: 0.00312 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 18 | Classification loss: 0.00004 | Regression loss: 0.00240 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 19 | Classification loss: 0.00000 | Regression loss: 0.00190 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 20 | Classification loss: 0.00011 | Regression loss: 0.00227 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 21 | Classification loss: 0.00006 | Regression loss: 0.00268 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 22 | Classification loss: 0.00003 | Regression loss: 0.00543 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 23 | Classification loss: 0.00036 | Regression loss: 0.01000 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 24 | Classification loss: 0.00003 | Regression loss: 0.00186 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 25 | Classification loss: 0.00008 | Regression loss: 0.00495 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 26 | Classification loss: 0.00013 | Regression loss: 0.00431 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 27 | Classification loss: 0.00001 | Regression loss: 0.00501 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 28 | Classification loss: 0.00013 | Regression loss: 0.01535 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 29 | Classification loss: 0.00005 | Regression loss: 0.00240 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 30 | Classification loss: 0.00005 | Regression loss: 0.00750 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 31 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 32 | Classification loss: 0.00006 | Regression loss: 0.00637 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 33 | Classification loss: 0.00002 | Regression loss: 0.00196 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 34 | Classification loss: 0.00001 | Regression loss: 0.00358 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 35 | Classification loss: 0.00006 | Regression loss: 0.00245 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 36 | Classification loss: 0.00001 | Regression loss: 0.00278 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 37 | Classification loss: 0.00003 | Regression loss: 0.01969 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 38 | Classification loss: 0.00016 | Regression loss: 0.00320 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 39 | Classification loss: 0.00005 | Regression loss: 0.00176 | Running loss: 0.00651\n",
            "Epoch: 49 | Iteration: 40 | Classification loss: 0.00010 | Regression loss: 0.00377 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 41 | Classification loss: 0.00011 | Regression loss: 0.00386 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 42 | Classification loss: 0.00001 | Regression loss: 0.00332 | Running loss: 0.00652\n",
            "Epoch: 49 | Iteration: 43 | Classification loss: 0.00002 | Regression loss: 0.00230 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 44 | Classification loss: 0.00001 | Regression loss: 0.00196 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 45 | Classification loss: 0.00002 | Regression loss: 0.00768 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 46 | Classification loss: 0.00001 | Regression loss: 0.00139 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 47 | Classification loss: 0.00001 | Regression loss: 0.00174 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 48 | Classification loss: 0.00005 | Regression loss: 0.00308 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 49 | Classification loss: 0.00014 | Regression loss: 0.01327 | Running loss: 0.00651\n",
            "Epoch: 49 | Iteration: 50 | Classification loss: 0.00008 | Regression loss: 0.00379 | Running loss: 0.00651\n",
            "Epoch: 49 | Iteration: 51 | Classification loss: 0.00002 | Regression loss: 0.00250 | Running loss: 0.00650\n",
            "Epoch: 49 | Iteration: 52 | Classification loss: 0.00002 | Regression loss: 0.00329 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 53 | Classification loss: 0.00001 | Regression loss: 0.00205 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 54 | Classification loss: 0.00005 | Regression loss: 0.00236 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 55 | Classification loss: 0.00005 | Regression loss: 0.00659 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 56 | Classification loss: 0.00004 | Regression loss: 0.00227 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 57 | Classification loss: 0.00017 | Regression loss: 0.00579 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 58 | Classification loss: 0.00004 | Regression loss: 0.00495 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 59 | Classification loss: 0.00012 | Regression loss: 0.00335 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 60 | Classification loss: 0.00001 | Regression loss: 0.00638 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 61 | Classification loss: 0.00019 | Regression loss: 0.00361 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 62 | Classification loss: 0.00007 | Regression loss: 0.00550 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 63 | Classification loss: 0.00001 | Regression loss: 0.00411 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 64 | Classification loss: 0.00016 | Regression loss: 0.00409 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 65 | Classification loss: 0.00007 | Regression loss: 0.00300 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 66 | Classification loss: 0.00037 | Regression loss: 0.01930 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 67 | Classification loss: 0.00044 | Regression loss: 0.01103 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 68 | Classification loss: 0.00003 | Regression loss: 0.00260 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 69 | Classification loss: 0.00019 | Regression loss: 0.00315 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 70 | Classification loss: 0.00002 | Regression loss: 0.00201 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 71 | Classification loss: 0.00003 | Regression loss: 0.00375 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 72 | Classification loss: 0.00047 | Regression loss: 0.00738 | Running loss: 0.00645\n",
            "Epoch: 49 | Iteration: 73 | Classification loss: 0.00014 | Regression loss: 0.01295 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 74 | Classification loss: 0.00010 | Regression loss: 0.00346 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 75 | Classification loss: 0.00002 | Regression loss: 0.00398 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 76 | Classification loss: 0.00000 | Regression loss: 0.00221 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 77 | Classification loss: 0.00005 | Regression loss: 0.00199 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 78 | Classification loss: 0.00005 | Regression loss: 0.00716 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 79 | Classification loss: 0.00001 | Regression loss: 0.00323 | Running loss: 0.00649\n",
            "Epoch: 49 | Iteration: 80 | Classification loss: 0.00003 | Regression loss: 0.00371 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 81 | Classification loss: 0.00017 | Regression loss: 0.00396 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 82 | Classification loss: 0.00002 | Regression loss: 0.00154 | Running loss: 0.00648\n",
            "Epoch: 49 | Iteration: 83 | Classification loss: 0.00001 | Regression loss: 0.00141 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 84 | Classification loss: 0.00006 | Regression loss: 0.00250 | Running loss: 0.00647\n",
            "Epoch: 49 | Iteration: 85 | Classification loss: 0.00005 | Regression loss: 0.00317 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 86 | Classification loss: 0.00082 | Regression loss: 0.01331 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 87 | Classification loss: 0.00016 | Regression loss: 0.00820 | Running loss: 0.00645\n",
            "Epoch: 49 | Iteration: 88 | Classification loss: 0.00014 | Regression loss: 0.00252 | Running loss: 0.00645\n",
            "Epoch: 49 | Iteration: 89 | Classification loss: 0.00002 | Regression loss: 0.00558 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 90 | Classification loss: 0.00012 | Regression loss: 0.00389 | Running loss: 0.00646\n",
            "Epoch: 49 | Iteration: 91 | Classification loss: 0.00001 | Regression loss: 0.00191 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 92 | Classification loss: 0.00001 | Regression loss: 0.00246 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 93 | Classification loss: 0.00002 | Regression loss: 0.00603 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 94 | Classification loss: 0.00007 | Regression loss: 0.00226 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 95 | Classification loss: 0.00001 | Regression loss: 0.00249 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 96 | Classification loss: 0.00004 | Regression loss: 0.00263 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 97 | Classification loss: 0.00002 | Regression loss: 0.00248 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 98 | Classification loss: 0.00007 | Regression loss: 0.00290 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 99 | Classification loss: 0.00021 | Regression loss: 0.00547 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 100 | Classification loss: 0.00001 | Regression loss: 0.00242 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 101 | Classification loss: 0.00006 | Regression loss: 0.00328 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 102 | Classification loss: 0.00013 | Regression loss: 0.00360 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 103 | Classification loss: 0.00014 | Regression loss: 0.00204 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 104 | Classification loss: 0.00029 | Regression loss: 0.00733 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 105 | Classification loss: 0.00008 | Regression loss: 0.00823 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 106 | Classification loss: 0.00002 | Regression loss: 0.00157 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 107 | Classification loss: 0.00016 | Regression loss: 0.00365 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 108 | Classification loss: 0.00022 | Regression loss: 0.00379 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 109 | Classification loss: 0.00030 | Regression loss: 0.00376 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 110 | Classification loss: 0.00011 | Regression loss: 0.00578 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 111 | Classification loss: 0.00003 | Regression loss: 0.00351 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 112 | Classification loss: 0.00004 | Regression loss: 0.00445 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 113 | Classification loss: 0.00006 | Regression loss: 0.00639 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 114 | Classification loss: 0.00006 | Regression loss: 0.00705 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 115 | Classification loss: 0.00005 | Regression loss: 0.00462 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 116 | Classification loss: 0.00002 | Regression loss: 0.00370 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 117 | Classification loss: 0.00005 | Regression loss: 0.00252 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 118 | Classification loss: 0.00014 | Regression loss: 0.00492 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 119 | Classification loss: 0.00008 | Regression loss: 0.00682 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 120 | Classification loss: 0.00003 | Regression loss: 0.00450 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 121 | Classification loss: 0.00001 | Regression loss: 0.00259 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 122 | Classification loss: 0.00024 | Regression loss: 0.01157 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 123 | Classification loss: 0.00007 | Regression loss: 0.00344 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 124 | Classification loss: 0.00002 | Regression loss: 0.00471 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 125 | Classification loss: 0.00009 | Regression loss: 0.00565 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 126 | Classification loss: 0.00001 | Regression loss: 0.00595 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 127 | Classification loss: 0.00012 | Regression loss: 0.00302 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 128 | Classification loss: 0.00007 | Regression loss: 0.00514 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 129 | Classification loss: 0.00001 | Regression loss: 0.00498 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 130 | Classification loss: 0.00002 | Regression loss: 0.00438 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 131 | Classification loss: 0.00037 | Regression loss: 0.01602 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 132 | Classification loss: 0.00005 | Regression loss: 0.00200 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 133 | Classification loss: 0.00007 | Regression loss: 0.00607 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 134 | Classification loss: 0.00000 | Regression loss: 0.00187 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 135 | Classification loss: 0.00008 | Regression loss: 0.00734 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 136 | Classification loss: 0.00001 | Regression loss: 0.00303 | Running loss: 0.00643\n",
            "Epoch: 49 | Iteration: 137 | Classification loss: 0.00007 | Regression loss: 0.00547 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 138 | Classification loss: 0.00012 | Regression loss: 0.00288 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 139 | Classification loss: 0.00006 | Regression loss: 0.00563 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 140 | Classification loss: 0.00002 | Regression loss: 0.00237 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 141 | Classification loss: 0.00020 | Regression loss: 0.00532 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 142 | Classification loss: 0.00003 | Regression loss: 0.00319 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 143 | Classification loss: 0.00004 | Regression loss: 0.00277 | Running loss: 0.00641\n",
            "Epoch: 49 | Iteration: 144 | Classification loss: 0.00020 | Regression loss: 0.01079 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 145 | Classification loss: 0.00001 | Regression loss: 0.00189 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 146 | Classification loss: 0.00004 | Regression loss: 0.00508 | Running loss: 0.00642\n",
            "Epoch: 49 | Iteration: 147 | Classification loss: 0.00006 | Regression loss: 0.01042 | Running loss: 0.00644\n",
            "Epoch: 49 | Iteration: 148 | Classification loss: 0.00003 | Regression loss: 0.01033 | Running loss: 0.00641\n",
            "Epoch: 49 | Iteration: 149 | Classification loss: 0.00028 | Regression loss: 0.00212 | Running loss: 0.00641\n",
            "Epoch: 49 | Iteration: 150 | Classification loss: 0.00003 | Regression loss: 0.00614 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 151 | Classification loss: 0.00001 | Regression loss: 0.00338 | Running loss: 0.00640\n",
            "Epoch: 49 | Iteration: 152 | Classification loss: 0.00014 | Regression loss: 0.00426 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 153 | Classification loss: 0.00011 | Regression loss: 0.00174 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 154 | Classification loss: 0.00011 | Regression loss: 0.00320 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 155 | Classification loss: 0.00027 | Regression loss: 0.00532 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 156 | Classification loss: 0.00081 | Regression loss: 0.00619 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 157 | Classification loss: 0.00001 | Regression loss: 0.00167 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 158 | Classification loss: 0.00002 | Regression loss: 0.00746 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 159 | Classification loss: 0.00004 | Regression loss: 0.00503 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 160 | Classification loss: 0.00001 | Regression loss: 0.00166 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 161 | Classification loss: 0.00006 | Regression loss: 0.00409 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 162 | Classification loss: 0.00002 | Regression loss: 0.00286 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 163 | Classification loss: 0.00009 | Regression loss: 0.00474 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 164 | Classification loss: 0.00031 | Regression loss: 0.00416 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 165 | Classification loss: 0.00019 | Regression loss: 0.00601 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 166 | Classification loss: 0.00034 | Regression loss: 0.00395 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 167 | Classification loss: 0.00014 | Regression loss: 0.01377 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 168 | Classification loss: 0.00007 | Regression loss: 0.00702 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 169 | Classification loss: 0.00050 | Regression loss: 0.00434 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 170 | Classification loss: 0.00002 | Regression loss: 0.00281 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 171 | Classification loss: 0.00005 | Regression loss: 0.00322 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 172 | Classification loss: 0.00021 | Regression loss: 0.01240 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 173 | Classification loss: 0.00003 | Regression loss: 0.00278 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 174 | Classification loss: 0.00003 | Regression loss: 0.00185 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 175 | Classification loss: 0.00004 | Regression loss: 0.00466 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 176 | Classification loss: 0.00022 | Regression loss: 0.00471 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 177 | Classification loss: 0.00058 | Regression loss: 0.00482 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 178 | Classification loss: 0.00007 | Regression loss: 0.01096 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 179 | Classification loss: 0.00002 | Regression loss: 0.00455 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 180 | Classification loss: 0.00174 | Regression loss: 0.01355 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 181 | Classification loss: 0.00001 | Regression loss: 0.00159 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 182 | Classification loss: 0.00005 | Regression loss: 0.00486 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 183 | Classification loss: 0.00005 | Regression loss: 0.00199 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 184 | Classification loss: 0.00000 | Regression loss: 0.00195 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 185 | Classification loss: 0.00004 | Regression loss: 0.00378 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 186 | Classification loss: 0.00007 | Regression loss: 0.00786 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 187 | Classification loss: 0.00005 | Regression loss: 0.00184 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 188 | Classification loss: 0.00003 | Regression loss: 0.00225 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 189 | Classification loss: 0.00002 | Regression loss: 0.00716 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 190 | Classification loss: 0.00009 | Regression loss: 0.00594 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 191 | Classification loss: 0.00002 | Regression loss: 0.00309 | Running loss: 0.00634\n",
            "Epoch: 49 | Iteration: 192 | Classification loss: 0.00048 | Regression loss: 0.00643 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 193 | Classification loss: 0.00001 | Regression loss: 0.00246 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 194 | Classification loss: 0.00010 | Regression loss: 0.00842 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 195 | Classification loss: 0.00022 | Regression loss: 0.00343 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 196 | Classification loss: 0.00001 | Regression loss: 0.00253 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 197 | Classification loss: 0.00003 | Regression loss: 0.00629 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 198 | Classification loss: 0.00017 | Regression loss: 0.00608 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 199 | Classification loss: 0.00007 | Regression loss: 0.00435 | Running loss: 0.00627\n",
            "Epoch: 49 | Iteration: 200 | Classification loss: 0.00026 | Regression loss: 0.04467 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 201 | Classification loss: 0.00023 | Regression loss: 0.00323 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 202 | Classification loss: 0.00009 | Regression loss: 0.02014 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 203 | Classification loss: 0.00014 | Regression loss: 0.00323 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 204 | Classification loss: 0.00008 | Regression loss: 0.00344 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 205 | Classification loss: 0.00006 | Regression loss: 0.00430 | Running loss: 0.00639\n",
            "Epoch: 49 | Iteration: 206 | Classification loss: 0.00002 | Regression loss: 0.00317 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 207 | Classification loss: 0.00023 | Regression loss: 0.00231 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 208 | Classification loss: 0.00005 | Regression loss: 0.00511 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 209 | Classification loss: 0.00007 | Regression loss: 0.00362 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 210 | Classification loss: 0.00004 | Regression loss: 0.00457 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 211 | Classification loss: 0.00011 | Regression loss: 0.00250 | Running loss: 0.00635\n",
            "Epoch: 49 | Iteration: 212 | Classification loss: 0.00018 | Regression loss: 0.01817 | Running loss: 0.00638\n",
            "Epoch: 49 | Iteration: 213 | Classification loss: 0.00001 | Regression loss: 0.00209 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 214 | Classification loss: 0.00002 | Regression loss: 0.00184 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 215 | Classification loss: 0.00007 | Regression loss: 0.00268 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 216 | Classification loss: 0.00006 | Regression loss: 0.00299 | Running loss: 0.00637\n",
            "Epoch: 49 | Iteration: 217 | Classification loss: 0.00017 | Regression loss: 0.00246 | Running loss: 0.00636\n",
            "Epoch: 49 | Iteration: 218 | Classification loss: 0.00010 | Regression loss: 0.00328 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 219 | Classification loss: 0.00005 | Regression loss: 0.00517 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 220 | Classification loss: 0.00015 | Regression loss: 0.00421 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 221 | Classification loss: 0.00001 | Regression loss: 0.00387 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 222 | Classification loss: 0.00011 | Regression loss: 0.00319 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 223 | Classification loss: 0.00037 | Regression loss: 0.02533 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 224 | Classification loss: 0.00000 | Regression loss: 0.00260 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 225 | Classification loss: 0.00002 | Regression loss: 0.00243 | Running loss: 0.00633\n",
            "Epoch: 49 | Iteration: 226 | Classification loss: 0.00005 | Regression loss: 0.00200 | Running loss: 0.00631\n",
            "Epoch: 49 | Iteration: 227 | Classification loss: 0.00002 | Regression loss: 0.00593 | Running loss: 0.00632\n",
            "Epoch: 49 | Iteration: 228 | Classification loss: 0.00006 | Regression loss: 0.00129 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 229 | Classification loss: 0.00006 | Regression loss: 0.00370 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 230 | Classification loss: 0.00005 | Regression loss: 0.00397 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 231 | Classification loss: 0.00001 | Regression loss: 0.00155 | Running loss: 0.00628\n",
            "Epoch: 49 | Iteration: 232 | Classification loss: 0.00006 | Regression loss: 0.00401 | Running loss: 0.00628\n",
            "Epoch: 49 | Iteration: 233 | Classification loss: 0.00003 | Regression loss: 0.00268 | Running loss: 0.00628\n",
            "Epoch: 49 | Iteration: 234 | Classification loss: 0.00009 | Regression loss: 0.00709 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 235 | Classification loss: 0.00004 | Regression loss: 0.00341 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 236 | Classification loss: 0.00015 | Regression loss: 0.00720 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 237 | Classification loss: 0.00006 | Regression loss: 0.00201 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 238 | Classification loss: 0.00014 | Regression loss: 0.01062 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 239 | Classification loss: 0.00011 | Regression loss: 0.00232 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 240 | Classification loss: 0.00011 | Regression loss: 0.00395 | Running loss: 0.00628\n",
            "Epoch: 49 | Iteration: 241 | Classification loss: 0.00006 | Regression loss: 0.00293 | Running loss: 0.00627\n",
            "Epoch: 49 | Iteration: 242 | Classification loss: 0.00011 | Regression loss: 0.00685 | Running loss: 0.00628\n",
            "Epoch: 49 | Iteration: 243 | Classification loss: 0.00003 | Regression loss: 0.00281 | Running loss: 0.00628\n",
            "Epoch: 49 | Iteration: 244 | Classification loss: 0.00024 | Regression loss: 0.01649 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 245 | Classification loss: 0.00001 | Regression loss: 0.00188 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 246 | Classification loss: 0.00015 | Regression loss: 0.00288 | Running loss: 0.00630\n",
            "Epoch: 49 | Iteration: 247 | Classification loss: 0.00008 | Regression loss: 0.00799 | Running loss: 0.00629\n",
            "Epoch: 49 | Iteration: 248 | Classification loss: 0.00003 | Regression loss: 0.00285 | Running loss: 0.00625\n",
            "Epoch: 49 | Iteration: 249 | Classification loss: 0.00007 | Regression loss: 0.00374 | Running loss: 0.00626\n",
            "Epoch: 49 | Iteration: 250 | Classification loss: 0.00121 | Regression loss: 0.02051 | Running loss: 0.00627\n",
            "Epoch: 49 | Iteration: 251 | Classification loss: 0.00004 | Regression loss: 0.00388 | Running loss: 0.00627\n",
            "Epoch: 49 | Iteration: 252 | Classification loss: 0.00006 | Regression loss: 0.00172 | Running loss: 0.00626\n",
            "Epoch: 49 | Iteration: 253 | Classification loss: 0.00013 | Regression loss: 0.00303 | Running loss: 0.00625\n",
            "Epoch: 49 | Iteration: 254 | Classification loss: 0.00007 | Regression loss: 0.00544 | Running loss: 0.00625\n",
            "Epoch: 49 | Iteration: 255 | Classification loss: 0.00009 | Regression loss: 0.00497 | Running loss: 0.00625\n",
            "Epoch: 49 | Iteration: 256 | Classification loss: 0.00005 | Regression loss: 0.00356 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 257 | Classification loss: 0.00002 | Regression loss: 0.00615 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 258 | Classification loss: 0.00003 | Regression loss: 0.00388 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 259 | Classification loss: 0.00001 | Regression loss: 0.00248 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 260 | Classification loss: 0.00012 | Regression loss: 0.00301 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 261 | Classification loss: 0.00024 | Regression loss: 0.01179 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 262 | Classification loss: 0.00002 | Regression loss: 0.00426 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 263 | Classification loss: 0.00007 | Regression loss: 0.00505 | Running loss: 0.00616\n",
            "Epoch: 49 | Iteration: 264 | Classification loss: 0.00004 | Regression loss: 0.00621 | Running loss: 0.00617\n",
            "Epoch: 49 | Iteration: 265 | Classification loss: 0.00001 | Regression loss: 0.00432 | Running loss: 0.00617\n",
            "Epoch: 49 | Iteration: 266 | Classification loss: 0.00022 | Regression loss: 0.01249 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 267 | Classification loss: 0.00012 | Regression loss: 0.00204 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 268 | Classification loss: 0.00002 | Regression loss: 0.00252 | Running loss: 0.00618\n",
            "Epoch: 49 | Iteration: 269 | Classification loss: 0.00078 | Regression loss: 0.00590 | Running loss: 0.00618\n",
            "Epoch: 49 | Iteration: 270 | Classification loss: 0.00043 | Regression loss: 0.00512 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 271 | Classification loss: 0.00004 | Regression loss: 0.00178 | Running loss: 0.00618\n",
            "Epoch: 49 | Iteration: 272 | Classification loss: 0.00007 | Regression loss: 0.00376 | Running loss: 0.00618\n",
            "Epoch: 49 | Iteration: 273 | Classification loss: 0.00008 | Regression loss: 0.00952 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 274 | Classification loss: 0.00030 | Regression loss: 0.00862 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 275 | Classification loss: 0.00056 | Regression loss: 0.06000 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 276 | Classification loss: 0.00007 | Regression loss: 0.00358 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 277 | Classification loss: 0.00004 | Regression loss: 0.00204 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 278 | Classification loss: 0.00001 | Regression loss: 0.00202 | Running loss: 0.00618\n",
            "Epoch: 49 | Iteration: 279 | Classification loss: 0.00083 | Regression loss: 0.00759 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 280 | Classification loss: 0.00002 | Regression loss: 0.00300 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 281 | Classification loss: 0.00014 | Regression loss: 0.00814 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 282 | Classification loss: 0.00007 | Regression loss: 0.01605 | Running loss: 0.00622\n",
            "Epoch: 49 | Iteration: 283 | Classification loss: 0.00006 | Regression loss: 0.00265 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 284 | Classification loss: 0.00013 | Regression loss: 0.00502 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 285 | Classification loss: 0.00001 | Regression loss: 0.00287 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 286 | Classification loss: 0.00002 | Regression loss: 0.00211 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 287 | Classification loss: 0.00002 | Regression loss: 0.00365 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 288 | Classification loss: 0.00008 | Regression loss: 0.00435 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 289 | Classification loss: 0.00004 | Regression loss: 0.00383 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 290 | Classification loss: 0.00004 | Regression loss: 0.00188 | Running loss: 0.00618\n",
            "Epoch: 49 | Iteration: 291 | Classification loss: 0.00011 | Regression loss: 0.00416 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 292 | Classification loss: 0.00007 | Regression loss: 0.00529 | Running loss: 0.00611\n",
            "Epoch: 49 | Iteration: 293 | Classification loss: 0.00001 | Regression loss: 0.00229 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 294 | Classification loss: 0.00005 | Regression loss: 0.00451 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 295 | Classification loss: 0.00019 | Regression loss: 0.00598 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 296 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 297 | Classification loss: 0.00001 | Regression loss: 0.00701 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 298 | Classification loss: 0.00006 | Regression loss: 0.00431 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 299 | Classification loss: 0.00013 | Regression loss: 0.00619 | Running loss: 0.00611\n",
            "Epoch: 49 | Iteration: 300 | Classification loss: 0.00003 | Regression loss: 0.00187 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 301 | Classification loss: 0.00058 | Regression loss: 0.00981 | Running loss: 0.00612\n",
            "Epoch: 49 | Iteration: 302 | Classification loss: 0.00006 | Regression loss: 0.00406 | Running loss: 0.00612\n",
            "Epoch: 49 | Iteration: 303 | Classification loss: 0.00009 | Regression loss: 0.00679 | Running loss: 0.00613\n",
            "Epoch: 49 | Iteration: 304 | Classification loss: 0.00011 | Regression loss: 0.01051 | Running loss: 0.00614\n",
            "Epoch: 49 | Iteration: 305 | Classification loss: 0.00008 | Regression loss: 0.01106 | Running loss: 0.00616\n",
            "Epoch: 49 | Iteration: 306 | Classification loss: 0.00003 | Regression loss: 0.00211 | Running loss: 0.00616\n",
            "Epoch: 49 | Iteration: 307 | Classification loss: 0.00005 | Regression loss: 0.01154 | Running loss: 0.00617\n",
            "Epoch: 49 | Iteration: 308 | Classification loss: 0.00006 | Regression loss: 0.00179 | Running loss: 0.00617\n",
            "Epoch: 49 | Iteration: 309 | Classification loss: 0.00008 | Regression loss: 0.00847 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 310 | Classification loss: 0.00001 | Regression loss: 0.00894 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 311 | Classification loss: 0.00009 | Regression loss: 0.00577 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 312 | Classification loss: 0.00001 | Regression loss: 0.00206 | Running loss: 0.00619\n",
            "Epoch: 49 | Iteration: 313 | Classification loss: 0.00005 | Regression loss: 0.00533 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 314 | Classification loss: 0.00016 | Regression loss: 0.00757 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 315 | Classification loss: 0.00036 | Regression loss: 0.00986 | Running loss: 0.00622\n",
            "Epoch: 49 | Iteration: 316 | Classification loss: 0.00012 | Regression loss: 0.00568 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 317 | Classification loss: 0.00017 | Regression loss: 0.00242 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 318 | Classification loss: 0.00002 | Regression loss: 0.00198 | Running loss: 0.00621\n",
            "Epoch: 49 | Iteration: 319 | Classification loss: 0.00001 | Regression loss: 0.00178 | Running loss: 0.00620\n",
            "Epoch: 49 | Iteration: 320 | Classification loss: 0.00005 | Regression loss: 0.00529 | Running loss: 0.00617\n",
            "Epoch: 49 | Iteration: 321 | Classification loss: 0.00004 | Regression loss: 0.00460 | Running loss: 0.00616\n",
            "Epoch: 49 | Iteration: 322 | Classification loss: 0.00002 | Regression loss: 0.00218 | Running loss: 0.00615\n",
            "Epoch: 49 | Iteration: 323 | Classification loss: 0.00001 | Regression loss: 0.00287 | Running loss: 0.00613\n",
            "Epoch: 49 | Iteration: 324 | Classification loss: 0.00002 | Regression loss: 0.00422 | Running loss: 0.00612\n",
            "Epoch: 49 | Iteration: 325 | Classification loss: 0.00001 | Regression loss: 0.00189 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 326 | Classification loss: 0.00003 | Regression loss: 0.00208 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 327 | Classification loss: 0.00001 | Regression loss: 0.00528 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 328 | Classification loss: 0.00003 | Regression loss: 0.00466 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 329 | Classification loss: 0.00003 | Regression loss: 0.00241 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 330 | Classification loss: 0.00008 | Regression loss: 0.00342 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 331 | Classification loss: 0.00015 | Regression loss: 0.00364 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 332 | Classification loss: 0.00007 | Regression loss: 0.00423 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 333 | Classification loss: 0.00046 | Regression loss: 0.00529 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 334 | Classification loss: 0.00002 | Regression loss: 0.00261 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 335 | Classification loss: 0.00007 | Regression loss: 0.00830 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 336 | Classification loss: 0.00005 | Regression loss: 0.00500 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 337 | Classification loss: 0.00003 | Regression loss: 0.01101 | Running loss: 0.00608\n",
            "Epoch: 49 | Iteration: 338 | Classification loss: 0.00001 | Regression loss: 0.00165 | Running loss: 0.00607\n",
            "Epoch: 49 | Iteration: 339 | Classification loss: 0.00018 | Regression loss: 0.01492 | Running loss: 0.00609\n",
            "Epoch: 49 | Iteration: 340 | Classification loss: 0.00038 | Regression loss: 0.01113 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 341 | Classification loss: 0.00005 | Regression loss: 0.00191 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 342 | Classification loss: 0.00012 | Regression loss: 0.00326 | Running loss: 0.00610\n",
            "Epoch: 49 | Iteration: 343 | Classification loss: 0.00009 | Regression loss: 0.01020 | Running loss: 0.00611\n",
            "Epoch: 49 | Iteration: 344 | Classification loss: 0.00001 | Regression loss: 0.00109 | Running loss: 0.00608\n",
            "Epoch: 49 | Iteration: 345 | Classification loss: 0.00001 | Regression loss: 0.00453 | Running loss: 0.00607\n",
            "Epoch: 49 | Iteration: 346 | Classification loss: 0.00003 | Regression loss: 0.00367 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 347 | Classification loss: 0.00004 | Regression loss: 0.00544 | Running loss: 0.00607\n",
            "Epoch: 49 | Iteration: 348 | Classification loss: 0.00029 | Regression loss: 0.00925 | Running loss: 0.00608\n",
            "Epoch: 49 | Iteration: 349 | Classification loss: 0.00008 | Regression loss: 0.00155 | Running loss: 0.00607\n",
            "Epoch: 49 | Iteration: 350 | Classification loss: 0.00012 | Regression loss: 0.00423 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 351 | Classification loss: 0.00002 | Regression loss: 0.00351 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 352 | Classification loss: 0.00004 | Regression loss: 0.00296 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 353 | Classification loss: 0.00007 | Regression loss: 0.00423 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 354 | Classification loss: 0.00005 | Regression loss: 0.00760 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 355 | Classification loss: 0.00001 | Regression loss: 0.00304 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 356 | Classification loss: 0.00008 | Regression loss: 0.00445 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 357 | Classification loss: 0.00014 | Regression loss: 0.00163 | Running loss: 0.00595\n",
            "Epoch: 49 | Iteration: 358 | Classification loss: 0.00000 | Regression loss: 0.00274 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 359 | Classification loss: 0.00001 | Regression loss: 0.00130 | Running loss: 0.00595\n",
            "Epoch: 49 | Iteration: 360 | Classification loss: 0.00001 | Regression loss: 0.00204 | Running loss: 0.00594\n",
            "Epoch: 49 | Iteration: 361 | Classification loss: 0.00001 | Regression loss: 0.00126 | Running loss: 0.00584\n",
            "Epoch: 49 | Iteration: 362 | Classification loss: 0.00083 | Regression loss: 0.01652 | Running loss: 0.00582\n",
            "Epoch: 49 | Iteration: 363 | Classification loss: 0.00007 | Regression loss: 0.00505 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 364 | Classification loss: 0.00007 | Regression loss: 0.00220 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 365 | Classification loss: 0.00011 | Regression loss: 0.01078 | Running loss: 0.00583\n",
            "Epoch: 49 | Iteration: 366 | Classification loss: 0.00085 | Regression loss: 0.01932 | Running loss: 0.00586\n",
            "Epoch: 49 | Iteration: 367 | Classification loss: 0.00009 | Regression loss: 0.00480 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 368 | Classification loss: 0.00001 | Regression loss: 0.00118 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 369 | Classification loss: 0.00015 | Regression loss: 0.00419 | Running loss: 0.00579\n",
            "Epoch: 49 | Iteration: 370 | Classification loss: 0.00009 | Regression loss: 0.01136 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 371 | Classification loss: 0.00001 | Regression loss: 0.00356 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 372 | Classification loss: 0.00008 | Regression loss: 0.00762 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 373 | Classification loss: 0.00020 | Regression loss: 0.00186 | Running loss: 0.00579\n",
            "Epoch: 49 | Iteration: 374 | Classification loss: 0.00018 | Regression loss: 0.00334 | Running loss: 0.00579\n",
            "Epoch: 49 | Iteration: 375 | Classification loss: 0.00217 | Regression loss: 0.02223 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 376 | Classification loss: 0.00001 | Regression loss: 0.00200 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 377 | Classification loss: 0.00004 | Regression loss: 0.00400 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 378 | Classification loss: 0.00001 | Regression loss: 0.00260 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 379 | Classification loss: 0.00002 | Regression loss: 0.00387 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 380 | Classification loss: 0.00005 | Regression loss: 0.00395 | Running loss: 0.00580\n",
            "Epoch: 49 | Iteration: 381 | Classification loss: 0.00007 | Regression loss: 0.00465 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 382 | Classification loss: 0.00002 | Regression loss: 0.00355 | Running loss: 0.00581\n",
            "Epoch: 49 | Iteration: 383 | Classification loss: 0.00004 | Regression loss: 0.00377 | Running loss: 0.00567\n",
            "Epoch: 49 | Iteration: 384 | Classification loss: 0.00003 | Regression loss: 0.00244 | Running loss: 0.00567\n",
            "Epoch: 49 | Iteration: 385 | Classification loss: 0.00003 | Regression loss: 0.00253 | Running loss: 0.00566\n",
            "Epoch: 49 | Iteration: 386 | Classification loss: 0.00006 | Regression loss: 0.00117 | Running loss: 0.00565\n",
            "Epoch: 49 | Iteration: 387 | Classification loss: 0.00007 | Regression loss: 0.00507 | Running loss: 0.00566\n",
            "Epoch: 49 | Iteration: 388 | Classification loss: 0.00015 | Regression loss: 0.00542 | Running loss: 0.00566\n",
            "Epoch: 49 | Iteration: 389 | Classification loss: 0.00001 | Regression loss: 0.00914 | Running loss: 0.00567\n",
            "Epoch: 49 | Iteration: 390 | Classification loss: 0.00021 | Regression loss: 0.01418 | Running loss: 0.00569\n",
            "Epoch: 49 | Iteration: 391 | Classification loss: 0.00014 | Regression loss: 0.03302 | Running loss: 0.00575\n",
            "Epoch: 49 | Iteration: 392 | Classification loss: 0.00001 | Regression loss: 0.00189 | Running loss: 0.00575\n",
            "Epoch: 49 | Iteration: 393 | Classification loss: 0.00003 | Regression loss: 0.00373 | Running loss: 0.00575\n",
            "Epoch: 49 | Iteration: 394 | Classification loss: 0.00028 | Regression loss: 0.00399 | Running loss: 0.00575\n",
            "Epoch: 49 | Iteration: 395 | Classification loss: 0.00007 | Regression loss: 0.00446 | Running loss: 0.00574\n",
            "Epoch: 49 | Iteration: 396 | Classification loss: 0.00004 | Regression loss: 0.01305 | Running loss: 0.00575\n",
            "Epoch: 49 | Iteration: 397 | Classification loss: 0.00064 | Regression loss: 0.01874 | Running loss: 0.00579\n",
            "Epoch: 49 | Iteration: 398 | Classification loss: 0.00002 | Regression loss: 0.00550 | Running loss: 0.00579\n",
            "Epoch: 49 | Iteration: 399 | Classification loss: 0.00008 | Regression loss: 0.00275 | Running loss: 0.00579\n",
            "Epoch: 49 | Iteration: 400 | Classification loss: 0.00007 | Regression loss: 0.04895 | Running loss: 0.00587\n",
            "Epoch: 49 | Iteration: 401 | Classification loss: 0.00005 | Regression loss: 0.00333 | Running loss: 0.00587\n",
            "Epoch: 49 | Iteration: 402 | Classification loss: 0.00004 | Regression loss: 0.00520 | Running loss: 0.00588\n",
            "Epoch: 49 | Iteration: 403 | Classification loss: 0.00002 | Regression loss: 0.00280 | Running loss: 0.00587\n",
            "Epoch: 49 | Iteration: 404 | Classification loss: 0.00011 | Regression loss: 0.00382 | Running loss: 0.00587\n",
            "Epoch: 49 | Iteration: 405 | Classification loss: 0.00002 | Regression loss: 0.00133 | Running loss: 0.00586\n",
            "Epoch: 49 | Iteration: 406 | Classification loss: 0.00020 | Regression loss: 0.01298 | Running loss: 0.00588\n",
            "Epoch: 49 | Iteration: 407 | Classification loss: 0.00007 | Regression loss: 0.00276 | Running loss: 0.00587\n",
            "Epoch: 49 | Iteration: 408 | Classification loss: 0.00345 | Regression loss: 0.03581 | Running loss: 0.00594\n",
            "Epoch: 49 | Iteration: 409 | Classification loss: 0.00005 | Regression loss: 0.00558 | Running loss: 0.00595\n",
            "Epoch: 49 | Iteration: 410 | Classification loss: 0.00001 | Regression loss: 0.00290 | Running loss: 0.00595\n",
            "Epoch: 49 | Iteration: 411 | Classification loss: 0.00035 | Regression loss: 0.00699 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 412 | Classification loss: 0.00004 | Regression loss: 0.00315 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 413 | Classification loss: 0.00008 | Regression loss: 0.00532 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 414 | Classification loss: 0.00003 | Regression loss: 0.00420 | Running loss: 0.00597\n",
            "Epoch: 49 | Iteration: 415 | Classification loss: 0.00007 | Regression loss: 0.01115 | Running loss: 0.00598\n",
            "Epoch: 49 | Iteration: 416 | Classification loss: 0.00011 | Regression loss: 0.02766 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 417 | Classification loss: 0.00012 | Regression loss: 0.00841 | Running loss: 0.00602\n",
            "Epoch: 49 | Iteration: 418 | Classification loss: 0.00002 | Regression loss: 0.00433 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 419 | Classification loss: 0.00002 | Regression loss: 0.00453 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 420 | Classification loss: 0.00005 | Regression loss: 0.00394 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 421 | Classification loss: 0.00009 | Regression loss: 0.00599 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 422 | Classification loss: 0.00002 | Regression loss: 0.00419 | Running loss: 0.00597\n",
            "Epoch: 49 | Iteration: 423 | Classification loss: 0.00020 | Regression loss: 0.00472 | Running loss: 0.00597\n",
            "Epoch: 49 | Iteration: 424 | Classification loss: 0.00000 | Regression loss: 0.00236 | Running loss: 0.00593\n",
            "Epoch: 49 | Iteration: 425 | Classification loss: 0.00002 | Regression loss: 0.00236 | Running loss: 0.00593\n",
            "Epoch: 49 | Iteration: 426 | Classification loss: 0.00004 | Regression loss: 0.00357 | Running loss: 0.00593\n",
            "Epoch: 49 | Iteration: 427 | Classification loss: 0.00012 | Regression loss: 0.01138 | Running loss: 0.00594\n",
            "Epoch: 49 | Iteration: 428 | Classification loss: 0.00007 | Regression loss: 0.00273 | Running loss: 0.00593\n",
            "Epoch: 49 | Iteration: 429 | Classification loss: 0.00005 | Regression loss: 0.00243 | Running loss: 0.00590\n",
            "Epoch: 49 | Iteration: 430 | Classification loss: 0.00103 | Regression loss: 0.02303 | Running loss: 0.00593\n",
            "Epoch: 49 | Iteration: 431 | Classification loss: 0.00017 | Regression loss: 0.00900 | Running loss: 0.00594\n",
            "Epoch: 49 | Iteration: 432 | Classification loss: 0.00002 | Regression loss: 0.00355 | Running loss: 0.00595\n",
            "Epoch: 49 | Iteration: 433 | Classification loss: 0.00016 | Regression loss: 0.01131 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 434 | Classification loss: 0.00024 | Regression loss: 0.00370 | Running loss: 0.00597\n",
            "Epoch: 49 | Iteration: 435 | Classification loss: 0.00003 | Regression loss: 0.00356 | Running loss: 0.00597\n",
            "Epoch: 49 | Iteration: 436 | Classification loss: 0.00001 | Regression loss: 0.00170 | Running loss: 0.00596\n",
            "Epoch: 49 | Iteration: 437 | Classification loss: 0.00086 | Regression loss: 0.02409 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 438 | Classification loss: 0.00008 | Regression loss: 0.00829 | Running loss: 0.00602\n",
            "Epoch: 49 | Iteration: 439 | Classification loss: 0.00001 | Regression loss: 0.00210 | Running loss: 0.00602\n",
            "Epoch: 49 | Iteration: 440 | Classification loss: 0.00022 | Regression loss: 0.00449 | Running loss: 0.00602\n",
            "Epoch: 49 | Iteration: 441 | Classification loss: 0.00004 | Regression loss: 0.00280 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 442 | Classification loss: 0.00006 | Regression loss: 0.01605 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 443 | Classification loss: 0.00020 | Regression loss: 0.00378 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 444 | Classification loss: 0.00011 | Regression loss: 0.00452 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 445 | Classification loss: 0.00091 | Regression loss: 0.01957 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 446 | Classification loss: 0.00002 | Regression loss: 0.00263 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 447 | Classification loss: 0.00006 | Regression loss: 0.00307 | Running loss: 0.00606\n",
            "Epoch: 49 | Iteration: 448 | Classification loss: 0.00007 | Regression loss: 0.00377 | Running loss: 0.00602\n",
            "Epoch: 49 | Iteration: 449 | Classification loss: 0.00005 | Regression loss: 0.00423 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 450 | Classification loss: 0.00010 | Regression loss: 0.01538 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 451 | Classification loss: 0.00014 | Regression loss: 0.00282 | Running loss: 0.00604\n",
            "Epoch: 49 | Iteration: 452 | Classification loss: 0.00004 | Regression loss: 0.00234 | Running loss: 0.00605\n",
            "Epoch: 49 | Iteration: 453 | Classification loss: 0.00002 | Regression loss: 0.00290 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 454 | Classification loss: 0.00004 | Regression loss: 0.00267 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 455 | Classification loss: 0.00003 | Regression loss: 0.00269 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 456 | Classification loss: 0.00003 | Regression loss: 0.00406 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 457 | Classification loss: 0.00018 | Regression loss: 0.00574 | Running loss: 0.00603\n",
            "Epoch: 49 | Iteration: 458 | Classification loss: 0.00008 | Regression loss: 0.00248 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 459 | Classification loss: 0.00006 | Regression loss: 0.00394 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 460 | Classification loss: 0.00015 | Regression loss: 0.00599 | Running loss: 0.00602\n",
            "Epoch: 49 | Iteration: 461 | Classification loss: 0.00004 | Regression loss: 0.00284 | Running loss: 0.00601\n",
            "Epoch: 49 | Iteration: 462 | Classification loss: 0.00007 | Regression loss: 0.00326 | Running loss: 0.00600\n",
            "Epoch: 49 | Iteration: 463 | Classification loss: 0.00008 | Regression loss: 0.00316 | Running loss: 0.00600\n",
            "Epoch: 49 | Iteration: 464 | Classification loss: 0.00002 | Regression loss: 0.00224 | Running loss: 0.00598\n",
            "Epoch: 49 | Iteration: 465 | Classification loss: 0.00000 | Regression loss: 0.00199 | Running loss: 0.00599\n",
            "Epoch: 49 | Iteration: 466 | Classification loss: 0.00008 | Regression loss: 0.00658 | Running loss: 0.00599\n",
            "Epoch: 49 | Iteration: 467 | Classification loss: 0.00008 | Regression loss: 0.00228 | Running loss: 0.00599\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.7050262080472844\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.35869809203142544\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.45878167531393343\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5345155754041484\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.4\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 50 | Iteration: 0 | Classification loss: 0.00006 | Regression loss: 0.00303 | Running loss: 0.00599\n",
            "Epoch: 50 | Iteration: 1 | Classification loss: 0.00020 | Regression loss: 0.00434 | Running loss: 0.00600\n",
            "Epoch: 50 | Iteration: 2 | Classification loss: 0.00003 | Regression loss: 0.00373 | Running loss: 0.00599\n",
            "Epoch: 50 | Iteration: 3 | Classification loss: 0.00063 | Regression loss: 0.02051 | Running loss: 0.00602\n",
            "Epoch: 50 | Iteration: 4 | Classification loss: 0.00016 | Regression loss: 0.00478 | Running loss: 0.00603\n",
            "Epoch: 50 | Iteration: 5 | Classification loss: 0.00002 | Regression loss: 0.00296 | Running loss: 0.00603\n",
            "Epoch: 50 | Iteration: 6 | Classification loss: 0.00000 | Regression loss: 0.00204 | Running loss: 0.00601\n",
            "Epoch: 50 | Iteration: 7 | Classification loss: 0.00004 | Regression loss: 0.00370 | Running loss: 0.00601\n",
            "Epoch: 50 | Iteration: 8 | Classification loss: 0.00349 | Regression loss: 0.03003 | Running loss: 0.00607\n",
            "Epoch: 50 | Iteration: 9 | Classification loss: 0.00039 | Regression loss: 0.00732 | Running loss: 0.00605\n",
            "Epoch: 50 | Iteration: 10 | Classification loss: 0.00001 | Regression loss: 0.00200 | Running loss: 0.00603\n",
            "Epoch: 50 | Iteration: 11 | Classification loss: 0.00009 | Regression loss: 0.00536 | Running loss: 0.00603\n",
            "Epoch: 50 | Iteration: 12 | Classification loss: 0.00017 | Regression loss: 0.00600 | Running loss: 0.00603\n",
            "Epoch: 50 | Iteration: 13 | Classification loss: 0.00000 | Regression loss: 0.00223 | Running loss: 0.00603\n",
            "Epoch: 50 | Iteration: 14 | Classification loss: 0.00001 | Regression loss: 0.00278 | Running loss: 0.00602\n",
            "Epoch: 50 | Iteration: 15 | Classification loss: 0.00001 | Regression loss: 0.00261 | Running loss: 0.00602\n",
            "Epoch: 50 | Iteration: 16 | Classification loss: 0.00002 | Regression loss: 0.00184 | Running loss: 0.00602\n",
            "Epoch: 50 | Iteration: 17 | Classification loss: 0.00001 | Regression loss: 0.00151 | Running loss: 0.00601\n",
            "Epoch: 50 | Iteration: 18 | Classification loss: 0.00002 | Regression loss: 0.00474 | Running loss: 0.00597\n",
            "Epoch: 50 | Iteration: 19 | Classification loss: 0.00003 | Regression loss: 0.00295 | Running loss: 0.00597\n",
            "Epoch: 50 | Iteration: 20 | Classification loss: 0.00021 | Regression loss: 0.00854 | Running loss: 0.00598\n",
            "Epoch: 50 | Iteration: 21 | Classification loss: 0.00002 | Regression loss: 0.00279 | Running loss: 0.00598\n",
            "Epoch: 50 | Iteration: 22 | Classification loss: 0.00003 | Regression loss: 0.00144 | Running loss: 0.00597\n",
            "Epoch: 50 | Iteration: 23 | Classification loss: 0.00000 | Regression loss: 0.00336 | Running loss: 0.00597\n",
            "Epoch: 50 | Iteration: 24 | Classification loss: 0.00004 | Regression loss: 0.00135 | Running loss: 0.00595\n",
            "Epoch: 50 | Iteration: 25 | Classification loss: 0.00001 | Regression loss: 0.00168 | Running loss: 0.00594\n",
            "Epoch: 50 | Iteration: 26 | Classification loss: 0.00001 | Regression loss: 0.00159 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 27 | Classification loss: 0.00006 | Regression loss: 0.00578 | Running loss: 0.00594\n",
            "Epoch: 50 | Iteration: 28 | Classification loss: 0.00005 | Regression loss: 0.00318 | Running loss: 0.00594\n",
            "Epoch: 50 | Iteration: 29 | Classification loss: 0.00032 | Regression loss: 0.01359 | Running loss: 0.00595\n",
            "Epoch: 50 | Iteration: 30 | Classification loss: 0.00004 | Regression loss: 0.00249 | Running loss: 0.00594\n",
            "Epoch: 50 | Iteration: 31 | Classification loss: 0.00005 | Regression loss: 0.00837 | Running loss: 0.00596\n",
            "Epoch: 50 | Iteration: 32 | Classification loss: 0.00020 | Regression loss: 0.00244 | Running loss: 0.00595\n",
            "Epoch: 50 | Iteration: 33 | Classification loss: 0.00011 | Regression loss: 0.00235 | Running loss: 0.00595\n",
            "Epoch: 50 | Iteration: 34 | Classification loss: 0.00001 | Regression loss: 0.00427 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 35 | Classification loss: 0.00001 | Regression loss: 0.00236 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 36 | Classification loss: 0.00008 | Regression loss: 0.00559 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 37 | Classification loss: 0.00003 | Regression loss: 0.00490 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 38 | Classification loss: 0.00001 | Regression loss: 0.00235 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 39 | Classification loss: 0.00017 | Regression loss: 0.00664 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 40 | Classification loss: 0.00003 | Regression loss: 0.00289 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 41 | Classification loss: 0.00006 | Regression loss: 0.00277 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 42 | Classification loss: 0.00002 | Regression loss: 0.00151 | Running loss: 0.00568\n",
            "Epoch: 50 | Iteration: 43 | Classification loss: 0.00001 | Regression loss: 0.00187 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 44 | Classification loss: 0.00050 | Regression loss: 0.00515 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 45 | Classification loss: 0.00001 | Regression loss: 0.00208 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 46 | Classification loss: 0.00005 | Regression loss: 0.00265 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 47 | Classification loss: 0.00007 | Regression loss: 0.00222 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 48 | Classification loss: 0.00008 | Regression loss: 0.00340 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 49 | Classification loss: 0.00002 | Regression loss: 0.00185 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 50 | Classification loss: 0.00007 | Regression loss: 0.00341 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 51 | Classification loss: 0.00002 | Regression loss: 0.00231 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 52 | Classification loss: 0.00003 | Regression loss: 0.00385 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 53 | Classification loss: 0.00006 | Regression loss: 0.00288 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 54 | Classification loss: 0.00001 | Regression loss: 0.00301 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 55 | Classification loss: 0.00019 | Regression loss: 0.00525 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 56 | Classification loss: 0.00002 | Regression loss: 0.00512 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 57 | Classification loss: 0.00002 | Regression loss: 0.00468 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 58 | Classification loss: 0.00000 | Regression loss: 0.00316 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 59 | Classification loss: 0.00006 | Regression loss: 0.00840 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 60 | Classification loss: 0.00003 | Regression loss: 0.00342 | Running loss: 0.00561\n",
            "Epoch: 50 | Iteration: 61 | Classification loss: 0.00016 | Regression loss: 0.01309 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 62 | Classification loss: 0.00001 | Regression loss: 0.00580 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 63 | Classification loss: 0.00021 | Regression loss: 0.00380 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 64 | Classification loss: 0.00003 | Regression loss: 0.00635 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 65 | Classification loss: 0.00018 | Regression loss: 0.00291 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 66 | Classification loss: 0.00001 | Regression loss: 0.00203 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 67 | Classification loss: 0.00015 | Regression loss: 0.00276 | Running loss: 0.00563\n",
            "Epoch: 50 | Iteration: 68 | Classification loss: 0.00068 | Regression loss: 0.01956 | Running loss: 0.00567\n",
            "Epoch: 50 | Iteration: 69 | Classification loss: 0.00071 | Regression loss: 0.01146 | Running loss: 0.00565\n",
            "Epoch: 50 | Iteration: 70 | Classification loss: 0.00014 | Regression loss: 0.00485 | Running loss: 0.00566\n",
            "Epoch: 50 | Iteration: 71 | Classification loss: 0.00007 | Regression loss: 0.00380 | Running loss: 0.00566\n",
            "Epoch: 50 | Iteration: 72 | Classification loss: 0.00001 | Regression loss: 0.00433 | Running loss: 0.00566\n",
            "Epoch: 50 | Iteration: 73 | Classification loss: 0.00056 | Regression loss: 0.00878 | Running loss: 0.00567\n",
            "Epoch: 50 | Iteration: 74 | Classification loss: 0.00010 | Regression loss: 0.00569 | Running loss: 0.00568\n",
            "Epoch: 50 | Iteration: 75 | Classification loss: 0.00014 | Regression loss: 0.00845 | Running loss: 0.00569\n",
            "Epoch: 50 | Iteration: 76 | Classification loss: 0.00002 | Regression loss: 0.01903 | Running loss: 0.00572\n",
            "Epoch: 50 | Iteration: 77 | Classification loss: 0.00010 | Regression loss: 0.00628 | Running loss: 0.00572\n",
            "Epoch: 50 | Iteration: 78 | Classification loss: 0.00003 | Regression loss: 0.00710 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 79 | Classification loss: 0.00003 | Regression loss: 0.01934 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 80 | Classification loss: 0.00003 | Regression loss: 0.00288 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 81 | Classification loss: 0.00002 | Regression loss: 0.00354 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 82 | Classification loss: 0.00003 | Regression loss: 0.00368 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 83 | Classification loss: 0.00008 | Regression loss: 0.00288 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 84 | Classification loss: 0.00006 | Regression loss: 0.00273 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 85 | Classification loss: 0.00001 | Regression loss: 0.00260 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 86 | Classification loss: 0.00002 | Regression loss: 0.00370 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 87 | Classification loss: 0.00007 | Regression loss: 0.00311 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 88 | Classification loss: 0.00034 | Regression loss: 0.00466 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 89 | Classification loss: 0.00034 | Regression loss: 0.00395 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 90 | Classification loss: 0.00005 | Regression loss: 0.00486 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 91 | Classification loss: 0.00006 | Regression loss: 0.00406 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 92 | Classification loss: 0.00005 | Regression loss: 0.00536 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 93 | Classification loss: 0.00001 | Regression loss: 0.00336 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 94 | Classification loss: 0.00006 | Regression loss: 0.00570 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 95 | Classification loss: 0.00081 | Regression loss: 0.01372 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 96 | Classification loss: 0.00001 | Regression loss: 0.00238 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 97 | Classification loss: 0.00003 | Regression loss: 0.00582 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 98 | Classification loss: 0.00015 | Regression loss: 0.00967 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 99 | Classification loss: 0.00012 | Regression loss: 0.00460 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 100 | Classification loss: 0.00002 | Regression loss: 0.00263 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 101 | Classification loss: 0.00006 | Regression loss: 0.00546 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 102 | Classification loss: 0.00073 | Regression loss: 0.01738 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 103 | Classification loss: 0.00010 | Regression loss: 0.00298 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 104 | Classification loss: 0.00045 | Regression loss: 0.00315 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 105 | Classification loss: 0.00003 | Regression loss: 0.00179 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 106 | Classification loss: 0.00001 | Regression loss: 0.00467 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 107 | Classification loss: 0.00003 | Regression loss: 0.00231 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 108 | Classification loss: 0.00015 | Regression loss: 0.00848 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 109 | Classification loss: 0.00005 | Regression loss: 0.00301 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 110 | Classification loss: 0.00008 | Regression loss: 0.00745 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 111 | Classification loss: 0.00031 | Regression loss: 0.00425 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 112 | Classification loss: 0.00002 | Regression loss: 0.00195 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 113 | Classification loss: 0.00006 | Regression loss: 0.00227 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 114 | Classification loss: 0.00011 | Regression loss: 0.00655 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 115 | Classification loss: 0.00013 | Regression loss: 0.00828 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 116 | Classification loss: 0.00010 | Regression loss: 0.00197 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 117 | Classification loss: 0.00014 | Regression loss: 0.00310 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 118 | Classification loss: 0.00002 | Regression loss: 0.00478 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 119 | Classification loss: 0.00001 | Regression loss: 0.00342 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 120 | Classification loss: 0.00005 | Regression loss: 0.00196 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 121 | Classification loss: 0.00004 | Regression loss: 0.00329 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 122 | Classification loss: 0.00007 | Regression loss: 0.00188 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 123 | Classification loss: 0.00021 | Regression loss: 0.00999 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 124 | Classification loss: 0.00006 | Regression loss: 0.00857 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 125 | Classification loss: 0.00000 | Regression loss: 0.00172 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 126 | Classification loss: 0.00002 | Regression loss: 0.00232 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 127 | Classification loss: 0.00000 | Regression loss: 0.00248 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 128 | Classification loss: 0.00002 | Regression loss: 0.00319 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 129 | Classification loss: 0.00009 | Regression loss: 0.00312 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 130 | Classification loss: 0.00004 | Regression loss: 0.00219 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 131 | Classification loss: 0.00007 | Regression loss: 0.00358 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 132 | Classification loss: 0.00002 | Regression loss: 0.00312 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 133 | Classification loss: 0.00003 | Regression loss: 0.00666 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 134 | Classification loss: 0.00002 | Regression loss: 0.00259 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 135 | Classification loss: 0.00001 | Regression loss: 0.00237 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 136 | Classification loss: 0.00005 | Regression loss: 0.00717 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 137 | Classification loss: 0.00005 | Regression loss: 0.00265 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 138 | Classification loss: 0.00018 | Regression loss: 0.00534 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 139 | Classification loss: 0.00004 | Regression loss: 0.00242 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 140 | Classification loss: 0.00014 | Regression loss: 0.01211 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 141 | Classification loss: 0.00001 | Regression loss: 0.00118 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 142 | Classification loss: 0.00003 | Regression loss: 0.00279 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 143 | Classification loss: 0.00009 | Regression loss: 0.01248 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 144 | Classification loss: 0.00003 | Regression loss: 0.00262 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 145 | Classification loss: 0.00015 | Regression loss: 0.06445 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 146 | Classification loss: 0.00024 | Regression loss: 0.00740 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 147 | Classification loss: 0.00004 | Regression loss: 0.00494 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 148 | Classification loss: 0.00002 | Regression loss: 0.00355 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 149 | Classification loss: 0.00006 | Regression loss: 0.02378 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 150 | Classification loss: 0.00002 | Regression loss: 0.00194 | Running loss: 0.00592\n",
            "Epoch: 50 | Iteration: 151 | Classification loss: 0.00008 | Regression loss: 0.00334 | Running loss: 0.00591\n",
            "Epoch: 50 | Iteration: 152 | Classification loss: 0.00001 | Regression loss: 0.00613 | Running loss: 0.00592\n",
            "Epoch: 50 | Iteration: 153 | Classification loss: 0.00008 | Regression loss: 0.00283 | Running loss: 0.00592\n",
            "Epoch: 50 | Iteration: 154 | Classification loss: 0.00020 | Regression loss: 0.00252 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 155 | Classification loss: 0.00005 | Regression loss: 0.00160 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 156 | Classification loss: 0.00002 | Regression loss: 0.00309 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 157 | Classification loss: 0.00003 | Regression loss: 0.00146 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 158 | Classification loss: 0.00003 | Regression loss: 0.00201 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 159 | Classification loss: 0.00010 | Regression loss: 0.00334 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 160 | Classification loss: 0.00003 | Regression loss: 0.00286 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 161 | Classification loss: 0.00016 | Regression loss: 0.01106 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 162 | Classification loss: 0.00012 | Regression loss: 0.00216 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 163 | Classification loss: 0.00001 | Regression loss: 0.00224 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 164 | Classification loss: 0.00003 | Regression loss: 0.00237 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 165 | Classification loss: 0.00013 | Regression loss: 0.01056 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 166 | Classification loss: 0.00007 | Regression loss: 0.00156 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 167 | Classification loss: 0.00005 | Regression loss: 0.00417 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 168 | Classification loss: 0.00001 | Regression loss: 0.00416 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 169 | Classification loss: 0.00006 | Regression loss: 0.00352 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 170 | Classification loss: 0.00006 | Regression loss: 0.00224 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 171 | Classification loss: 0.00008 | Regression loss: 0.00247 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 172 | Classification loss: 0.00006 | Regression loss: 0.00156 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 173 | Classification loss: 0.00005 | Regression loss: 0.00312 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 174 | Classification loss: 0.00007 | Regression loss: 0.00258 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 175 | Classification loss: 0.00046 | Regression loss: 0.00362 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 176 | Classification loss: 0.00006 | Regression loss: 0.00345 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 177 | Classification loss: 0.00003 | Regression loss: 0.00278 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 178 | Classification loss: 0.00012 | Regression loss: 0.00723 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 179 | Classification loss: 0.00007 | Regression loss: 0.00304 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 180 | Classification loss: 0.00010 | Regression loss: 0.00232 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 181 | Classification loss: 0.00003 | Regression loss: 0.00234 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 182 | Classification loss: 0.00004 | Regression loss: 0.00220 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 183 | Classification loss: 0.00005 | Regression loss: 0.00548 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 184 | Classification loss: 0.00001 | Regression loss: 0.00277 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 185 | Classification loss: 0.00002 | Regression loss: 0.00480 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 186 | Classification loss: 0.00019 | Regression loss: 0.02009 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 187 | Classification loss: 0.00001 | Regression loss: 0.00362 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 188 | Classification loss: 0.00003 | Regression loss: 0.00273 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 189 | Classification loss: 0.00000 | Regression loss: 0.00119 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 190 | Classification loss: 0.00002 | Regression loss: 0.00322 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 191 | Classification loss: 0.00003 | Regression loss: 0.00612 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 192 | Classification loss: 0.00010 | Regression loss: 0.01022 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 193 | Classification loss: 0.00001 | Regression loss: 0.00185 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 194 | Classification loss: 0.00001 | Regression loss: 0.00299 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 195 | Classification loss: 0.00019 | Regression loss: 0.00405 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 196 | Classification loss: 0.00006 | Regression loss: 0.00262 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 197 | Classification loss: 0.00009 | Regression loss: 0.00361 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 198 | Classification loss: 0.00003 | Regression loss: 0.01058 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 199 | Classification loss: 0.00003 | Regression loss: 0.00364 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 200 | Classification loss: 0.00000 | Regression loss: 0.00202 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 201 | Classification loss: 0.00001 | Regression loss: 0.00238 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 202 | Classification loss: 0.00003 | Regression loss: 0.00251 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 203 | Classification loss: 0.00004 | Regression loss: 0.00177 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 204 | Classification loss: 0.00009 | Regression loss: 0.00135 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 205 | Classification loss: 0.00003 | Regression loss: 0.00204 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 206 | Classification loss: 0.00009 | Regression loss: 0.00380 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 207 | Classification loss: 0.00009 | Regression loss: 0.00339 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 208 | Classification loss: 0.00017 | Regression loss: 0.00325 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 209 | Classification loss: 0.00015 | Regression loss: 0.00459 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 210 | Classification loss: 0.00003 | Regression loss: 0.00415 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 211 | Classification loss: 0.00014 | Regression loss: 0.00408 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 212 | Classification loss: 0.00023 | Regression loss: 0.01056 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 213 | Classification loss: 0.00007 | Regression loss: 0.00266 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 214 | Classification loss: 0.00002 | Regression loss: 0.00231 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 215 | Classification loss: 0.00014 | Regression loss: 0.00313 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 216 | Classification loss: 0.00012 | Regression loss: 0.00178 | Running loss: 0.00574\n",
            "Epoch: 50 | Iteration: 217 | Classification loss: 0.00038 | Regression loss: 0.01698 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 218 | Classification loss: 0.00003 | Regression loss: 0.00324 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 219 | Classification loss: 0.00001 | Regression loss: 0.00486 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 220 | Classification loss: 0.00002 | Regression loss: 0.00262 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 221 | Classification loss: 0.00013 | Regression loss: 0.00616 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 222 | Classification loss: 0.00003 | Regression loss: 0.00282 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 223 | Classification loss: 0.00002 | Regression loss: 0.00230 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 224 | Classification loss: 0.00003 | Regression loss: 0.00307 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 225 | Classification loss: 0.00050 | Regression loss: 0.01333 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 226 | Classification loss: 0.00004 | Regression loss: 0.00301 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 227 | Classification loss: 0.00000 | Regression loss: 0.00222 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 228 | Classification loss: 0.00014 | Regression loss: 0.00824 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 229 | Classification loss: 0.00013 | Regression loss: 0.00210 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 230 | Classification loss: 0.00005 | Regression loss: 0.00222 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 231 | Classification loss: 0.00001 | Regression loss: 0.00121 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 232 | Classification loss: 0.00010 | Regression loss: 0.00334 | Running loss: 0.00566\n",
            "Epoch: 50 | Iteration: 233 | Classification loss: 0.00141 | Regression loss: 0.02003 | Running loss: 0.00570\n",
            "Epoch: 50 | Iteration: 234 | Classification loss: 0.00001 | Regression loss: 0.00264 | Running loss: 0.00566\n",
            "Epoch: 50 | Iteration: 235 | Classification loss: 0.00006 | Regression loss: 0.01064 | Running loss: 0.00568\n",
            "Epoch: 50 | Iteration: 236 | Classification loss: 0.00066 | Regression loss: 0.05604 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 237 | Classification loss: 0.00024 | Regression loss: 0.01558 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 238 | Classification loss: 0.00011 | Regression loss: 0.00194 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 239 | Classification loss: 0.00005 | Regression loss: 0.00691 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 240 | Classification loss: 0.00005 | Regression loss: 0.00491 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 241 | Classification loss: 0.00001 | Regression loss: 0.00141 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 242 | Classification loss: 0.00005 | Regression loss: 0.00201 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 243 | Classification loss: 0.00010 | Regression loss: 0.00460 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 244 | Classification loss: 0.00004 | Regression loss: 0.00225 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 245 | Classification loss: 0.00003 | Regression loss: 0.00262 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 246 | Classification loss: 0.00000 | Regression loss: 0.00181 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 247 | Classification loss: 0.00000 | Regression loss: 0.00210 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 248 | Classification loss: 0.00004 | Regression loss: 0.00363 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 249 | Classification loss: 0.00024 | Regression loss: 0.00420 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 250 | Classification loss: 0.00011 | Regression loss: 0.01656 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 251 | Classification loss: 0.00004 | Regression loss: 0.00668 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 252 | Classification loss: 0.00004 | Regression loss: 0.00145 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 253 | Classification loss: 0.00029 | Regression loss: 0.01045 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 254 | Classification loss: 0.00016 | Regression loss: 0.00361 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 255 | Classification loss: 0.00004 | Regression loss: 0.00563 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 256 | Classification loss: 0.00168 | Regression loss: 0.05217 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 257 | Classification loss: 0.00001 | Regression loss: 0.00314 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 258 | Classification loss: 0.00057 | Regression loss: 0.00799 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 259 | Classification loss: 0.00009 | Regression loss: 0.00286 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 260 | Classification loss: 0.00005 | Regression loss: 0.00334 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 261 | Classification loss: 0.00012 | Regression loss: 0.00559 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 262 | Classification loss: 0.00005 | Regression loss: 0.00253 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 263 | Classification loss: 0.00001 | Regression loss: 0.00135 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 264 | Classification loss: 0.00001 | Regression loss: 0.00230 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 265 | Classification loss: 0.00003 | Regression loss: 0.00339 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 266 | Classification loss: 0.00002 | Regression loss: 0.00985 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 267 | Classification loss: 0.00001 | Regression loss: 0.00535 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 268 | Classification loss: 0.00011 | Regression loss: 0.00733 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 269 | Classification loss: 0.00002 | Regression loss: 0.00155 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 270 | Classification loss: 0.00001 | Regression loss: 0.00172 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 271 | Classification loss: 0.00000 | Regression loss: 0.00203 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 272 | Classification loss: 0.00004 | Regression loss: 0.00377 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 273 | Classification loss: 0.00004 | Regression loss: 0.00224 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 274 | Classification loss: 0.00002 | Regression loss: 0.00194 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 275 | Classification loss: 0.00001 | Regression loss: 0.00446 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 276 | Classification loss: 0.00008 | Regression loss: 0.00330 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 277 | Classification loss: 0.00002 | Regression loss: 0.00284 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 278 | Classification loss: 0.00001 | Regression loss: 0.00449 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 279 | Classification loss: 0.00001 | Regression loss: 0.00235 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 280 | Classification loss: 0.00002 | Regression loss: 0.00358 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 281 | Classification loss: 0.00013 | Regression loss: 0.00305 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 282 | Classification loss: 0.00017 | Regression loss: 0.00254 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 283 | Classification loss: 0.00006 | Regression loss: 0.01072 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 284 | Classification loss: 0.00004 | Regression loss: 0.00256 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 285 | Classification loss: 0.00001 | Regression loss: 0.00205 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 286 | Classification loss: 0.00006 | Regression loss: 0.00554 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 287 | Classification loss: 0.00004 | Regression loss: 0.00344 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 288 | Classification loss: 0.00004 | Regression loss: 0.00257 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 289 | Classification loss: 0.00001 | Regression loss: 0.00198 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 290 | Classification loss: 0.00001 | Regression loss: 0.00200 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 291 | Classification loss: 0.00002 | Regression loss: 0.00321 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 292 | Classification loss: 0.00005 | Regression loss: 0.00419 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 293 | Classification loss: 0.00011 | Regression loss: 0.00511 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 294 | Classification loss: 0.00008 | Regression loss: 0.00422 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 295 | Classification loss: 0.00003 | Regression loss: 0.00645 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 296 | Classification loss: 0.00017 | Regression loss: 0.00579 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 297 | Classification loss: 0.00003 | Regression loss: 0.00306 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 298 | Classification loss: 0.00013 | Regression loss: 0.01352 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 299 | Classification loss: 0.00012 | Regression loss: 0.00291 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 300 | Classification loss: 0.00041 | Regression loss: 0.01082 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 301 | Classification loss: 0.00006 | Regression loss: 0.00318 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 302 | Classification loss: 0.00001 | Regression loss: 0.00322 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 303 | Classification loss: 0.00010 | Regression loss: 0.00800 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 304 | Classification loss: 0.00013 | Regression loss: 0.00414 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 305 | Classification loss: 0.00008 | Regression loss: 0.00381 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 306 | Classification loss: 0.00001 | Regression loss: 0.00216 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 307 | Classification loss: 0.00024 | Regression loss: 0.04096 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 308 | Classification loss: 0.00045 | Regression loss: 0.00898 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 309 | Classification loss: 0.00016 | Regression loss: 0.00511 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 310 | Classification loss: 0.00009 | Regression loss: 0.00182 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 311 | Classification loss: 0.00014 | Regression loss: 0.00302 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 312 | Classification loss: 0.00001 | Regression loss: 0.00447 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 313 | Classification loss: 0.00008 | Regression loss: 0.00226 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 314 | Classification loss: 0.00005 | Regression loss: 0.00224 | Running loss: 0.00572\n",
            "Epoch: 50 | Iteration: 315 | Classification loss: 0.00008 | Regression loss: 0.00716 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 316 | Classification loss: 0.00001 | Regression loss: 0.00522 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 317 | Classification loss: 0.00007 | Regression loss: 0.00296 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 318 | Classification loss: 0.00024 | Regression loss: 0.01127 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 319 | Classification loss: 0.00027 | Regression loss: 0.01116 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 320 | Classification loss: 0.00003 | Regression loss: 0.00403 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 321 | Classification loss: 0.00123 | Regression loss: 0.03772 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 322 | Classification loss: 0.00007 | Regression loss: 0.00279 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 323 | Classification loss: 0.00004 | Regression loss: 0.00128 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 324 | Classification loss: 0.00002 | Regression loss: 0.00215 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 325 | Classification loss: 0.00052 | Regression loss: 0.01026 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 326 | Classification loss: 0.00009 | Regression loss: 0.00568 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 327 | Classification loss: 0.00004 | Regression loss: 0.00357 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 328 | Classification loss: 0.00001 | Regression loss: 0.00636 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 329 | Classification loss: 0.00004 | Regression loss: 0.00362 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 330 | Classification loss: 0.00002 | Regression loss: 0.00305 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 331 | Classification loss: 0.00003 | Regression loss: 0.00444 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 332 | Classification loss: 0.00014 | Regression loss: 0.01088 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 333 | Classification loss: 0.00004 | Regression loss: 0.00330 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 334 | Classification loss: 0.00005 | Regression loss: 0.00405 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 335 | Classification loss: 0.00011 | Regression loss: 0.00470 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 336 | Classification loss: 0.00002 | Regression loss: 0.00265 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 337 | Classification loss: 0.00009 | Regression loss: 0.00324 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 338 | Classification loss: 0.00002 | Regression loss: 0.00339 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 339 | Classification loss: 0.00006 | Regression loss: 0.00295 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 340 | Classification loss: 0.00005 | Regression loss: 0.00321 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 341 | Classification loss: 0.00005 | Regression loss: 0.00542 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 342 | Classification loss: 0.00002 | Regression loss: 0.00275 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 343 | Classification loss: 0.00023 | Regression loss: 0.00494 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 344 | Classification loss: 0.00014 | Regression loss: 0.01000 | Running loss: 0.00578\n",
            "Epoch: 50 | Iteration: 345 | Classification loss: 0.00001 | Regression loss: 0.00185 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 346 | Classification loss: 0.00044 | Regression loss: 0.00313 | Running loss: 0.00577\n",
            "Epoch: 50 | Iteration: 347 | Classification loss: 0.00002 | Regression loss: 0.00267 | Running loss: 0.00575\n",
            "Epoch: 50 | Iteration: 348 | Classification loss: 0.00023 | Regression loss: 0.01083 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 349 | Classification loss: 0.00003 | Regression loss: 0.00291 | Running loss: 0.00576\n",
            "Epoch: 50 | Iteration: 350 | Classification loss: 0.00039 | Regression loss: 0.02441 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 351 | Classification loss: 0.00005 | Regression loss: 0.00267 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 352 | Classification loss: 0.00000 | Regression loss: 0.00187 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 353 | Classification loss: 0.00010 | Regression loss: 0.00428 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 354 | Classification loss: 0.00011 | Regression loss: 0.00755 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 355 | Classification loss: 0.00004 | Regression loss: 0.00472 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 356 | Classification loss: 0.00104 | Regression loss: 0.02202 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 357 | Classification loss: 0.00002 | Regression loss: 0.00199 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 358 | Classification loss: 0.00017 | Regression loss: 0.01343 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 359 | Classification loss: 0.00004 | Regression loss: 0.00651 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 360 | Classification loss: 0.00001 | Regression loss: 0.00251 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 361 | Classification loss: 0.00005 | Regression loss: 0.00307 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 362 | Classification loss: 0.00009 | Regression loss: 0.00317 | Running loss: 0.00588\n",
            "Epoch: 50 | Iteration: 363 | Classification loss: 0.00002 | Regression loss: 0.00181 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 364 | Classification loss: 0.00002 | Regression loss: 0.00229 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 365 | Classification loss: 0.00002 | Regression loss: 0.00140 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 366 | Classification loss: 0.00001 | Regression loss: 0.00249 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 367 | Classification loss: 0.00000 | Regression loss: 0.00212 | Running loss: 0.00585\n",
            "Epoch: 50 | Iteration: 368 | Classification loss: 0.00002 | Regression loss: 0.00316 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 369 | Classification loss: 0.00001 | Regression loss: 0.00142 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 370 | Classification loss: 0.00008 | Regression loss: 0.00267 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 371 | Classification loss: 0.00017 | Regression loss: 0.00161 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 372 | Classification loss: 0.00008 | Regression loss: 0.00527 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 373 | Classification loss: 0.00006 | Regression loss: 0.00255 | Running loss: 0.00579\n",
            "Epoch: 50 | Iteration: 374 | Classification loss: 0.00009 | Regression loss: 0.00802 | Running loss: 0.00580\n",
            "Epoch: 50 | Iteration: 375 | Classification loss: 0.00061 | Regression loss: 0.01655 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 376 | Classification loss: 0.00015 | Regression loss: 0.00790 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 377 | Classification loss: 0.00068 | Regression loss: 0.01986 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 378 | Classification loss: 0.00000 | Regression loss: 0.00741 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 379 | Classification loss: 0.00036 | Regression loss: 0.00701 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 380 | Classification loss: 0.00020 | Regression loss: 0.00546 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 381 | Classification loss: 0.00002 | Regression loss: 0.00233 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 382 | Classification loss: 0.00011 | Regression loss: 0.00314 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 383 | Classification loss: 0.00006 | Regression loss: 0.00306 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 384 | Classification loss: 0.00007 | Regression loss: 0.00484 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 385 | Classification loss: 0.00001 | Regression loss: 0.00297 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 386 | Classification loss: 0.00005 | Regression loss: 0.00957 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 387 | Classification loss: 0.00008 | Regression loss: 0.00666 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 388 | Classification loss: 0.00008 | Regression loss: 0.00301 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 389 | Classification loss: 0.00007 | Regression loss: 0.00318 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 390 | Classification loss: 0.00019 | Regression loss: 0.00375 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 391 | Classification loss: 0.00011 | Regression loss: 0.00808 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 392 | Classification loss: 0.00001 | Regression loss: 0.00389 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 393 | Classification loss: 0.00000 | Regression loss: 0.00169 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 394 | Classification loss: 0.00023 | Regression loss: 0.00784 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 395 | Classification loss: 0.00001 | Regression loss: 0.00172 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 396 | Classification loss: 0.00001 | Regression loss: 0.00238 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 397 | Classification loss: 0.00014 | Regression loss: 0.03098 | Running loss: 0.00591\n",
            "Epoch: 50 | Iteration: 398 | Classification loss: 0.00000 | Regression loss: 0.00203 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 399 | Classification loss: 0.00007 | Regression loss: 0.00501 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 400 | Classification loss: 0.00002 | Regression loss: 0.00260 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 401 | Classification loss: 0.00013 | Regression loss: 0.01077 | Running loss: 0.00589\n",
            "Epoch: 50 | Iteration: 402 | Classification loss: 0.00002 | Regression loss: 0.00312 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 403 | Classification loss: 0.00020 | Regression loss: 0.00435 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 404 | Classification loss: 0.00001 | Regression loss: 0.00158 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 405 | Classification loss: 0.00006 | Regression loss: 0.00343 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 406 | Classification loss: 0.00001 | Regression loss: 0.00521 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 407 | Classification loss: 0.00003 | Regression loss: 0.00310 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 408 | Classification loss: 0.00023 | Regression loss: 0.00624 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 409 | Classification loss: 0.00010 | Regression loss: 0.00412 | Running loss: 0.00583\n",
            "Epoch: 50 | Iteration: 410 | Classification loss: 0.00012 | Regression loss: 0.00685 | Running loss: 0.00584\n",
            "Epoch: 50 | Iteration: 411 | Classification loss: 0.00006 | Regression loss: 0.04726 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 412 | Classification loss: 0.00007 | Regression loss: 0.00506 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 413 | Classification loss: 0.00001 | Regression loss: 0.00417 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 414 | Classification loss: 0.00005 | Regression loss: 0.00291 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 415 | Classification loss: 0.00002 | Regression loss: 0.00347 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 416 | Classification loss: 0.00003 | Regression loss: 0.00380 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 417 | Classification loss: 0.00009 | Regression loss: 0.00418 | Running loss: 0.00594\n",
            "Epoch: 50 | Iteration: 418 | Classification loss: 0.00003 | Regression loss: 0.00307 | Running loss: 0.00594\n",
            "Epoch: 50 | Iteration: 419 | Classification loss: 0.00005 | Regression loss: 0.00237 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 420 | Classification loss: 0.00017 | Regression loss: 0.00550 | Running loss: 0.00593\n",
            "Epoch: 50 | Iteration: 421 | Classification loss: 0.00023 | Regression loss: 0.00332 | Running loss: 0.00592\n",
            "Epoch: 50 | Iteration: 422 | Classification loss: 0.00014 | Regression loss: 0.00507 | Running loss: 0.00590\n",
            "Epoch: 50 | Iteration: 423 | Classification loss: 0.00011 | Regression loss: 0.01705 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 424 | Classification loss: 0.00001 | Regression loss: 0.00238 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 425 | Classification loss: 0.00001 | Regression loss: 0.00228 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 426 | Classification loss: 0.00003 | Regression loss: 0.00296 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 427 | Classification loss: 0.00011 | Regression loss: 0.00658 | Running loss: 0.00587\n",
            "Epoch: 50 | Iteration: 428 | Classification loss: 0.00002 | Regression loss: 0.00467 | Running loss: 0.00586\n",
            "Epoch: 50 | Iteration: 429 | Classification loss: 0.00004 | Regression loss: 0.00257 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 430 | Classification loss: 0.00014 | Regression loss: 0.00264 | Running loss: 0.00582\n",
            "Epoch: 50 | Iteration: 431 | Classification loss: 0.00001 | Regression loss: 0.00178 | Running loss: 0.00581\n",
            "Epoch: 50 | Iteration: 432 | Classification loss: 0.00007 | Regression loss: 0.00442 | Running loss: 0.00572\n",
            "Epoch: 50 | Iteration: 433 | Classification loss: 0.00001 | Regression loss: 0.00570 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 434 | Classification loss: 0.00006 | Regression loss: 0.00297 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 435 | Classification loss: 0.00003 | Regression loss: 0.00424 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 436 | Classification loss: 0.00001 | Regression loss: 0.00435 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 437 | Classification loss: 0.00008 | Regression loss: 0.00290 | Running loss: 0.00573\n",
            "Epoch: 50 | Iteration: 438 | Classification loss: 0.00002 | Regression loss: 0.00281 | Running loss: 0.00571\n",
            "Epoch: 50 | Iteration: 439 | Classification loss: 0.00009 | Regression loss: 0.00506 | Running loss: 0.00572\n",
            "Epoch: 50 | Iteration: 440 | Classification loss: 0.00017 | Regression loss: 0.01046 | Running loss: 0.00566\n",
            "Epoch: 50 | Iteration: 441 | Classification loss: 0.00001 | Regression loss: 0.00226 | Running loss: 0.00565\n",
            "Epoch: 50 | Iteration: 442 | Classification loss: 0.00016 | Regression loss: 0.00250 | Running loss: 0.00565\n",
            "Epoch: 50 | Iteration: 443 | Classification loss: 0.00006 | Regression loss: 0.00384 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 444 | Classification loss: 0.00008 | Regression loss: 0.00269 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 445 | Classification loss: 0.00009 | Regression loss: 0.00299 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 446 | Classification loss: 0.00001 | Regression loss: 0.00255 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 447 | Classification loss: 0.00002 | Regression loss: 0.01321 | Running loss: 0.00564\n",
            "Epoch: 50 | Iteration: 448 | Classification loss: 0.00019 | Regression loss: 0.00450 | Running loss: 0.00559\n",
            "Epoch: 50 | Iteration: 449 | Classification loss: 0.00003 | Regression loss: 0.00183 | Running loss: 0.00558\n",
            "Epoch: 50 | Iteration: 450 | Classification loss: 0.00002 | Regression loss: 0.00344 | Running loss: 0.00558\n",
            "Epoch: 50 | Iteration: 451 | Classification loss: 0.00018 | Regression loss: 0.00625 | Running loss: 0.00558\n",
            "Epoch: 50 | Iteration: 452 | Classification loss: 0.00016 | Regression loss: 0.00381 | Running loss: 0.00558\n",
            "Epoch: 50 | Iteration: 453 | Classification loss: 0.00001 | Regression loss: 0.00201 | Running loss: 0.00557\n",
            "Epoch: 50 | Iteration: 454 | Classification loss: 0.00004 | Regression loss: 0.00265 | Running loss: 0.00557\n",
            "Epoch: 50 | Iteration: 455 | Classification loss: 0.00012 | Regression loss: 0.00581 | Running loss: 0.00557\n",
            "Epoch: 50 | Iteration: 456 | Classification loss: 0.00004 | Regression loss: 0.00189 | Running loss: 0.00557\n",
            "Epoch: 50 | Iteration: 457 | Classification loss: 0.00003 | Regression loss: 0.00378 | Running loss: 0.00558\n",
            "Epoch: 50 | Iteration: 458 | Classification loss: 0.00004 | Regression loss: 0.00200 | Running loss: 0.00557\n",
            "Epoch: 50 | Iteration: 459 | Classification loss: 0.00004 | Regression loss: 0.00243 | Running loss: 0.00555\n",
            "Epoch: 50 | Iteration: 460 | Classification loss: 0.00005 | Regression loss: 0.00245 | Running loss: 0.00555\n",
            "Epoch: 50 | Iteration: 461 | Classification loss: 0.00002 | Regression loss: 0.00328 | Running loss: 0.00556\n",
            "Epoch: 50 | Iteration: 462 | Classification loss: 0.00002 | Regression loss: 0.00232 | Running loss: 0.00551\n",
            "Epoch: 50 | Iteration: 463 | Classification loss: 0.00006 | Regression loss: 0.00526 | Running loss: 0.00550\n",
            "Epoch: 50 | Iteration: 464 | Classification loss: 0.00006 | Regression loss: 0.00324 | Running loss: 0.00550\n",
            "Epoch: 50 | Iteration: 465 | Classification loss: 0.00003 | Regression loss: 0.00686 | Running loss: 0.00549\n",
            "Epoch: 50 | Iteration: 466 | Classification loss: 0.00022 | Regression loss: 0.00918 | Running loss: 0.00551\n",
            "Epoch: 50 | Iteration: 467 | Classification loss: 0.00011 | Regression loss: 0.00188 | Running loss: 0.00550\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.690332260576163\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.354059829059829\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.460642303920336\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5350964655039359\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.4117647058823529\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 51 | Iteration: 0 | Classification loss: 0.00000 | Regression loss: 0.00143 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 1 | Classification loss: 0.00002 | Regression loss: 0.00296 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 2 | Classification loss: 0.00032 | Regression loss: 0.00447 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 3 | Classification loss: 0.00010 | Regression loss: 0.00611 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 4 | Classification loss: 0.00005 | Regression loss: 0.00305 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 5 | Classification loss: 0.00005 | Regression loss: 0.00504 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 6 | Classification loss: 0.00006 | Regression loss: 0.00681 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 7 | Classification loss: 0.00001 | Regression loss: 0.00177 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 8 | Classification loss: 0.00001 | Regression loss: 0.00262 | Running loss: 0.00543\n",
            "Epoch: 51 | Iteration: 9 | Classification loss: 0.00030 | Regression loss: 0.00906 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 10 | Classification loss: 0.00010 | Regression loss: 0.00439 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 11 | Classification loss: 0.00000 | Regression loss: 0.00188 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 12 | Classification loss: 0.00010 | Regression loss: 0.00135 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 13 | Classification loss: 0.00004 | Regression loss: 0.00279 | Running loss: 0.00540\n",
            "Epoch: 51 | Iteration: 14 | Classification loss: 0.00004 | Regression loss: 0.00181 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 15 | Classification loss: 0.00007 | Regression loss: 0.00420 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 16 | Classification loss: 0.00005 | Regression loss: 0.00326 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 17 | Classification loss: 0.00003 | Regression loss: 0.00436 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 18 | Classification loss: 0.00004 | Regression loss: 0.00303 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 19 | Classification loss: 0.00006 | Regression loss: 0.00131 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 20 | Classification loss: 0.00013 | Regression loss: 0.00768 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 21 | Classification loss: 0.00002 | Regression loss: 0.00496 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 22 | Classification loss: 0.00072 | Regression loss: 0.01973 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 23 | Classification loss: 0.00014 | Regression loss: 0.02558 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 24 | Classification loss: 0.00014 | Regression loss: 0.00653 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 25 | Classification loss: 0.00001 | Regression loss: 0.00308 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 26 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 27 | Classification loss: 0.00004 | Regression loss: 0.00464 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 28 | Classification loss: 0.00018 | Regression loss: 0.00279 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 29 | Classification loss: 0.00008 | Regression loss: 0.00195 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 30 | Classification loss: 0.00020 | Regression loss: 0.00819 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 31 | Classification loss: 0.00004 | Regression loss: 0.00185 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 32 | Classification loss: 0.00005 | Regression loss: 0.00152 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 33 | Classification loss: 0.00008 | Regression loss: 0.00433 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 34 | Classification loss: 0.00001 | Regression loss: 0.00214 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 35 | Classification loss: 0.00001 | Regression loss: 0.00566 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 36 | Classification loss: 0.00005 | Regression loss: 0.00816 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 37 | Classification loss: 0.00005 | Regression loss: 0.00157 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 38 | Classification loss: 0.00001 | Regression loss: 0.00206 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 39 | Classification loss: 0.00006 | Regression loss: 0.00202 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 40 | Classification loss: 0.00006 | Regression loss: 0.01720 | Running loss: 0.00540\n",
            "Epoch: 51 | Iteration: 41 | Classification loss: 0.00004 | Regression loss: 0.00226 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 42 | Classification loss: 0.00015 | Regression loss: 0.00540 | Running loss: 0.00540\n",
            "Epoch: 51 | Iteration: 43 | Classification loss: 0.00008 | Regression loss: 0.00170 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 44 | Classification loss: 0.00009 | Regression loss: 0.00388 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 45 | Classification loss: 0.00001 | Regression loss: 0.00379 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 46 | Classification loss: 0.00097 | Regression loss: 0.01538 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 47 | Classification loss: 0.00002 | Regression loss: 0.00350 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 48 | Classification loss: 0.00012 | Regression loss: 0.06298 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 49 | Classification loss: 0.00009 | Regression loss: 0.02392 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 50 | Classification loss: 0.00016 | Regression loss: 0.01089 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 51 | Classification loss: 0.00004 | Regression loss: 0.00217 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 52 | Classification loss: 0.00008 | Regression loss: 0.00197 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 53 | Classification loss: 0.00002 | Regression loss: 0.00370 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 54 | Classification loss: 0.00029 | Regression loss: 0.00699 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 55 | Classification loss: 0.00017 | Regression loss: 0.00493 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 56 | Classification loss: 0.00001 | Regression loss: 0.00220 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 57 | Classification loss: 0.00007 | Regression loss: 0.00199 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 58 | Classification loss: 0.00002 | Regression loss: 0.00331 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 59 | Classification loss: 0.00005 | Regression loss: 0.00398 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 60 | Classification loss: 0.00014 | Regression loss: 0.00702 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 61 | Classification loss: 0.00000 | Regression loss: 0.00167 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 62 | Classification loss: 0.00032 | Regression loss: 0.00938 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 63 | Classification loss: 0.00002 | Regression loss: 0.00124 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 64 | Classification loss: 0.00001 | Regression loss: 0.00262 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 65 | Classification loss: 0.00013 | Regression loss: 0.00595 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 66 | Classification loss: 0.00001 | Regression loss: 0.00153 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 67 | Classification loss: 0.00007 | Regression loss: 0.00325 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 68 | Classification loss: 0.00005 | Regression loss: 0.00940 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 69 | Classification loss: 0.00002 | Regression loss: 0.00134 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 70 | Classification loss: 0.00006 | Regression loss: 0.00977 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 71 | Classification loss: 0.00002 | Regression loss: 0.00193 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 72 | Classification loss: 0.00002 | Regression loss: 0.00175 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 73 | Classification loss: 0.00002 | Regression loss: 0.00245 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 74 | Classification loss: 0.00003 | Regression loss: 0.00351 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 75 | Classification loss: 0.00001 | Regression loss: 0.00251 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 76 | Classification loss: 0.00004 | Regression loss: 0.00362 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 77 | Classification loss: 0.00021 | Regression loss: 0.00422 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 78 | Classification loss: 0.00006 | Regression loss: 0.00246 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 79 | Classification loss: 0.00001 | Regression loss: 0.00306 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 80 | Classification loss: 0.00004 | Regression loss: 0.00616 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 81 | Classification loss: 0.00001 | Regression loss: 0.00188 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 82 | Classification loss: 0.00006 | Regression loss: 0.00145 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 83 | Classification loss: 0.00002 | Regression loss: 0.02747 | Running loss: 0.00565\n",
            "Epoch: 51 | Iteration: 84 | Classification loss: 0.00002 | Regression loss: 0.00263 | Running loss: 0.00565\n",
            "Epoch: 51 | Iteration: 85 | Classification loss: 0.00011 | Regression loss: 0.00353 | Running loss: 0.00565\n",
            "Epoch: 51 | Iteration: 86 | Classification loss: 0.00006 | Regression loss: 0.00120 | Running loss: 0.00565\n",
            "Epoch: 51 | Iteration: 87 | Classification loss: 0.00003 | Regression loss: 0.00389 | Running loss: 0.00565\n",
            "Epoch: 51 | Iteration: 88 | Classification loss: 0.00005 | Regression loss: 0.00189 | Running loss: 0.00564\n",
            "Epoch: 51 | Iteration: 89 | Classification loss: 0.00008 | Regression loss: 0.00209 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 90 | Classification loss: 0.00007 | Regression loss: 0.00249 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 91 | Classification loss: 0.00004 | Regression loss: 0.00310 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 92 | Classification loss: 0.00002 | Regression loss: 0.00283 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 93 | Classification loss: 0.00001 | Regression loss: 0.00427 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 94 | Classification loss: 0.00002 | Regression loss: 0.00339 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 95 | Classification loss: 0.00008 | Regression loss: 0.00256 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 96 | Classification loss: 0.00002 | Regression loss: 0.00132 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 97 | Classification loss: 0.00024 | Regression loss: 0.00354 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 98 | Classification loss: 0.00000 | Regression loss: 0.00183 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 99 | Classification loss: 0.00009 | Regression loss: 0.00672 | Running loss: 0.00559\n",
            "Epoch: 51 | Iteration: 100 | Classification loss: 0.00003 | Regression loss: 0.00241 | Running loss: 0.00556\n",
            "Epoch: 51 | Iteration: 101 | Classification loss: 0.00004 | Regression loss: 0.00126 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 102 | Classification loss: 0.00001 | Regression loss: 0.00242 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 103 | Classification loss: 0.00006 | Regression loss: 0.00242 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 104 | Classification loss: 0.00005 | Regression loss: 0.00367 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 105 | Classification loss: 0.00009 | Regression loss: 0.00615 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 106 | Classification loss: 0.00012 | Regression loss: 0.00294 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 107 | Classification loss: 0.00002 | Regression loss: 0.00346 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 108 | Classification loss: 0.00001 | Regression loss: 0.00348 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 109 | Classification loss: 0.00001 | Regression loss: 0.00187 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 110 | Classification loss: 0.00001 | Regression loss: 0.00153 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 111 | Classification loss: 0.00002 | Regression loss: 0.00273 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 112 | Classification loss: 0.00003 | Regression loss: 0.00198 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 113 | Classification loss: 0.00001 | Regression loss: 0.00124 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 114 | Classification loss: 0.00000 | Regression loss: 0.00183 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 115 | Classification loss: 0.00108 | Regression loss: 0.02230 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 116 | Classification loss: 0.00036 | Regression loss: 0.01067 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 117 | Classification loss: 0.00008 | Regression loss: 0.00469 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 118 | Classification loss: 0.00005 | Regression loss: 0.00661 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 119 | Classification loss: 0.00019 | Regression loss: 0.00298 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 120 | Classification loss: 0.00001 | Regression loss: 0.00233 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 121 | Classification loss: 0.00002 | Regression loss: 0.00479 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 122 | Classification loss: 0.00000 | Regression loss: 0.00385 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 123 | Classification loss: 0.00030 | Regression loss: 0.01024 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 124 | Classification loss: 0.00016 | Regression loss: 0.00283 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 125 | Classification loss: 0.00004 | Regression loss: 0.00454 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 126 | Classification loss: 0.00005 | Regression loss: 0.00444 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 127 | Classification loss: 0.00004 | Regression loss: 0.00464 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 128 | Classification loss: 0.00002 | Regression loss: 0.00171 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 129 | Classification loss: 0.00001 | Regression loss: 0.00489 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 130 | Classification loss: 0.00023 | Regression loss: 0.00631 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 131 | Classification loss: 0.00003 | Regression loss: 0.00343 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 132 | Classification loss: 0.00002 | Regression loss: 0.00215 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 133 | Classification loss: 0.00004 | Regression loss: 0.00241 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 134 | Classification loss: 0.00005 | Regression loss: 0.00401 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 135 | Classification loss: 0.00012 | Regression loss: 0.00309 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 136 | Classification loss: 0.00001 | Regression loss: 0.00224 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 137 | Classification loss: 0.00006 | Regression loss: 0.00183 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 138 | Classification loss: 0.00006 | Regression loss: 0.00362 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 139 | Classification loss: 0.00001 | Regression loss: 0.00367 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 140 | Classification loss: 0.00013 | Regression loss: 0.00267 | Running loss: 0.00540\n",
            "Epoch: 51 | Iteration: 141 | Classification loss: 0.00009 | Regression loss: 0.01067 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 142 | Classification loss: 0.00001 | Regression loss: 0.00147 | Running loss: 0.00540\n",
            "Epoch: 51 | Iteration: 143 | Classification loss: 0.00007 | Regression loss: 0.01167 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 144 | Classification loss: 0.00002 | Regression loss: 0.00744 | Running loss: 0.00543\n",
            "Epoch: 51 | Iteration: 145 | Classification loss: 0.00001 | Regression loss: 0.00170 | Running loss: 0.00543\n",
            "Epoch: 51 | Iteration: 146 | Classification loss: 0.00029 | Regression loss: 0.00393 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 147 | Classification loss: 0.00001 | Regression loss: 0.00176 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 148 | Classification loss: 0.00006 | Regression loss: 0.00220 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 149 | Classification loss: 0.00004 | Regression loss: 0.00133 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 150 | Classification loss: 0.00016 | Regression loss: 0.00874 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 151 | Classification loss: 0.00010 | Regression loss: 0.00740 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 152 | Classification loss: 0.00113 | Regression loss: 0.04066 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 153 | Classification loss: 0.00002 | Regression loss: 0.00627 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 154 | Classification loss: 0.00002 | Regression loss: 0.00153 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 155 | Classification loss: 0.00002 | Regression loss: 0.00304 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 156 | Classification loss: 0.00004 | Regression loss: 0.00169 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 157 | Classification loss: 0.00012 | Regression loss: 0.00288 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 158 | Classification loss: 0.00019 | Regression loss: 0.01373 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 159 | Classification loss: 0.00005 | Regression loss: 0.00325 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 160 | Classification loss: 0.00003 | Regression loss: 0.00113 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 161 | Classification loss: 0.00006 | Regression loss: 0.00272 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 162 | Classification loss: 0.00056 | Regression loss: 0.01379 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 163 | Classification loss: 0.00013 | Regression loss: 0.02081 | Running loss: 0.00556\n",
            "Epoch: 51 | Iteration: 164 | Classification loss: 0.00273 | Regression loss: 0.03086 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 165 | Classification loss: 0.00025 | Regression loss: 0.01181 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 166 | Classification loss: 0.00007 | Regression loss: 0.00502 | Running loss: 0.00564\n",
            "Epoch: 51 | Iteration: 167 | Classification loss: 0.00001 | Regression loss: 0.00153 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 168 | Classification loss: 0.00000 | Regression loss: 0.00248 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 169 | Classification loss: 0.00006 | Regression loss: 0.00197 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 170 | Classification loss: 0.00005 | Regression loss: 0.00327 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 171 | Classification loss: 0.00001 | Regression loss: 0.00431 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 172 | Classification loss: 0.00002 | Regression loss: 0.00264 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 173 | Classification loss: 0.00010 | Regression loss: 0.00817 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 174 | Classification loss: 0.00001 | Regression loss: 0.02511 | Running loss: 0.00566\n",
            "Epoch: 51 | Iteration: 175 | Classification loss: 0.00005 | Regression loss: 0.00297 | Running loss: 0.00564\n",
            "Epoch: 51 | Iteration: 176 | Classification loss: 0.00009 | Regression loss: 0.00854 | Running loss: 0.00566\n",
            "Epoch: 51 | Iteration: 177 | Classification loss: 0.00001 | Regression loss: 0.00241 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 178 | Classification loss: 0.00011 | Regression loss: 0.00336 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 179 | Classification loss: 0.00002 | Regression loss: 0.00475 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 180 | Classification loss: 0.00002 | Regression loss: 0.00160 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 181 | Classification loss: 0.00010 | Regression loss: 0.00987 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 182 | Classification loss: 0.00002 | Regression loss: 0.00147 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 183 | Classification loss: 0.00002 | Regression loss: 0.00246 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 184 | Classification loss: 0.00003 | Regression loss: 0.00275 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 185 | Classification loss: 0.00006 | Regression loss: 0.00294 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 186 | Classification loss: 0.00002 | Regression loss: 0.00430 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 187 | Classification loss: 0.00006 | Regression loss: 0.00367 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 188 | Classification loss: 0.00017 | Regression loss: 0.00653 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 189 | Classification loss: 0.00005 | Regression loss: 0.00501 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 190 | Classification loss: 0.00009 | Regression loss: 0.00260 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 191 | Classification loss: 0.00002 | Regression loss: 0.01139 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 192 | Classification loss: 0.00001 | Regression loss: 0.00440 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 193 | Classification loss: 0.00000 | Regression loss: 0.00262 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 194 | Classification loss: 0.00002 | Regression loss: 0.00254 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 195 | Classification loss: 0.00002 | Regression loss: 0.01326 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 196 | Classification loss: 0.00007 | Regression loss: 0.00337 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 197 | Classification loss: 0.00002 | Regression loss: 0.00353 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 198 | Classification loss: 0.00003 | Regression loss: 0.00441 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 199 | Classification loss: 0.00001 | Regression loss: 0.00274 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 200 | Classification loss: 0.00003 | Regression loss: 0.00245 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 201 | Classification loss: 0.00013 | Regression loss: 0.00501 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 202 | Classification loss: 0.00002 | Regression loss: 0.00235 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 203 | Classification loss: 0.00001 | Regression loss: 0.00242 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 204 | Classification loss: 0.00002 | Regression loss: 0.00186 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 205 | Classification loss: 0.00047 | Regression loss: 0.00990 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 206 | Classification loss: 0.00002 | Regression loss: 0.00176 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 207 | Classification loss: 0.00001 | Regression loss: 0.00227 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 208 | Classification loss: 0.00003 | Regression loss: 0.00969 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 209 | Classification loss: 0.00009 | Regression loss: 0.00907 | Running loss: 0.00555\n",
            "Epoch: 51 | Iteration: 210 | Classification loss: 0.00003 | Regression loss: 0.00235 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 211 | Classification loss: 0.00003 | Regression loss: 0.00205 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 212 | Classification loss: 0.00001 | Regression loss: 0.00185 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 213 | Classification loss: 0.00002 | Regression loss: 0.00253 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 214 | Classification loss: 0.00015 | Regression loss: 0.00321 | Running loss: 0.00554\n",
            "Epoch: 51 | Iteration: 215 | Classification loss: 0.00193 | Regression loss: 0.04841 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 216 | Classification loss: 0.00001 | Regression loss: 0.00252 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 217 | Classification loss: 0.00001 | Regression loss: 0.00277 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 218 | Classification loss: 0.00006 | Regression loss: 0.00477 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 219 | Classification loss: 0.00001 | Regression loss: 0.00486 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 220 | Classification loss: 0.00001 | Regression loss: 0.00186 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 221 | Classification loss: 0.00015 | Regression loss: 0.00418 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 222 | Classification loss: 0.00006 | Regression loss: 0.00513 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 223 | Classification loss: 0.00004 | Regression loss: 0.01386 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 224 | Classification loss: 0.00006 | Regression loss: 0.00336 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 225 | Classification loss: 0.00001 | Regression loss: 0.00233 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 226 | Classification loss: 0.00010 | Regression loss: 0.00317 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 227 | Classification loss: 0.00006 | Regression loss: 0.00382 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 228 | Classification loss: 0.00001 | Regression loss: 0.00446 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 229 | Classification loss: 0.00008 | Regression loss: 0.00665 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 230 | Classification loss: 0.00003 | Regression loss: 0.00340 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 231 | Classification loss: 0.00004 | Regression loss: 0.00311 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 232 | Classification loss: 0.00001 | Regression loss: 0.00157 | Running loss: 0.00560\n",
            "Epoch: 51 | Iteration: 233 | Classification loss: 0.00032 | Regression loss: 0.01459 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 234 | Classification loss: 0.00004 | Regression loss: 0.00316 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 235 | Classification loss: 0.00001 | Regression loss: 0.00192 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 236 | Classification loss: 0.00002 | Regression loss: 0.00269 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 237 | Classification loss: 0.00000 | Regression loss: 0.00195 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 238 | Classification loss: 0.00003 | Regression loss: 0.00276 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 239 | Classification loss: 0.00002 | Regression loss: 0.00187 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 240 | Classification loss: 0.00003 | Regression loss: 0.00506 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 241 | Classification loss: 0.00002 | Regression loss: 0.00208 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 242 | Classification loss: 0.00004 | Regression loss: 0.00244 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 243 | Classification loss: 0.00003 | Regression loss: 0.00564 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 244 | Classification loss: 0.00004 | Regression loss: 0.00309 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 245 | Classification loss: 0.00003 | Regression loss: 0.00186 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 246 | Classification loss: 0.00003 | Regression loss: 0.00293 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 247 | Classification loss: 0.00002 | Regression loss: 0.00284 | Running loss: 0.00561\n",
            "Epoch: 51 | Iteration: 248 | Classification loss: 0.00009 | Regression loss: 0.00548 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 249 | Classification loss: 0.00001 | Regression loss: 0.00169 | Running loss: 0.00558\n",
            "Epoch: 51 | Iteration: 250 | Classification loss: 0.00004 | Regression loss: 0.00230 | Running loss: 0.00558\n",
            "Epoch: 51 | Iteration: 251 | Classification loss: 0.00000 | Regression loss: 0.00380 | Running loss: 0.00558\n",
            "Epoch: 51 | Iteration: 252 | Classification loss: 0.00003 | Regression loss: 0.00245 | Running loss: 0.00558\n",
            "Epoch: 51 | Iteration: 253 | Classification loss: 0.00001 | Regression loss: 0.00188 | Running loss: 0.00557\n",
            "Epoch: 51 | Iteration: 254 | Classification loss: 0.00002 | Regression loss: 0.00291 | Running loss: 0.00557\n",
            "Epoch: 51 | Iteration: 255 | Classification loss: 0.00005 | Regression loss: 0.00795 | Running loss: 0.00558\n",
            "Epoch: 51 | Iteration: 256 | Classification loss: 0.00008 | Regression loss: 0.00219 | Running loss: 0.00558\n",
            "Epoch: 51 | Iteration: 257 | Classification loss: 0.00004 | Regression loss: 0.00171 | Running loss: 0.00556\n",
            "Epoch: 51 | Iteration: 258 | Classification loss: 0.00006 | Regression loss: 0.04686 | Running loss: 0.00565\n",
            "Epoch: 51 | Iteration: 259 | Classification loss: 0.00053 | Regression loss: 0.01650 | Running loss: 0.00567\n",
            "Epoch: 51 | Iteration: 260 | Classification loss: 0.00005 | Regression loss: 0.00212 | Running loss: 0.00566\n",
            "Epoch: 51 | Iteration: 261 | Classification loss: 0.00005 | Regression loss: 0.00179 | Running loss: 0.00566\n",
            "Epoch: 51 | Iteration: 262 | Classification loss: 0.00007 | Regression loss: 0.00305 | Running loss: 0.00566\n",
            "Epoch: 51 | Iteration: 263 | Classification loss: 0.00000 | Regression loss: 0.00244 | Running loss: 0.00567\n",
            "Epoch: 51 | Iteration: 264 | Classification loss: 0.00021 | Regression loss: 0.00478 | Running loss: 0.00567\n",
            "Epoch: 51 | Iteration: 265 | Classification loss: 0.00004 | Regression loss: 0.00294 | Running loss: 0.00563\n",
            "Epoch: 51 | Iteration: 266 | Classification loss: 0.00005 | Regression loss: 0.00746 | Running loss: 0.00564\n",
            "Epoch: 51 | Iteration: 267 | Classification loss: 0.00005 | Regression loss: 0.00206 | Running loss: 0.00562\n",
            "Epoch: 51 | Iteration: 268 | Classification loss: 0.00002 | Regression loss: 0.00198 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 269 | Classification loss: 0.00002 | Regression loss: 0.00169 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 270 | Classification loss: 0.00030 | Regression loss: 0.01930 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 271 | Classification loss: 0.00010 | Regression loss: 0.00291 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 272 | Classification loss: 0.00009 | Regression loss: 0.00277 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 273 | Classification loss: 0.00013 | Regression loss: 0.00306 | Running loss: 0.00551\n",
            "Epoch: 51 | Iteration: 274 | Classification loss: 0.00003 | Regression loss: 0.00486 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 275 | Classification loss: 0.00005 | Regression loss: 0.00287 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 276 | Classification loss: 0.00040 | Regression loss: 0.00586 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 277 | Classification loss: 0.00002 | Regression loss: 0.00366 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 278 | Classification loss: 0.00017 | Regression loss: 0.00279 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 279 | Classification loss: 0.00010 | Regression loss: 0.00364 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 280 | Classification loss: 0.00001 | Regression loss: 0.00224 | Running loss: 0.00553\n",
            "Epoch: 51 | Iteration: 281 | Classification loss: 0.00001 | Regression loss: 0.00174 | Running loss: 0.00552\n",
            "Epoch: 51 | Iteration: 282 | Classification loss: 0.00002 | Regression loss: 0.00372 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 283 | Classification loss: 0.00006 | Regression loss: 0.00250 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 284 | Classification loss: 0.00006 | Regression loss: 0.00614 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 285 | Classification loss: 0.00007 | Regression loss: 0.00388 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 286 | Classification loss: 0.00010 | Regression loss: 0.00873 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 287 | Classification loss: 0.00016 | Regression loss: 0.00511 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 288 | Classification loss: 0.00041 | Regression loss: 0.00833 | Running loss: 0.00540\n",
            "Epoch: 51 | Iteration: 289 | Classification loss: 0.00012 | Regression loss: 0.00557 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 290 | Classification loss: 0.00021 | Regression loss: 0.00944 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 291 | Classification loss: 0.00008 | Regression loss: 0.00305 | Running loss: 0.00541\n",
            "Epoch: 51 | Iteration: 292 | Classification loss: 0.00005 | Regression loss: 0.00782 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 293 | Classification loss: 0.00006 | Regression loss: 0.00861 | Running loss: 0.00543\n",
            "Epoch: 51 | Iteration: 294 | Classification loss: 0.00001 | Regression loss: 0.00164 | Running loss: 0.00542\n",
            "Epoch: 51 | Iteration: 295 | Classification loss: 0.00012 | Regression loss: 0.01220 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 296 | Classification loss: 0.00001 | Regression loss: 0.00196 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 297 | Classification loss: 0.00022 | Regression loss: 0.01121 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 298 | Classification loss: 0.00002 | Regression loss: 0.00501 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 299 | Classification loss: 0.00011 | Regression loss: 0.00941 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 300 | Classification loss: 0.00002 | Regression loss: 0.00321 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 301 | Classification loss: 0.00004 | Regression loss: 0.00198 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 302 | Classification loss: 0.00006 | Regression loss: 0.00658 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 303 | Classification loss: 0.00003 | Regression loss: 0.00225 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 304 | Classification loss: 0.00003 | Regression loss: 0.00452 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 305 | Classification loss: 0.00002 | Regression loss: 0.00224 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 306 | Classification loss: 0.00001 | Regression loss: 0.00171 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 307 | Classification loss: 0.00020 | Regression loss: 0.00844 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 308 | Classification loss: 0.00001 | Regression loss: 0.00322 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 309 | Classification loss: 0.00005 | Regression loss: 0.00420 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 310 | Classification loss: 0.00008 | Regression loss: 0.00729 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 311 | Classification loss: 0.00020 | Regression loss: 0.01180 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 312 | Classification loss: 0.00007 | Regression loss: 0.00222 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 313 | Classification loss: 0.00012 | Regression loss: 0.00560 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 314 | Classification loss: 0.00000 | Regression loss: 0.00215 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 315 | Classification loss: 0.00003 | Regression loss: 0.00768 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 316 | Classification loss: 0.00004 | Regression loss: 0.00164 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 317 | Classification loss: 0.00000 | Regression loss: 0.00192 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 318 | Classification loss: 0.00001 | Regression loss: 0.00192 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 319 | Classification loss: 0.00006 | Regression loss: 0.00256 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 320 | Classification loss: 0.00002 | Regression loss: 0.00234 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 321 | Classification loss: 0.00004 | Regression loss: 0.00625 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 322 | Classification loss: 0.00002 | Regression loss: 0.00235 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 323 | Classification loss: 0.00002 | Regression loss: 0.00268 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 324 | Classification loss: 0.00004 | Regression loss: 0.00694 | Running loss: 0.00550\n",
            "Epoch: 51 | Iteration: 325 | Classification loss: 0.00008 | Regression loss: 0.00253 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 326 | Classification loss: 0.00018 | Regression loss: 0.00542 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 327 | Classification loss: 0.00002 | Regression loss: 0.00329 | Running loss: 0.00549\n",
            "Epoch: 51 | Iteration: 328 | Classification loss: 0.00002 | Regression loss: 0.00230 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 329 | Classification loss: 0.00002 | Regression loss: 0.00241 | Running loss: 0.00548\n",
            "Epoch: 51 | Iteration: 330 | Classification loss: 0.00017 | Regression loss: 0.00160 | Running loss: 0.00546\n",
            "Epoch: 51 | Iteration: 331 | Classification loss: 0.00009 | Regression loss: 0.00252 | Running loss: 0.00545\n",
            "Epoch: 51 | Iteration: 332 | Classification loss: 0.00001 | Regression loss: 0.00202 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 333 | Classification loss: 0.00017 | Regression loss: 0.00437 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 334 | Classification loss: 0.00000 | Regression loss: 0.00237 | Running loss: 0.00544\n",
            "Epoch: 51 | Iteration: 335 | Classification loss: 0.00004 | Regression loss: 0.00234 | Running loss: 0.00543\n",
            "Epoch: 51 | Iteration: 336 | Classification loss: 0.00011 | Regression loss: 0.00370 | Running loss: 0.00543\n",
            "Epoch: 51 | Iteration: 337 | Classification loss: 0.00110 | Regression loss: 0.02454 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 338 | Classification loss: 0.00000 | Regression loss: 0.00203 | Running loss: 0.00547\n",
            "Epoch: 51 | Iteration: 339 | Classification loss: 0.00001 | Regression loss: 0.00206 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 340 | Classification loss: 0.00003 | Regression loss: 0.00322 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 341 | Classification loss: 0.00002 | Regression loss: 0.00110 | Running loss: 0.00537\n",
            "Epoch: 51 | Iteration: 342 | Classification loss: 0.00019 | Regression loss: 0.00570 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 343 | Classification loss: 0.00011 | Regression loss: 0.00610 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 344 | Classification loss: 0.00009 | Regression loss: 0.00423 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 345 | Classification loss: 0.00002 | Regression loss: 0.00345 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 346 | Classification loss: 0.00012 | Regression loss: 0.00269 | Running loss: 0.00539\n",
            "Epoch: 51 | Iteration: 347 | Classification loss: 0.00001 | Regression loss: 0.00327 | Running loss: 0.00538\n",
            "Epoch: 51 | Iteration: 348 | Classification loss: 0.00004 | Regression loss: 0.00180 | Running loss: 0.00537\n",
            "Epoch: 51 | Iteration: 349 | Classification loss: 0.00002 | Regression loss: 0.00244 | Running loss: 0.00537\n",
            "Epoch: 51 | Iteration: 350 | Classification loss: 0.00032 | Regression loss: 0.00490 | Running loss: 0.00536\n",
            "Epoch: 51 | Iteration: 351 | Classification loss: 0.00005 | Regression loss: 0.00304 | Running loss: 0.00534\n",
            "Epoch: 51 | Iteration: 352 | Classification loss: 0.00003 | Regression loss: 0.00322 | Running loss: 0.00534\n",
            "Epoch: 51 | Iteration: 353 | Classification loss: 0.00002 | Regression loss: 0.00126 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 354 | Classification loss: 0.00010 | Regression loss: 0.00273 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 355 | Classification loss: 0.00002 | Regression loss: 0.00277 | Running loss: 0.00527\n",
            "Epoch: 51 | Iteration: 356 | Classification loss: 0.00003 | Regression loss: 0.00211 | Running loss: 0.00527\n",
            "Epoch: 51 | Iteration: 357 | Classification loss: 0.00003 | Regression loss: 0.00610 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 358 | Classification loss: 0.00001 | Regression loss: 0.00177 | Running loss: 0.00525\n",
            "Epoch: 51 | Iteration: 359 | Classification loss: 0.00008 | Regression loss: 0.00398 | Running loss: 0.00525\n",
            "Epoch: 51 | Iteration: 360 | Classification loss: 0.00010 | Regression loss: 0.00283 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 361 | Classification loss: 0.00001 | Regression loss: 0.00210 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 362 | Classification loss: 0.00002 | Regression loss: 0.00127 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 363 | Classification loss: 0.00000 | Regression loss: 0.00175 | Running loss: 0.00523\n",
            "Epoch: 51 | Iteration: 364 | Classification loss: 0.00020 | Regression loss: 0.00643 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 365 | Classification loss: 0.00007 | Regression loss: 0.00409 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 366 | Classification loss: 0.00002 | Regression loss: 0.00380 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 367 | Classification loss: 0.00004 | Regression loss: 0.00400 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 368 | Classification loss: 0.00003 | Regression loss: 0.00291 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 369 | Classification loss: 0.00003 | Regression loss: 0.00205 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 370 | Classification loss: 0.00125 | Regression loss: 0.01147 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 371 | Classification loss: 0.00005 | Regression loss: 0.01089 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 372 | Classification loss: 0.00003 | Regression loss: 0.00600 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 373 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00525\n",
            "Epoch: 51 | Iteration: 374 | Classification loss: 0.00004 | Regression loss: 0.00449 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 375 | Classification loss: 0.00004 | Regression loss: 0.00246 | Running loss: 0.00525\n",
            "Epoch: 51 | Iteration: 376 | Classification loss: 0.00030 | Regression loss: 0.00536 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 377 | Classification loss: 0.00010 | Regression loss: 0.00231 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 378 | Classification loss: 0.00035 | Regression loss: 0.00257 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 379 | Classification loss: 0.00003 | Regression loss: 0.00181 | Running loss: 0.00524\n",
            "Epoch: 51 | Iteration: 380 | Classification loss: 0.00002 | Regression loss: 0.00387 | Running loss: 0.00523\n",
            "Epoch: 51 | Iteration: 381 | Classification loss: 0.00017 | Regression loss: 0.00520 | Running loss: 0.00523\n",
            "Epoch: 51 | Iteration: 382 | Classification loss: 0.00001 | Regression loss: 0.00567 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 383 | Classification loss: 0.00001 | Regression loss: 0.00142 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 384 | Classification loss: 0.00001 | Regression loss: 0.00732 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 385 | Classification loss: 0.00005 | Regression loss: 0.00293 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 386 | Classification loss: 0.00023 | Regression loss: 0.00531 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 387 | Classification loss: 0.00000 | Regression loss: 0.00217 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 388 | Classification loss: 0.00016 | Regression loss: 0.00407 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 389 | Classification loss: 0.00002 | Regression loss: 0.00141 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 390 | Classification loss: 0.00001 | Regression loss: 0.00253 | Running loss: 0.00513\n",
            "Epoch: 51 | Iteration: 391 | Classification loss: 0.00004 | Regression loss: 0.00964 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 392 | Classification loss: 0.00013 | Regression loss: 0.00460 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 393 | Classification loss: 0.00006 | Regression loss: 0.00199 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 394 | Classification loss: 0.00010 | Regression loss: 0.00460 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 395 | Classification loss: 0.00000 | Regression loss: 0.00150 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 396 | Classification loss: 0.00015 | Regression loss: 0.00522 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 397 | Classification loss: 0.00005 | Regression loss: 0.00321 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 398 | Classification loss: 0.00007 | Regression loss: 0.00607 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 399 | Classification loss: 0.00001 | Regression loss: 0.00255 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 400 | Classification loss: 0.00004 | Regression loss: 0.00462 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 401 | Classification loss: 0.00003 | Regression loss: 0.00186 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 402 | Classification loss: 0.00003 | Regression loss: 0.00688 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 403 | Classification loss: 0.00001 | Regression loss: 0.00106 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 404 | Classification loss: 0.00002 | Regression loss: 0.00325 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 405 | Classification loss: 0.00001 | Regression loss: 0.00211 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 406 | Classification loss: 0.00012 | Regression loss: 0.00893 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 407 | Classification loss: 0.00007 | Regression loss: 0.00221 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 408 | Classification loss: 0.00003 | Regression loss: 0.00190 | Running loss: 0.00512\n",
            "Epoch: 51 | Iteration: 409 | Classification loss: 0.00013 | Regression loss: 0.04277 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 410 | Classification loss: 0.00015 | Regression loss: 0.00401 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 411 | Classification loss: 0.00008 | Regression loss: 0.00435 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 412 | Classification loss: 0.00001 | Regression loss: 0.00205 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 413 | Classification loss: 0.00004 | Regression loss: 0.01462 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 414 | Classification loss: 0.00001 | Regression loss: 0.00159 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 415 | Classification loss: 0.00001 | Regression loss: 0.00460 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 416 | Classification loss: 0.00007 | Regression loss: 0.00375 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 417 | Classification loss: 0.00012 | Regression loss: 0.00288 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 418 | Classification loss: 0.00002 | Regression loss: 0.00191 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 419 | Classification loss: 0.00003 | Regression loss: 0.00374 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 420 | Classification loss: 0.00001 | Regression loss: 0.00489 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 421 | Classification loss: 0.00006 | Regression loss: 0.00286 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 422 | Classification loss: 0.00137 | Regression loss: 0.01839 | Running loss: 0.00518\n",
            "Epoch: 51 | Iteration: 423 | Classification loss: 0.00004 | Regression loss: 0.00493 | Running loss: 0.00518\n",
            "Epoch: 51 | Iteration: 424 | Classification loss: 0.00007 | Regression loss: 0.00485 | Running loss: 0.00518\n",
            "Epoch: 51 | Iteration: 425 | Classification loss: 0.00026 | Regression loss: 0.02373 | Running loss: 0.00522\n",
            "Epoch: 51 | Iteration: 426 | Classification loss: 0.00015 | Regression loss: 0.01078 | Running loss: 0.00523\n",
            "Epoch: 51 | Iteration: 427 | Classification loss: 0.00002 | Regression loss: 0.01601 | Running loss: 0.00526\n",
            "Epoch: 51 | Iteration: 428 | Classification loss: 0.00024 | Regression loss: 0.00556 | Running loss: 0.00527\n",
            "Epoch: 51 | Iteration: 429 | Classification loss: 0.00003 | Regression loss: 0.00312 | Running loss: 0.00521\n",
            "Epoch: 51 | Iteration: 430 | Classification loss: 0.00005 | Regression loss: 0.00427 | Running loss: 0.00521\n",
            "Epoch: 51 | Iteration: 431 | Classification loss: 0.00015 | Regression loss: 0.00376 | Running loss: 0.00521\n",
            "Epoch: 51 | Iteration: 432 | Classification loss: 0.00000 | Regression loss: 0.00136 | Running loss: 0.00521\n",
            "Epoch: 51 | Iteration: 433 | Classification loss: 0.00003 | Regression loss: 0.00274 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 434 | Classification loss: 0.00003 | Regression loss: 0.00415 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 435 | Classification loss: 0.00013 | Regression loss: 0.00409 | Running loss: 0.00519\n",
            "Epoch: 51 | Iteration: 436 | Classification loss: 0.00001 | Regression loss: 0.00246 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 437 | Classification loss: 0.00001 | Regression loss: 0.00346 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 438 | Classification loss: 0.00018 | Regression loss: 0.00823 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 439 | Classification loss: 0.00000 | Regression loss: 0.00223 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 440 | Classification loss: 0.00006 | Regression loss: 0.01296 | Running loss: 0.00521\n",
            "Epoch: 51 | Iteration: 441 | Classification loss: 0.00008 | Regression loss: 0.00434 | Running loss: 0.00521\n",
            "Epoch: 51 | Iteration: 442 | Classification loss: 0.00002 | Regression loss: 0.00206 | Running loss: 0.00520\n",
            "Epoch: 51 | Iteration: 443 | Classification loss: 0.00116 | Regression loss: 0.01826 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 444 | Classification loss: 0.00002 | Regression loss: 0.00467 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 445 | Classification loss: 0.00003 | Regression loss: 0.00314 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 446 | Classification loss: 0.00039 | Regression loss: 0.01267 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 447 | Classification loss: 0.00007 | Regression loss: 0.00301 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 448 | Classification loss: 0.00031 | Regression loss: 0.00573 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 449 | Classification loss: 0.00004 | Regression loss: 0.00326 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 450 | Classification loss: 0.00012 | Regression loss: 0.00667 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 451 | Classification loss: 0.00012 | Regression loss: 0.00297 | Running loss: 0.00518\n",
            "Epoch: 51 | Iteration: 452 | Classification loss: 0.00004 | Regression loss: 0.00304 | Running loss: 0.00517\n",
            "Epoch: 51 | Iteration: 453 | Classification loss: 0.00006 | Regression loss: 0.00886 | Running loss: 0.00518\n",
            "Epoch: 51 | Iteration: 454 | Classification loss: 0.00002 | Regression loss: 0.00416 | Running loss: 0.00518\n",
            "Epoch: 51 | Iteration: 455 | Classification loss: 0.00004 | Regression loss: 0.00423 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 456 | Classification loss: 0.00004 | Regression loss: 0.00327 | Running loss: 0.00516\n",
            "Epoch: 51 | Iteration: 457 | Classification loss: 0.00005 | Regression loss: 0.00188 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 458 | Classification loss: 0.00001 | Regression loss: 0.00277 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 459 | Classification loss: 0.00006 | Regression loss: 0.00267 | Running loss: 0.00515\n",
            "Epoch: 51 | Iteration: 460 | Classification loss: 0.00002 | Regression loss: 0.00244 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 461 | Classification loss: 0.00035 | Regression loss: 0.00264 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 462 | Classification loss: 0.00001 | Regression loss: 0.00144 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 463 | Classification loss: 0.00003 | Regression loss: 0.00164 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 464 | Classification loss: 0.00004 | Regression loss: 0.00380 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 465 | Classification loss: 0.00001 | Regression loss: 0.00327 | Running loss: 0.00513\n",
            "Epoch: 51 | Iteration: 466 | Classification loss: 0.00001 | Regression loss: 0.00412 | Running loss: 0.00514\n",
            "Epoch: 51 | Iteration: 467 | Classification loss: 0.00001 | Regression loss: 0.00161 | Running loss: 0.00513\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.7040856976190737\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.35058717253839206\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.45906133082603673\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5359727948016869\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 52 | Iteration: 0 | Classification loss: 0.00018 | Regression loss: 0.00308 | Running loss: 0.00513\n",
            "Epoch: 52 | Iteration: 1 | Classification loss: 0.00000 | Regression loss: 0.00286 | Running loss: 0.00513\n",
            "Epoch: 52 | Iteration: 2 | Classification loss: 0.00006 | Regression loss: 0.00877 | Running loss: 0.00514\n",
            "Epoch: 52 | Iteration: 3 | Classification loss: 0.00003 | Regression loss: 0.00279 | Running loss: 0.00514\n",
            "Epoch: 52 | Iteration: 4 | Classification loss: 0.00002 | Regression loss: 0.00213 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 5 | Classification loss: 0.00002 | Regression loss: 0.00212 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 6 | Classification loss: 0.00001 | Regression loss: 0.00266 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 7 | Classification loss: 0.00011 | Regression loss: 0.00533 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 8 | Classification loss: 0.00013 | Regression loss: 0.00710 | Running loss: 0.00513\n",
            "Epoch: 52 | Iteration: 9 | Classification loss: 0.00004 | Regression loss: 0.00282 | Running loss: 0.00513\n",
            "Epoch: 52 | Iteration: 10 | Classification loss: 0.00000 | Regression loss: 0.00640 | Running loss: 0.00514\n",
            "Epoch: 52 | Iteration: 11 | Classification loss: 0.00007 | Regression loss: 0.00263 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 12 | Classification loss: 0.00010 | Regression loss: 0.00648 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 13 | Classification loss: 0.00096 | Regression loss: 0.02054 | Running loss: 0.00516\n",
            "Epoch: 52 | Iteration: 14 | Classification loss: 0.00003 | Regression loss: 0.00263 | Running loss: 0.00516\n",
            "Epoch: 52 | Iteration: 15 | Classification loss: 0.00003 | Regression loss: 0.01410 | Running loss: 0.00517\n",
            "Epoch: 52 | Iteration: 16 | Classification loss: 0.00002 | Regression loss: 0.00194 | Running loss: 0.00517\n",
            "Epoch: 52 | Iteration: 17 | Classification loss: 0.00000 | Regression loss: 0.00144 | Running loss: 0.00517\n",
            "Epoch: 52 | Iteration: 18 | Classification loss: 0.00015 | Regression loss: 0.00278 | Running loss: 0.00517\n",
            "Epoch: 52 | Iteration: 19 | Classification loss: 0.00004 | Regression loss: 0.00363 | Running loss: 0.00516\n",
            "Epoch: 52 | Iteration: 20 | Classification loss: 0.00001 | Regression loss: 0.00183 | Running loss: 0.00516\n",
            "Epoch: 52 | Iteration: 21 | Classification loss: 0.00005 | Regression loss: 0.00483 | Running loss: 0.00517\n",
            "Epoch: 52 | Iteration: 22 | Classification loss: 0.00022 | Regression loss: 0.00305 | Running loss: 0.00517\n",
            "Epoch: 52 | Iteration: 23 | Classification loss: 0.00071 | Regression loss: 0.02208 | Running loss: 0.00521\n",
            "Epoch: 52 | Iteration: 24 | Classification loss: 0.00002 | Regression loss: 0.00419 | Running loss: 0.00521\n",
            "Epoch: 52 | Iteration: 25 | Classification loss: 0.00006 | Regression loss: 0.00195 | Running loss: 0.00521\n",
            "Epoch: 52 | Iteration: 26 | Classification loss: 0.00008 | Regression loss: 0.00976 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 27 | Classification loss: 0.00001 | Regression loss: 0.00269 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 28 | Classification loss: 0.00008 | Regression loss: 0.00194 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 29 | Classification loss: 0.00044 | Regression loss: 0.01432 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 30 | Classification loss: 0.00002 | Regression loss: 0.00301 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 31 | Classification loss: 0.00002 | Regression loss: 0.00110 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 32 | Classification loss: 0.00009 | Regression loss: 0.00270 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 33 | Classification loss: 0.00016 | Regression loss: 0.00477 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 34 | Classification loss: 0.00000 | Regression loss: 0.00171 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 35 | Classification loss: 0.00002 | Regression loss: 0.01378 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 36 | Classification loss: 0.00001 | Regression loss: 0.00326 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 37 | Classification loss: 0.00004 | Regression loss: 0.00544 | Running loss: 0.00524\n",
            "Epoch: 52 | Iteration: 38 | Classification loss: 0.00004 | Regression loss: 0.00298 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 39 | Classification loss: 0.00011 | Regression loss: 0.00453 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 40 | Classification loss: 0.00009 | Regression loss: 0.00192 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 41 | Classification loss: 0.00005 | Regression loss: 0.00468 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 42 | Classification loss: 0.00002 | Regression loss: 0.02436 | Running loss: 0.00526\n",
            "Epoch: 52 | Iteration: 43 | Classification loss: 0.00001 | Regression loss: 0.00103 | Running loss: 0.00526\n",
            "Epoch: 52 | Iteration: 44 | Classification loss: 0.00006 | Regression loss: 0.00193 | Running loss: 0.00526\n",
            "Epoch: 52 | Iteration: 45 | Classification loss: 0.00002 | Regression loss: 0.00673 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 46 | Classification loss: 0.00005 | Regression loss: 0.00190 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 47 | Classification loss: 0.00004 | Regression loss: 0.00647 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 48 | Classification loss: 0.00003 | Regression loss: 0.00254 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 49 | Classification loss: 0.00007 | Regression loss: 0.00280 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 50 | Classification loss: 0.00009 | Regression loss: 0.00717 | Running loss: 0.00528\n",
            "Epoch: 52 | Iteration: 51 | Classification loss: 0.00001 | Regression loss: 0.00194 | Running loss: 0.00528\n",
            "Epoch: 52 | Iteration: 52 | Classification loss: 0.00002 | Regression loss: 0.00216 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 53 | Classification loss: 0.00014 | Regression loss: 0.00739 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 54 | Classification loss: 0.00007 | Regression loss: 0.00268 | Running loss: 0.00524\n",
            "Epoch: 52 | Iteration: 55 | Classification loss: 0.00001 | Regression loss: 0.00337 | Running loss: 0.00519\n",
            "Epoch: 52 | Iteration: 56 | Classification loss: 0.00002 | Regression loss: 0.00269 | Running loss: 0.00519\n",
            "Epoch: 52 | Iteration: 57 | Classification loss: 0.00001 | Regression loss: 0.00225 | Running loss: 0.00518\n",
            "Epoch: 52 | Iteration: 58 | Classification loss: 0.00097 | Regression loss: 0.01443 | Running loss: 0.00521\n",
            "Epoch: 52 | Iteration: 59 | Classification loss: 0.00039 | Regression loss: 0.00842 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 60 | Classification loss: 0.00005 | Regression loss: 0.00526 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 61 | Classification loss: 0.00019 | Regression loss: 0.00189 | Running loss: 0.00522\n",
            "Epoch: 52 | Iteration: 62 | Classification loss: 0.00005 | Regression loss: 0.04068 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 63 | Classification loss: 0.00013 | Regression loss: 0.00212 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 64 | Classification loss: 0.00002 | Regression loss: 0.00274 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 65 | Classification loss: 0.00002 | Regression loss: 0.00243 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 66 | Classification loss: 0.00015 | Regression loss: 0.00345 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 67 | Classification loss: 0.00007 | Regression loss: 0.00448 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 68 | Classification loss: 0.00011 | Regression loss: 0.00534 | Running loss: 0.00528\n",
            "Epoch: 52 | Iteration: 69 | Classification loss: 0.00003 | Regression loss: 0.00159 | Running loss: 0.00528\n",
            "Epoch: 52 | Iteration: 70 | Classification loss: 0.00004 | Regression loss: 0.00248 | Running loss: 0.00528\n",
            "Epoch: 52 | Iteration: 71 | Classification loss: 0.00004 | Regression loss: 0.00692 | Running loss: 0.00529\n",
            "Epoch: 52 | Iteration: 72 | Classification loss: 0.00054 | Regression loss: 0.00450 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 73 | Classification loss: 0.00008 | Regression loss: 0.00370 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 74 | Classification loss: 0.00014 | Regression loss: 0.00425 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 75 | Classification loss: 0.00001 | Regression loss: 0.00275 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 76 | Classification loss: 0.00000 | Regression loss: 0.00200 | Running loss: 0.00527\n",
            "Epoch: 52 | Iteration: 77 | Classification loss: 0.00000 | Regression loss: 0.00119 | Running loss: 0.00526\n",
            "Epoch: 52 | Iteration: 78 | Classification loss: 0.00003 | Regression loss: 0.00184 | Running loss: 0.00523\n",
            "Epoch: 52 | Iteration: 79 | Classification loss: 0.00004 | Regression loss: 0.00532 | Running loss: 0.00524\n",
            "Epoch: 52 | Iteration: 80 | Classification loss: 0.00001 | Regression loss: 0.00201 | Running loss: 0.00511\n",
            "Epoch: 52 | Iteration: 81 | Classification loss: 0.00009 | Regression loss: 0.00433 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 82 | Classification loss: 0.00005 | Regression loss: 0.00305 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 83 | Classification loss: 0.00001 | Regression loss: 0.00197 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 84 | Classification loss: 0.00001 | Regression loss: 0.00203 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 85 | Classification loss: 0.00008 | Regression loss: 0.00350 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 86 | Classification loss: 0.00017 | Regression loss: 0.00946 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 87 | Classification loss: 0.00006 | Regression loss: 0.00405 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 88 | Classification loss: 0.00005 | Regression loss: 0.00238 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 89 | Classification loss: 0.00000 | Regression loss: 0.00130 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 90 | Classification loss: 0.00002 | Regression loss: 0.00258 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 91 | Classification loss: 0.00002 | Regression loss: 0.00304 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 92 | Classification loss: 0.00002 | Regression loss: 0.00343 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 93 | Classification loss: 0.00001 | Regression loss: 0.00430 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 94 | Classification loss: 0.00011 | Regression loss: 0.00648 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 95 | Classification loss: 0.00002 | Regression loss: 0.00188 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 96 | Classification loss: 0.00003 | Regression loss: 0.00421 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 97 | Classification loss: 0.00001 | Regression loss: 0.00179 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 98 | Classification loss: 0.00008 | Regression loss: 0.00923 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 99 | Classification loss: 0.00002 | Regression loss: 0.00161 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 100 | Classification loss: 0.00002 | Regression loss: 0.00178 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 101 | Classification loss: 0.00003 | Regression loss: 0.00465 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 102 | Classification loss: 0.00000 | Regression loss: 0.00159 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 103 | Classification loss: 0.00008 | Regression loss: 0.01642 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 104 | Classification loss: 0.00001 | Regression loss: 0.00113 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 105 | Classification loss: 0.00015 | Regression loss: 0.01070 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 106 | Classification loss: 0.00000 | Regression loss: 0.00141 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 107 | Classification loss: 0.00008 | Regression loss: 0.00224 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 108 | Classification loss: 0.00003 | Regression loss: 0.00308 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 109 | Classification loss: 0.00001 | Regression loss: 0.00293 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 110 | Classification loss: 0.00004 | Regression loss: 0.00240 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 111 | Classification loss: 0.00002 | Regression loss: 0.00189 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 112 | Classification loss: 0.00005 | Regression loss: 0.00423 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 113 | Classification loss: 0.00003 | Regression loss: 0.00565 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 114 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 115 | Classification loss: 0.00009 | Regression loss: 0.00367 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 116 | Classification loss: 0.00002 | Regression loss: 0.00191 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 117 | Classification loss: 0.00006 | Regression loss: 0.00292 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 118 | Classification loss: 0.00020 | Regression loss: 0.00312 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 119 | Classification loss: 0.00002 | Regression loss: 0.00258 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 120 | Classification loss: 0.00005 | Regression loss: 0.00371 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 121 | Classification loss: 0.00013 | Regression loss: 0.00501 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 122 | Classification loss: 0.00003 | Regression loss: 0.00684 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 123 | Classification loss: 0.00001 | Regression loss: 0.00330 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 124 | Classification loss: 0.00004 | Regression loss: 0.00347 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 125 | Classification loss: 0.00009 | Regression loss: 0.00276 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 126 | Classification loss: 0.00002 | Regression loss: 0.00217 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 127 | Classification loss: 0.00008 | Regression loss: 0.00965 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 128 | Classification loss: 0.00001 | Regression loss: 0.00121 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 129 | Classification loss: 0.00021 | Regression loss: 0.02155 | Running loss: 0.00509\n",
            "Epoch: 52 | Iteration: 130 | Classification loss: 0.00002 | Regression loss: 0.00099 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 131 | Classification loss: 0.00001 | Regression loss: 0.00220 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 132 | Classification loss: 0.00000 | Regression loss: 0.00332 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 133 | Classification loss: 0.00002 | Regression loss: 0.00528 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 134 | Classification loss: 0.00101 | Regression loss: 0.01904 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 135 | Classification loss: 0.00015 | Regression loss: 0.00432 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 136 | Classification loss: 0.00004 | Regression loss: 0.00491 | Running loss: 0.00513\n",
            "Epoch: 52 | Iteration: 137 | Classification loss: 0.00001 | Regression loss: 0.00227 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 138 | Classification loss: 0.00002 | Regression loss: 0.00216 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 139 | Classification loss: 0.00004 | Regression loss: 0.00241 | Running loss: 0.00511\n",
            "Epoch: 52 | Iteration: 140 | Classification loss: 0.00000 | Regression loss: 0.00316 | Running loss: 0.00511\n",
            "Epoch: 52 | Iteration: 141 | Classification loss: 0.00000 | Regression loss: 0.00174 | Running loss: 0.00511\n",
            "Epoch: 52 | Iteration: 142 | Classification loss: 0.00001 | Regression loss: 0.00431 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 143 | Classification loss: 0.00001 | Regression loss: 0.00417 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 144 | Classification loss: 0.00005 | Regression loss: 0.00189 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 145 | Classification loss: 0.00000 | Regression loss: 0.00234 | Running loss: 0.00512\n",
            "Epoch: 52 | Iteration: 146 | Classification loss: 0.00009 | Regression loss: 0.00993 | Running loss: 0.00514\n",
            "Epoch: 52 | Iteration: 147 | Classification loss: 0.00006 | Regression loss: 0.00502 | Running loss: 0.00510\n",
            "Epoch: 52 | Iteration: 148 | Classification loss: 0.00001 | Regression loss: 0.00218 | Running loss: 0.00509\n",
            "Epoch: 52 | Iteration: 149 | Classification loss: 0.00000 | Regression loss: 0.00217 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 150 | Classification loss: 0.00007 | Regression loss: 0.00286 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 151 | Classification loss: 0.00034 | Regression loss: 0.00490 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 152 | Classification loss: 0.00005 | Regression loss: 0.00290 | Running loss: 0.00508\n",
            "Epoch: 52 | Iteration: 153 | Classification loss: 0.00000 | Regression loss: 0.00216 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 154 | Classification loss: 0.00001 | Regression loss: 0.00130 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 155 | Classification loss: 0.00002 | Regression loss: 0.00208 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 156 | Classification loss: 0.00007 | Regression loss: 0.00603 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 157 | Classification loss: 0.00019 | Regression loss: 0.00852 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 158 | Classification loss: 0.00002 | Regression loss: 0.00210 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 159 | Classification loss: 0.00005 | Regression loss: 0.00421 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 160 | Classification loss: 0.00006 | Regression loss: 0.00583 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 161 | Classification loss: 0.00003 | Regression loss: 0.00269 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 162 | Classification loss: 0.00002 | Regression loss: 0.00246 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 163 | Classification loss: 0.00005 | Regression loss: 0.00341 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 164 | Classification loss: 0.00006 | Regression loss: 0.00328 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 165 | Classification loss: 0.00007 | Regression loss: 0.00311 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 166 | Classification loss: 0.00001 | Regression loss: 0.00270 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 167 | Classification loss: 0.00005 | Regression loss: 0.00184 | Running loss: 0.00505\n",
            "Epoch: 52 | Iteration: 168 | Classification loss: 0.00005 | Regression loss: 0.00706 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 169 | Classification loss: 0.00005 | Regression loss: 0.00511 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 170 | Classification loss: 0.00001 | Regression loss: 0.00266 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 171 | Classification loss: 0.00015 | Regression loss: 0.00182 | Running loss: 0.00507\n",
            "Epoch: 52 | Iteration: 172 | Classification loss: 0.00002 | Regression loss: 0.00203 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 173 | Classification loss: 0.00001 | Regression loss: 0.00634 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 174 | Classification loss: 0.00003 | Regression loss: 0.00480 | Running loss: 0.00506\n",
            "Epoch: 52 | Iteration: 175 | Classification loss: 0.00003 | Regression loss: 0.00229 | Running loss: 0.00504\n",
            "Epoch: 52 | Iteration: 176 | Classification loss: 0.00016 | Regression loss: 0.00151 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 177 | Classification loss: 0.00001 | Regression loss: 0.00287 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 178 | Classification loss: 0.00001 | Regression loss: 0.00154 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 179 | Classification loss: 0.00001 | Regression loss: 0.00297 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 180 | Classification loss: 0.00001 | Regression loss: 0.00189 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 181 | Classification loss: 0.00003 | Regression loss: 0.00144 | Running loss: 0.00503\n",
            "Epoch: 52 | Iteration: 182 | Classification loss: 0.00005 | Regression loss: 0.00254 | Running loss: 0.00502\n",
            "Epoch: 52 | Iteration: 183 | Classification loss: 0.00002 | Regression loss: 0.00276 | Running loss: 0.00501\n",
            "Epoch: 52 | Iteration: 184 | Classification loss: 0.00046 | Regression loss: 0.00291 | Running loss: 0.00493\n",
            "Epoch: 52 | Iteration: 185 | Classification loss: 0.00003 | Regression loss: 0.00245 | Running loss: 0.00492\n",
            "Epoch: 52 | Iteration: 186 | Classification loss: 0.00005 | Regression loss: 0.00145 | Running loss: 0.00492\n",
            "Epoch: 52 | Iteration: 187 | Classification loss: 0.00008 | Regression loss: 0.00475 | Running loss: 0.00493\n",
            "Epoch: 52 | Iteration: 188 | Classification loss: 0.00009 | Regression loss: 0.00137 | Running loss: 0.00493\n",
            "Epoch: 52 | Iteration: 189 | Classification loss: 0.00000 | Regression loss: 0.00153 | Running loss: 0.00492\n",
            "Epoch: 52 | Iteration: 190 | Classification loss: 0.00003 | Regression loss: 0.00220 | Running loss: 0.00490\n",
            "Epoch: 52 | Iteration: 191 | Classification loss: 0.00018 | Regression loss: 0.00403 | Running loss: 0.00490\n",
            "Epoch: 52 | Iteration: 192 | Classification loss: 0.00005 | Regression loss: 0.00221 | Running loss: 0.00490\n",
            "Epoch: 52 | Iteration: 193 | Classification loss: 0.00007 | Regression loss: 0.00149 | Running loss: 0.00490\n",
            "Epoch: 52 | Iteration: 194 | Classification loss: 0.00001 | Regression loss: 0.00211 | Running loss: 0.00488\n",
            "Epoch: 52 | Iteration: 195 | Classification loss: 0.00003 | Regression loss: 0.00623 | Running loss: 0.00485\n",
            "Epoch: 52 | Iteration: 196 | Classification loss: 0.00011 | Regression loss: 0.01269 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 197 | Classification loss: 0.00005 | Regression loss: 0.00238 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 198 | Classification loss: 0.00001 | Regression loss: 0.00275 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 199 | Classification loss: 0.00001 | Regression loss: 0.00137 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 200 | Classification loss: 0.00002 | Regression loss: 0.00438 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 201 | Classification loss: 0.00004 | Regression loss: 0.00222 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 202 | Classification loss: 0.00000 | Regression loss: 0.00167 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 203 | Classification loss: 0.00000 | Regression loss: 0.00243 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 204 | Classification loss: 0.00002 | Regression loss: 0.00217 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 205 | Classification loss: 0.00010 | Regression loss: 0.00508 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 206 | Classification loss: 0.00016 | Regression loss: 0.00696 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 207 | Classification loss: 0.00001 | Regression loss: 0.00194 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 208 | Classification loss: 0.00001 | Regression loss: 0.00129 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 209 | Classification loss: 0.00005 | Regression loss: 0.00272 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 210 | Classification loss: 0.00005 | Regression loss: 0.00611 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 211 | Classification loss: 0.00004 | Regression loss: 0.00418 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 212 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 213 | Classification loss: 0.00007 | Regression loss: 0.00310 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 214 | Classification loss: 0.00006 | Regression loss: 0.00318 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 215 | Classification loss: 0.00004 | Regression loss: 0.00433 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 216 | Classification loss: 0.00009 | Regression loss: 0.00582 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 217 | Classification loss: 0.00001 | Regression loss: 0.00256 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 218 | Classification loss: 0.00000 | Regression loss: 0.00281 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 219 | Classification loss: 0.00009 | Regression loss: 0.00316 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 220 | Classification loss: 0.00001 | Regression loss: 0.00194 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 221 | Classification loss: 0.00003 | Regression loss: 0.00242 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 222 | Classification loss: 0.00009 | Regression loss: 0.00369 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 223 | Classification loss: 0.00001 | Regression loss: 0.00156 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 224 | Classification loss: 0.00004 | Regression loss: 0.00343 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 225 | Classification loss: 0.00010 | Regression loss: 0.00235 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 226 | Classification loss: 0.00005 | Regression loss: 0.00281 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 227 | Classification loss: 0.00004 | Regression loss: 0.00935 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 228 | Classification loss: 0.00008 | Regression loss: 0.00584 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 229 | Classification loss: 0.00001 | Regression loss: 0.00168 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 230 | Classification loss: 0.00002 | Regression loss: 0.00333 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 231 | Classification loss: 0.00017 | Regression loss: 0.00831 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 232 | Classification loss: 0.00013 | Regression loss: 0.00222 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 233 | Classification loss: 0.00142 | Regression loss: 0.04479 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 234 | Classification loss: 0.00004 | Regression loss: 0.00309 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 235 | Classification loss: 0.00003 | Regression loss: 0.00296 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 236 | Classification loss: 0.00029 | Regression loss: 0.01401 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 237 | Classification loss: 0.00004 | Regression loss: 0.00446 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 238 | Classification loss: 0.00001 | Regression loss: 0.00169 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 239 | Classification loss: 0.00003 | Regression loss: 0.00551 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 240 | Classification loss: 0.00006 | Regression loss: 0.00203 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 241 | Classification loss: 0.00017 | Regression loss: 0.01101 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 242 | Classification loss: 0.00002 | Regression loss: 0.00253 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 243 | Classification loss: 0.00004 | Regression loss: 0.00236 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 244 | Classification loss: 0.00022 | Regression loss: 0.01577 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 245 | Classification loss: 0.00001 | Regression loss: 0.00243 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 246 | Classification loss: 0.00013 | Regression loss: 0.00739 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 247 | Classification loss: 0.00001 | Regression loss: 0.00231 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 248 | Classification loss: 0.00011 | Regression loss: 0.00478 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 249 | Classification loss: 0.00015 | Regression loss: 0.01107 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 250 | Classification loss: 0.00011 | Regression loss: 0.02467 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 251 | Classification loss: 0.00001 | Regression loss: 0.00226 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 252 | Classification loss: 0.00002 | Regression loss: 0.00324 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 253 | Classification loss: 0.00004 | Regression loss: 0.00298 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 254 | Classification loss: 0.00002 | Regression loss: 0.00314 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 255 | Classification loss: 0.00006 | Regression loss: 0.00259 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 256 | Classification loss: 0.00077 | Regression loss: 0.00425 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 257 | Classification loss: 0.00000 | Regression loss: 0.00197 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 258 | Classification loss: 0.00002 | Regression loss: 0.00278 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 259 | Classification loss: 0.00000 | Regression loss: 0.00194 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 260 | Classification loss: 0.00002 | Regression loss: 0.00403 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 261 | Classification loss: 0.00003 | Regression loss: 0.00329 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 262 | Classification loss: 0.00002 | Regression loss: 0.00166 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 263 | Classification loss: 0.00002 | Regression loss: 0.00219 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 264 | Classification loss: 0.00001 | Regression loss: 0.00183 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 265 | Classification loss: 0.00005 | Regression loss: 0.00536 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 266 | Classification loss: 0.00007 | Regression loss: 0.00250 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 267 | Classification loss: 0.00005 | Regression loss: 0.00246 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 268 | Classification loss: 0.00003 | Regression loss: 0.00236 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 269 | Classification loss: 0.00029 | Regression loss: 0.00550 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 270 | Classification loss: 0.00016 | Regression loss: 0.00390 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 271 | Classification loss: 0.00002 | Regression loss: 0.00763 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 272 | Classification loss: 0.00010 | Regression loss: 0.00601 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 273 | Classification loss: 0.00008 | Regression loss: 0.00815 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 274 | Classification loss: 0.00040 | Regression loss: 0.01109 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 275 | Classification loss: 0.00005 | Regression loss: 0.00746 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 276 | Classification loss: 0.00004 | Regression loss: 0.00519 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 277 | Classification loss: 0.00004 | Regression loss: 0.00249 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 278 | Classification loss: 0.00001 | Regression loss: 0.00378 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 279 | Classification loss: 0.00001 | Regression loss: 0.01754 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 280 | Classification loss: 0.00002 | Regression loss: 0.00177 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 281 | Classification loss: 0.00001 | Regression loss: 0.00798 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 282 | Classification loss: 0.00005 | Regression loss: 0.00278 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 283 | Classification loss: 0.00001 | Regression loss: 0.00299 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 284 | Classification loss: 0.00045 | Regression loss: 0.00878 | Running loss: 0.00483\n",
            "Epoch: 52 | Iteration: 285 | Classification loss: 0.00005 | Regression loss: 0.00434 | Running loss: 0.00484\n",
            "Epoch: 52 | Iteration: 286 | Classification loss: 0.00001 | Regression loss: 0.00240 | Running loss: 0.00484\n",
            "Epoch: 52 | Iteration: 287 | Classification loss: 0.00001 | Regression loss: 0.00299 | Running loss: 0.00483\n",
            "Epoch: 52 | Iteration: 288 | Classification loss: 0.00013 | Regression loss: 0.00206 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 289 | Classification loss: 0.00028 | Regression loss: 0.00926 | Running loss: 0.00484\n",
            "Epoch: 52 | Iteration: 290 | Classification loss: 0.00001 | Regression loss: 0.00258 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 291 | Classification loss: 0.00007 | Regression loss: 0.00329 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 292 | Classification loss: 0.00013 | Regression loss: 0.00540 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 293 | Classification loss: 0.00005 | Regression loss: 0.00173 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 294 | Classification loss: 0.00004 | Regression loss: 0.00134 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 295 | Classification loss: 0.00005 | Regression loss: 0.00663 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 296 | Classification loss: 0.00007 | Regression loss: 0.00376 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 297 | Classification loss: 0.00003 | Regression loss: 0.00312 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 298 | Classification loss: 0.00007 | Regression loss: 0.00399 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 299 | Classification loss: 0.00002 | Regression loss: 0.00313 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 300 | Classification loss: 0.00000 | Regression loss: 0.00539 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 301 | Classification loss: 0.00002 | Regression loss: 0.00189 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 302 | Classification loss: 0.00002 | Regression loss: 0.00289 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 303 | Classification loss: 0.00004 | Regression loss: 0.00239 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 304 | Classification loss: 0.00001 | Regression loss: 0.00193 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 305 | Classification loss: 0.00002 | Regression loss: 0.00364 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 306 | Classification loss: 0.00013 | Regression loss: 0.00612 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 307 | Classification loss: 0.00007 | Regression loss: 0.00581 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 308 | Classification loss: 0.00003 | Regression loss: 0.02170 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 309 | Classification loss: 0.00009 | Regression loss: 0.01017 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 310 | Classification loss: 0.00003 | Regression loss: 0.00384 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 311 | Classification loss: 0.00002 | Regression loss: 0.00231 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 312 | Classification loss: 0.00004 | Regression loss: 0.00235 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 313 | Classification loss: 0.00013 | Regression loss: 0.00661 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 314 | Classification loss: 0.00002 | Regression loss: 0.00213 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 315 | Classification loss: 0.00002 | Regression loss: 0.00285 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 316 | Classification loss: 0.00001 | Regression loss: 0.00162 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 317 | Classification loss: 0.00004 | Regression loss: 0.00336 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 318 | Classification loss: 0.00006 | Regression loss: 0.00340 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 319 | Classification loss: 0.00001 | Regression loss: 0.00235 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 320 | Classification loss: 0.00003 | Regression loss: 0.00178 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 321 | Classification loss: 0.00017 | Regression loss: 0.00266 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 322 | Classification loss: 0.00001 | Regression loss: 0.00458 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 323 | Classification loss: 0.00015 | Regression loss: 0.01673 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 324 | Classification loss: 0.00001 | Regression loss: 0.00439 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 325 | Classification loss: 0.00002 | Regression loss: 0.00276 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 326 | Classification loss: 0.00000 | Regression loss: 0.00150 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 327 | Classification loss: 0.00006 | Regression loss: 0.00214 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 328 | Classification loss: 0.00013 | Regression loss: 0.00223 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 329 | Classification loss: 0.00008 | Regression loss: 0.00179 | Running loss: 0.00467\n",
            "Epoch: 52 | Iteration: 330 | Classification loss: 0.00007 | Regression loss: 0.00154 | Running loss: 0.00467\n",
            "Epoch: 52 | Iteration: 331 | Classification loss: 0.00009 | Regression loss: 0.00278 | Running loss: 0.00465\n",
            "Epoch: 52 | Iteration: 332 | Classification loss: 0.00042 | Regression loss: 0.05375 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 333 | Classification loss: 0.00001 | Regression loss: 0.00138 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 334 | Classification loss: 0.00018 | Regression loss: 0.00328 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 335 | Classification loss: 0.00010 | Regression loss: 0.00462 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 336 | Classification loss: 0.00004 | Regression loss: 0.00445 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 337 | Classification loss: 0.00001 | Regression loss: 0.00317 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 338 | Classification loss: 0.00004 | Regression loss: 0.00164 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 339 | Classification loss: 0.00007 | Regression loss: 0.00590 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 340 | Classification loss: 0.00000 | Regression loss: 0.00156 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 341 | Classification loss: 0.00001 | Regression loss: 0.00368 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 342 | Classification loss: 0.00001 | Regression loss: 0.00216 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 343 | Classification loss: 0.00001 | Regression loss: 0.00199 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 344 | Classification loss: 0.00005 | Regression loss: 0.00266 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 345 | Classification loss: 0.00004 | Regression loss: 0.00323 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 346 | Classification loss: 0.00006 | Regression loss: 0.00307 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 347 | Classification loss: 0.00003 | Regression loss: 0.00144 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 348 | Classification loss: 0.00004 | Regression loss: 0.01102 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 349 | Classification loss: 0.00001 | Regression loss: 0.00155 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 350 | Classification loss: 0.00009 | Regression loss: 0.00401 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 351 | Classification loss: 0.00009 | Regression loss: 0.00293 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 352 | Classification loss: 0.00003 | Regression loss: 0.00234 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 353 | Classification loss: 0.00001 | Regression loss: 0.00162 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 354 | Classification loss: 0.00009 | Regression loss: 0.00383 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 355 | Classification loss: 0.00006 | Regression loss: 0.00280 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 356 | Classification loss: 0.00005 | Regression loss: 0.00829 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 357 | Classification loss: 0.00013 | Regression loss: 0.00398 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 358 | Classification loss: 0.00003 | Regression loss: 0.00259 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 359 | Classification loss: 0.00001 | Regression loss: 0.00214 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 360 | Classification loss: 0.00001 | Regression loss: 0.00214 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 361 | Classification loss: 0.00001 | Regression loss: 0.00227 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 362 | Classification loss: 0.00001 | Regression loss: 0.00177 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 363 | Classification loss: 0.00024 | Regression loss: 0.00395 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 364 | Classification loss: 0.00004 | Regression loss: 0.00492 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 365 | Classification loss: 0.00008 | Regression loss: 0.00196 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 366 | Classification loss: 0.00008 | Regression loss: 0.00586 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 367 | Classification loss: 0.00007 | Regression loss: 0.00318 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 368 | Classification loss: 0.00020 | Regression loss: 0.01036 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 369 | Classification loss: 0.00015 | Regression loss: 0.00459 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 370 | Classification loss: 0.00052 | Regression loss: 0.00602 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 371 | Classification loss: 0.00010 | Regression loss: 0.00884 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 372 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 373 | Classification loss: 0.00012 | Regression loss: 0.00512 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 374 | Classification loss: 0.00008 | Regression loss: 0.00913 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 375 | Classification loss: 0.00002 | Regression loss: 0.00362 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 376 | Classification loss: 0.00022 | Regression loss: 0.01158 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 377 | Classification loss: 0.00004 | Regression loss: 0.00171 | Running loss: 0.00474\n",
            "Epoch: 52 | Iteration: 378 | Classification loss: 0.00012 | Regression loss: 0.00689 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 379 | Classification loss: 0.00022 | Regression loss: 0.00425 | Running loss: 0.00475\n",
            "Epoch: 52 | Iteration: 380 | Classification loss: 0.00010 | Regression loss: 0.00416 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 381 | Classification loss: 0.00001 | Regression loss: 0.00393 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 382 | Classification loss: 0.00032 | Regression loss: 0.01935 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 383 | Classification loss: 0.00004 | Regression loss: 0.00261 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 384 | Classification loss: 0.00005 | Regression loss: 0.00223 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 385 | Classification loss: 0.00004 | Regression loss: 0.00133 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 386 | Classification loss: 0.00002 | Regression loss: 0.00225 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 387 | Classification loss: 0.00001 | Regression loss: 0.00296 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 388 | Classification loss: 0.00006 | Regression loss: 0.00524 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 389 | Classification loss: 0.00001 | Regression loss: 0.00200 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 390 | Classification loss: 0.00001 | Regression loss: 0.00242 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 391 | Classification loss: 0.00002 | Regression loss: 0.00316 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 392 | Classification loss: 0.00027 | Regression loss: 0.00421 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 393 | Classification loss: 0.00120 | Regression loss: 0.01494 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 394 | Classification loss: 0.00002 | Regression loss: 0.00212 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 395 | Classification loss: 0.00002 | Regression loss: 0.00213 | Running loss: 0.00482\n",
            "Epoch: 52 | Iteration: 396 | Classification loss: 0.00011 | Regression loss: 0.00331 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 397 | Classification loss: 0.00005 | Regression loss: 0.00114 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 398 | Classification loss: 0.00006 | Regression loss: 0.00265 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 399 | Classification loss: 0.00006 | Regression loss: 0.00303 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 400 | Classification loss: 0.00017 | Regression loss: 0.00350 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 401 | Classification loss: 0.00004 | Regression loss: 0.00177 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 402 | Classification loss: 0.00001 | Regression loss: 0.00291 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 403 | Classification loss: 0.00004 | Regression loss: 0.00207 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 404 | Classification loss: 0.00005 | Regression loss: 0.00309 | Running loss: 0.00476\n",
            "Epoch: 52 | Iteration: 405 | Classification loss: 0.00053 | Regression loss: 0.01913 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 406 | Classification loss: 0.00000 | Regression loss: 0.00222 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 407 | Classification loss: 0.00002 | Regression loss: 0.00344 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 408 | Classification loss: 0.00008 | Regression loss: 0.00300 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 409 | Classification loss: 0.00004 | Regression loss: 0.00214 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 410 | Classification loss: 0.00001 | Regression loss: 0.00386 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 411 | Classification loss: 0.00008 | Regression loss: 0.00244 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 412 | Classification loss: 0.00001 | Regression loss: 0.00197 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 413 | Classification loss: 0.00001 | Regression loss: 0.00345 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 414 | Classification loss: 0.00003 | Regression loss: 0.00985 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 415 | Classification loss: 0.00001 | Regression loss: 0.00609 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 416 | Classification loss: 0.00006 | Regression loss: 0.00572 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 417 | Classification loss: 0.00000 | Regression loss: 0.00200 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 418 | Classification loss: 0.00001 | Regression loss: 0.00200 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 419 | Classification loss: 0.00010 | Regression loss: 0.01091 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 420 | Classification loss: 0.00014 | Regression loss: 0.00270 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 421 | Classification loss: 0.00002 | Regression loss: 0.00242 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 422 | Classification loss: 0.00019 | Regression loss: 0.00580 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 423 | Classification loss: 0.00004 | Regression loss: 0.00177 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 424 | Classification loss: 0.00002 | Regression loss: 0.00258 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 425 | Classification loss: 0.00000 | Regression loss: 0.00198 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 426 | Classification loss: 0.00004 | Regression loss: 0.00230 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 427 | Classification loss: 0.00004 | Regression loss: 0.00424 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 428 | Classification loss: 0.00010 | Regression loss: 0.00663 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 429 | Classification loss: 0.00001 | Regression loss: 0.00459 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 430 | Classification loss: 0.00014 | Regression loss: 0.00975 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 431 | Classification loss: 0.00002 | Regression loss: 0.00211 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 432 | Classification loss: 0.00001 | Regression loss: 0.00260 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 433 | Classification loss: 0.00013 | Regression loss: 0.00348 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 434 | Classification loss: 0.00001 | Regression loss: 0.00214 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 435 | Classification loss: 0.00022 | Regression loss: 0.00408 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 436 | Classification loss: 0.00006 | Regression loss: 0.00536 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 437 | Classification loss: 0.00000 | Regression loss: 0.00164 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 438 | Classification loss: 0.00006 | Regression loss: 0.00302 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 439 | Classification loss: 0.00002 | Regression loss: 0.00280 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 440 | Classification loss: 0.00004 | Regression loss: 0.00350 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 441 | Classification loss: 0.00004 | Regression loss: 0.00282 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 442 | Classification loss: 0.00009 | Regression loss: 0.00748 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 443 | Classification loss: 0.00001 | Regression loss: 0.00201 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 444 | Classification loss: 0.00002 | Regression loss: 0.00440 | Running loss: 0.00472\n",
            "Epoch: 52 | Iteration: 445 | Classification loss: 0.00008 | Regression loss: 0.00351 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 446 | Classification loss: 0.00001 | Regression loss: 0.00207 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 447 | Classification loss: 0.00001 | Regression loss: 0.00186 | Running loss: 0.00470\n",
            "Epoch: 52 | Iteration: 448 | Classification loss: 0.00001 | Regression loss: 0.00227 | Running loss: 0.00469\n",
            "Epoch: 52 | Iteration: 449 | Classification loss: 0.00012 | Regression loss: 0.00865 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 450 | Classification loss: 0.00003 | Regression loss: 0.04238 | Running loss: 0.00479\n",
            "Epoch: 52 | Iteration: 451 | Classification loss: 0.00001 | Regression loss: 0.00156 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 452 | Classification loss: 0.00055 | Regression loss: 0.01882 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 453 | Classification loss: 0.00001 | Regression loss: 0.00343 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 454 | Classification loss: 0.00003 | Regression loss: 0.00515 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 455 | Classification loss: 0.00004 | Regression loss: 0.00192 | Running loss: 0.00478\n",
            "Epoch: 52 | Iteration: 456 | Classification loss: 0.00001 | Regression loss: 0.00377 | Running loss: 0.00477\n",
            "Epoch: 52 | Iteration: 457 | Classification loss: 0.00005 | Regression loss: 0.00282 | Running loss: 0.00473\n",
            "Epoch: 52 | Iteration: 458 | Classification loss: 0.00002 | Regression loss: 0.00178 | Running loss: 0.00471\n",
            "Epoch: 52 | Iteration: 459 | Classification loss: 0.00000 | Regression loss: 0.00144 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 460 | Classification loss: 0.00007 | Regression loss: 0.00401 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 461 | Classification loss: 0.00004 | Regression loss: 0.00217 | Running loss: 0.00468\n",
            "Epoch: 52 | Iteration: 462 | Classification loss: 0.00023 | Regression loss: 0.06509 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 463 | Classification loss: 0.00004 | Regression loss: 0.00552 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 464 | Classification loss: 0.00002 | Regression loss: 0.00151 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 465 | Classification loss: 0.00024 | Regression loss: 0.00298 | Running loss: 0.00481\n",
            "Epoch: 52 | Iteration: 466 | Classification loss: 0.00001 | Regression loss: 0.00303 | Running loss: 0.00480\n",
            "Epoch: 52 | Iteration: 467 | Classification loss: 0.00000 | Regression loss: 0.00175 | Running loss: 0.00480\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9925342882237684\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6857373719545782\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.36278302594092066\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.4680377010387806\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5329041849474181\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.417910447761194\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 53 | Iteration: 0 | Classification loss: 0.00007 | Regression loss: 0.00173 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 1 | Classification loss: 0.00007 | Regression loss: 0.00311 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 2 | Classification loss: 0.00009 | Regression loss: 0.00644 | Running loss: 0.00479\n",
            "Epoch: 53 | Iteration: 3 | Classification loss: 0.00001 | Regression loss: 0.00431 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 4 | Classification loss: 0.00006 | Regression loss: 0.00333 | Running loss: 0.00478\n",
            "Epoch: 53 | Iteration: 5 | Classification loss: 0.00001 | Regression loss: 0.00183 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 6 | Classification loss: 0.00001 | Regression loss: 0.00226 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 7 | Classification loss: 0.00002 | Regression loss: 0.00441 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 8 | Classification loss: 0.00002 | Regression loss: 0.00345 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 9 | Classification loss: 0.00080 | Regression loss: 0.01461 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 10 | Classification loss: 0.00003 | Regression loss: 0.00216 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 11 | Classification loss: 0.00001 | Regression loss: 0.00294 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 12 | Classification loss: 0.00003 | Regression loss: 0.00261 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 13 | Classification loss: 0.00008 | Regression loss: 0.00223 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 14 | Classification loss: 0.00014 | Regression loss: 0.00237 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 15 | Classification loss: 0.00219 | Regression loss: 0.02470 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 16 | Classification loss: 0.00004 | Regression loss: 0.00323 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 17 | Classification loss: 0.00000 | Regression loss: 0.00212 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 18 | Classification loss: 0.00010 | Regression loss: 0.00445 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 19 | Classification loss: 0.00003 | Regression loss: 0.00215 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 20 | Classification loss: 0.00004 | Regression loss: 0.00180 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 21 | Classification loss: 0.00000 | Regression loss: 0.00208 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 22 | Classification loss: 0.00001 | Regression loss: 0.01684 | Running loss: 0.00478\n",
            "Epoch: 53 | Iteration: 23 | Classification loss: 0.00002 | Regression loss: 0.00202 | Running loss: 0.00478\n",
            "Epoch: 53 | Iteration: 24 | Classification loss: 0.00003 | Regression loss: 0.01002 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 25 | Classification loss: 0.00002 | Regression loss: 0.00306 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 26 | Classification loss: 0.00003 | Regression loss: 0.00464 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 27 | Classification loss: 0.00003 | Regression loss: 0.00275 | Running loss: 0.00481\n",
            "Epoch: 53 | Iteration: 28 | Classification loss: 0.00008 | Regression loss: 0.00869 | Running loss: 0.00481\n",
            "Epoch: 53 | Iteration: 29 | Classification loss: 0.00008 | Regression loss: 0.00780 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 30 | Classification loss: 0.00001 | Regression loss: 0.00273 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 31 | Classification loss: 0.00003 | Regression loss: 0.00326 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 32 | Classification loss: 0.00002 | Regression loss: 0.00489 | Running loss: 0.00483\n",
            "Epoch: 53 | Iteration: 33 | Classification loss: 0.00016 | Regression loss: 0.00512 | Running loss: 0.00483\n",
            "Epoch: 53 | Iteration: 34 | Classification loss: 0.00003 | Regression loss: 0.00365 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 35 | Classification loss: 0.00001 | Regression loss: 0.00132 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 36 | Classification loss: 0.00000 | Regression loss: 0.00165 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 37 | Classification loss: 0.00001 | Regression loss: 0.00290 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 38 | Classification loss: 0.00002 | Regression loss: 0.00163 | Running loss: 0.00482\n",
            "Epoch: 53 | Iteration: 39 | Classification loss: 0.00004 | Regression loss: 0.00260 | Running loss: 0.00481\n",
            "Epoch: 53 | Iteration: 40 | Classification loss: 0.00005 | Regression loss: 0.00268 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 41 | Classification loss: 0.00000 | Regression loss: 0.00577 | Running loss: 0.00481\n",
            "Epoch: 53 | Iteration: 42 | Classification loss: 0.00002 | Regression loss: 0.00304 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 43 | Classification loss: 0.00015 | Regression loss: 0.00610 | Running loss: 0.00481\n",
            "Epoch: 53 | Iteration: 44 | Classification loss: 0.00006 | Regression loss: 0.00178 | Running loss: 0.00480\n",
            "Epoch: 53 | Iteration: 45 | Classification loss: 0.00002 | Regression loss: 0.00360 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 46 | Classification loss: 0.00003 | Regression loss: 0.00241 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 47 | Classification loss: 0.00012 | Regression loss: 0.00275 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 48 | Classification loss: 0.00001 | Regression loss: 0.00164 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 49 | Classification loss: 0.00003 | Regression loss: 0.00157 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 50 | Classification loss: 0.00002 | Regression loss: 0.00481 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 51 | Classification loss: 0.00001 | Regression loss: 0.00187 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 52 | Classification loss: 0.00035 | Regression loss: 0.00384 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 53 | Classification loss: 0.00003 | Regression loss: 0.00179 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 54 | Classification loss: 0.00028 | Regression loss: 0.00300 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 55 | Classification loss: 0.00002 | Regression loss: 0.00287 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 56 | Classification loss: 0.00052 | Regression loss: 0.04645 | Running loss: 0.00479\n",
            "Epoch: 53 | Iteration: 57 | Classification loss: 0.00005 | Regression loss: 0.00651 | Running loss: 0.00479\n",
            "Epoch: 53 | Iteration: 58 | Classification loss: 0.00004 | Regression loss: 0.00273 | Running loss: 0.00478\n",
            "Epoch: 53 | Iteration: 59 | Classification loss: 0.00005 | Regression loss: 0.00192 | Running loss: 0.00478\n",
            "Epoch: 53 | Iteration: 60 | Classification loss: 0.00002 | Regression loss: 0.00267 | Running loss: 0.00478\n",
            "Epoch: 53 | Iteration: 61 | Classification loss: 0.00002 | Regression loss: 0.00446 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 62 | Classification loss: 0.00002 | Regression loss: 0.00205 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 63 | Classification loss: 0.00000 | Regression loss: 0.00125 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 64 | Classification loss: 0.00001 | Regression loss: 0.00197 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 65 | Classification loss: 0.00004 | Regression loss: 0.00304 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 66 | Classification loss: 0.00004 | Regression loss: 0.00171 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 67 | Classification loss: 0.00003 | Regression loss: 0.00591 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 68 | Classification loss: 0.00002 | Regression loss: 0.00195 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 69 | Classification loss: 0.00001 | Regression loss: 0.00193 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 70 | Classification loss: 0.00004 | Regression loss: 0.00390 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 71 | Classification loss: 0.00002 | Regression loss: 0.00258 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 72 | Classification loss: 0.00003 | Regression loss: 0.00329 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 73 | Classification loss: 0.00006 | Regression loss: 0.00266 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 74 | Classification loss: 0.00008 | Regression loss: 0.00311 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 75 | Classification loss: 0.00107 | Regression loss: 0.01486 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 76 | Classification loss: 0.00004 | Regression loss: 0.00275 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 77 | Classification loss: 0.00006 | Regression loss: 0.00725 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 78 | Classification loss: 0.00003 | Regression loss: 0.00199 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 79 | Classification loss: 0.00021 | Regression loss: 0.00503 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 80 | Classification loss: 0.00004 | Regression loss: 0.00198 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 81 | Classification loss: 0.00001 | Regression loss: 0.00154 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 82 | Classification loss: 0.00000 | Regression loss: 0.00151 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 83 | Classification loss: 0.00006 | Regression loss: 0.00154 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 84 | Classification loss: 0.00002 | Regression loss: 0.00536 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 85 | Classification loss: 0.00001 | Regression loss: 0.00314 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 86 | Classification loss: 0.00003 | Regression loss: 0.00226 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 87 | Classification loss: 0.00003 | Regression loss: 0.00166 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 88 | Classification loss: 0.00007 | Regression loss: 0.00330 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 89 | Classification loss: 0.00002 | Regression loss: 0.00186 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 90 | Classification loss: 0.00006 | Regression loss: 0.00498 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 91 | Classification loss: 0.00001 | Regression loss: 0.00218 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 92 | Classification loss: 0.00010 | Regression loss: 0.00326 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 93 | Classification loss: 0.00005 | Regression loss: 0.00433 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 94 | Classification loss: 0.00026 | Regression loss: 0.00896 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 95 | Classification loss: 0.00008 | Regression loss: 0.00144 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 96 | Classification loss: 0.00001 | Regression loss: 0.00103 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 97 | Classification loss: 0.00001 | Regression loss: 0.00313 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 98 | Classification loss: 0.00004 | Regression loss: 0.00484 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 99 | Classification loss: 0.00002 | Regression loss: 0.00296 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 100 | Classification loss: 0.00006 | Regression loss: 0.00410 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 101 | Classification loss: 0.00003 | Regression loss: 0.00240 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 102 | Classification loss: 0.00001 | Regression loss: 0.00159 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 103 | Classification loss: 0.00006 | Regression loss: 0.00243 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 104 | Classification loss: 0.00006 | Regression loss: 0.00175 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 105 | Classification loss: 0.00002 | Regression loss: 0.00393 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 106 | Classification loss: 0.00001 | Regression loss: 0.00215 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 107 | Classification loss: 0.00001 | Regression loss: 0.00285 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 108 | Classification loss: 0.00004 | Regression loss: 0.00338 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 109 | Classification loss: 0.00001 | Regression loss: 0.00128 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 110 | Classification loss: 0.00000 | Regression loss: 0.00142 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 111 | Classification loss: 0.00029 | Regression loss: 0.00449 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 112 | Classification loss: 0.00001 | Regression loss: 0.00172 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 113 | Classification loss: 0.00005 | Regression loss: 0.00168 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 114 | Classification loss: 0.00003 | Regression loss: 0.00262 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 115 | Classification loss: 0.00001 | Regression loss: 0.00177 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 116 | Classification loss: 0.00006 | Regression loss: 0.00248 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 117 | Classification loss: 0.00005 | Regression loss: 0.00381 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 118 | Classification loss: 0.00000 | Regression loss: 0.00142 | Running loss: 0.00455\n",
            "Epoch: 53 | Iteration: 119 | Classification loss: 0.00003 | Regression loss: 0.00240 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 120 | Classification loss: 0.00005 | Regression loss: 0.00290 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 121 | Classification loss: 0.00002 | Regression loss: 0.00331 | Running loss: 0.00455\n",
            "Epoch: 53 | Iteration: 122 | Classification loss: 0.00000 | Regression loss: 0.00204 | Running loss: 0.00455\n",
            "Epoch: 53 | Iteration: 123 | Classification loss: 0.00004 | Regression loss: 0.00183 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 124 | Classification loss: 0.00001 | Regression loss: 0.00185 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 125 | Classification loss: 0.00001 | Regression loss: 0.00167 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 126 | Classification loss: 0.00001 | Regression loss: 0.00224 | Running loss: 0.00453\n",
            "Epoch: 53 | Iteration: 127 | Classification loss: 0.00010 | Regression loss: 0.00726 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 128 | Classification loss: 0.00015 | Regression loss: 0.00563 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 129 | Classification loss: 0.00014 | Regression loss: 0.00377 | Running loss: 0.00455\n",
            "Epoch: 53 | Iteration: 130 | Classification loss: 0.00003 | Regression loss: 0.00198 | Running loss: 0.00453\n",
            "Epoch: 53 | Iteration: 131 | Classification loss: 0.00001 | Regression loss: 0.00323 | Running loss: 0.00453\n",
            "Epoch: 53 | Iteration: 132 | Classification loss: 0.00004 | Regression loss: 0.00261 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 133 | Classification loss: 0.00004 | Regression loss: 0.00445 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 134 | Classification loss: 0.00002 | Regression loss: 0.00229 | Running loss: 0.00454\n",
            "Epoch: 53 | Iteration: 135 | Classification loss: 0.00001 | Regression loss: 0.00187 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 136 | Classification loss: 0.00001 | Regression loss: 0.00331 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 137 | Classification loss: 0.00001 | Regression loss: 0.00258 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 138 | Classification loss: 0.00007 | Regression loss: 0.00663 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 139 | Classification loss: 0.00007 | Regression loss: 0.00153 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 140 | Classification loss: 0.00001 | Regression loss: 0.00251 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 141 | Classification loss: 0.00000 | Regression loss: 0.00232 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 142 | Classification loss: 0.00004 | Regression loss: 0.00335 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 143 | Classification loss: 0.00006 | Regression loss: 0.00307 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 144 | Classification loss: 0.00001 | Regression loss: 0.00247 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 145 | Classification loss: 0.00001 | Regression loss: 0.00178 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 146 | Classification loss: 0.00001 | Regression loss: 0.00170 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 147 | Classification loss: 0.00001 | Regression loss: 0.00208 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 148 | Classification loss: 0.00003 | Regression loss: 0.00395 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 149 | Classification loss: 0.00002 | Regression loss: 0.00129 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 150 | Classification loss: 0.00007 | Regression loss: 0.00199 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 151 | Classification loss: 0.00009 | Regression loss: 0.00229 | Running loss: 0.00449\n",
            "Epoch: 53 | Iteration: 152 | Classification loss: 0.00002 | Regression loss: 0.00208 | Running loss: 0.00448\n",
            "Epoch: 53 | Iteration: 153 | Classification loss: 0.00001 | Regression loss: 0.00295 | Running loss: 0.00448\n",
            "Epoch: 53 | Iteration: 154 | Classification loss: 0.00000 | Regression loss: 0.00137 | Running loss: 0.00447\n",
            "Epoch: 53 | Iteration: 155 | Classification loss: 0.00004 | Regression loss: 0.00231 | Running loss: 0.00447\n",
            "Epoch: 53 | Iteration: 156 | Classification loss: 0.00001 | Regression loss: 0.00298 | Running loss: 0.00447\n",
            "Epoch: 53 | Iteration: 157 | Classification loss: 0.00004 | Regression loss: 0.00191 | Running loss: 0.00446\n",
            "Epoch: 53 | Iteration: 158 | Classification loss: 0.00006 | Regression loss: 0.00372 | Running loss: 0.00447\n",
            "Epoch: 53 | Iteration: 159 | Classification loss: 0.00001 | Regression loss: 0.00187 | Running loss: 0.00445\n",
            "Epoch: 53 | Iteration: 160 | Classification loss: 0.00004 | Regression loss: 0.00302 | Running loss: 0.00446\n",
            "Epoch: 53 | Iteration: 161 | Classification loss: 0.00015 | Regression loss: 0.00920 | Running loss: 0.00443\n",
            "Epoch: 53 | Iteration: 162 | Classification loss: 0.00007 | Regression loss: 0.00416 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 163 | Classification loss: 0.00001 | Regression loss: 0.00198 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 164 | Classification loss: 0.00005 | Regression loss: 0.00225 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 165 | Classification loss: 0.00007 | Regression loss: 0.00565 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 166 | Classification loss: 0.00002 | Regression loss: 0.00544 | Running loss: 0.00441\n",
            "Epoch: 53 | Iteration: 167 | Classification loss: 0.00002 | Regression loss: 0.00208 | Running loss: 0.00440\n",
            "Epoch: 53 | Iteration: 168 | Classification loss: 0.00004 | Regression loss: 0.00632 | Running loss: 0.00440\n",
            "Epoch: 53 | Iteration: 169 | Classification loss: 0.00002 | Regression loss: 0.00176 | Running loss: 0.00440\n",
            "Epoch: 53 | Iteration: 170 | Classification loss: 0.00004 | Regression loss: 0.00218 | Running loss: 0.00440\n",
            "Epoch: 53 | Iteration: 171 | Classification loss: 0.00001 | Regression loss: 0.00172 | Running loss: 0.00440\n",
            "Epoch: 53 | Iteration: 172 | Classification loss: 0.00007 | Regression loss: 0.02016 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 173 | Classification loss: 0.00002 | Regression loss: 0.00151 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 174 | Classification loss: 0.00027 | Regression loss: 0.01198 | Running loss: 0.00445\n",
            "Epoch: 53 | Iteration: 175 | Classification loss: 0.00001 | Regression loss: 0.00173 | Running loss: 0.00445\n",
            "Epoch: 53 | Iteration: 176 | Classification loss: 0.00016 | Regression loss: 0.00304 | Running loss: 0.00445\n",
            "Epoch: 53 | Iteration: 177 | Classification loss: 0.00001 | Regression loss: 0.00170 | Running loss: 0.00445\n",
            "Epoch: 53 | Iteration: 178 | Classification loss: 0.00006 | Regression loss: 0.00332 | Running loss: 0.00444\n",
            "Epoch: 53 | Iteration: 179 | Classification loss: 0.00005 | Regression loss: 0.03660 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 180 | Classification loss: 0.00008 | Regression loss: 0.00529 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 181 | Classification loss: 0.00005 | Regression loss: 0.00508 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 182 | Classification loss: 0.00004 | Regression loss: 0.00281 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 183 | Classification loss: 0.00012 | Regression loss: 0.00404 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 184 | Classification loss: 0.00001 | Regression loss: 0.00258 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 185 | Classification loss: 0.00002 | Regression loss: 0.00219 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 186 | Classification loss: 0.00003 | Regression loss: 0.00183 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 187 | Classification loss: 0.00003 | Regression loss: 0.00858 | Running loss: 0.00452\n",
            "Epoch: 53 | Iteration: 188 | Classification loss: 0.00001 | Regression loss: 0.00176 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 189 | Classification loss: 0.00033 | Regression loss: 0.01316 | Running loss: 0.00452\n",
            "Epoch: 53 | Iteration: 190 | Classification loss: 0.00001 | Regression loss: 0.00276 | Running loss: 0.00452\n",
            "Epoch: 53 | Iteration: 191 | Classification loss: 0.00004 | Regression loss: 0.00244 | Running loss: 0.00452\n",
            "Epoch: 53 | Iteration: 192 | Classification loss: 0.00016 | Regression loss: 0.00263 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 193 | Classification loss: 0.00005 | Regression loss: 0.00198 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 194 | Classification loss: 0.00004 | Regression loss: 0.00222 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 195 | Classification loss: 0.00004 | Regression loss: 0.00222 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 196 | Classification loss: 0.00001 | Regression loss: 0.00228 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 197 | Classification loss: 0.00001 | Regression loss: 0.00246 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 198 | Classification loss: 0.00001 | Regression loss: 0.00144 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 199 | Classification loss: 0.00002 | Regression loss: 0.00299 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 200 | Classification loss: 0.00014 | Regression loss: 0.00893 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 201 | Classification loss: 0.00005 | Regression loss: 0.00144 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 202 | Classification loss: 0.00005 | Regression loss: 0.00344 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 203 | Classification loss: 0.00002 | Regression loss: 0.00142 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 204 | Classification loss: 0.00005 | Regression loss: 0.00410 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 205 | Classification loss: 0.00002 | Regression loss: 0.00271 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 206 | Classification loss: 0.00002 | Regression loss: 0.03664 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 207 | Classification loss: 0.00004 | Regression loss: 0.00970 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 208 | Classification loss: 0.00009 | Regression loss: 0.00361 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 209 | Classification loss: 0.00002 | Regression loss: 0.00169 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 210 | Classification loss: 0.00001 | Regression loss: 0.00243 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 211 | Classification loss: 0.00004 | Regression loss: 0.00135 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 212 | Classification loss: 0.00001 | Regression loss: 0.00401 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 213 | Classification loss: 0.00004 | Regression loss: 0.00743 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 214 | Classification loss: 0.00004 | Regression loss: 0.00481 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 215 | Classification loss: 0.00001 | Regression loss: 0.00307 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 216 | Classification loss: 0.00001 | Regression loss: 0.00146 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 217 | Classification loss: 0.00002 | Regression loss: 0.00232 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 218 | Classification loss: 0.00024 | Regression loss: 0.01226 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 219 | Classification loss: 0.00003 | Regression loss: 0.00509 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 220 | Classification loss: 0.00004 | Regression loss: 0.00600 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 221 | Classification loss: 0.00015 | Regression loss: 0.00973 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 222 | Classification loss: 0.00004 | Regression loss: 0.00198 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 223 | Classification loss: 0.00000 | Regression loss: 0.00255 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 224 | Classification loss: 0.00037 | Regression loss: 0.00296 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 225 | Classification loss: 0.00001 | Regression loss: 0.00563 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 226 | Classification loss: 0.00009 | Regression loss: 0.00995 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 227 | Classification loss: 0.00010 | Regression loss: 0.00368 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 228 | Classification loss: 0.00005 | Regression loss: 0.00801 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 229 | Classification loss: 0.00004 | Regression loss: 0.00291 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 230 | Classification loss: 0.00005 | Regression loss: 0.04729 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 231 | Classification loss: 0.00006 | Regression loss: 0.00368 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 232 | Classification loss: 0.00002 | Regression loss: 0.00222 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 233 | Classification loss: 0.00014 | Regression loss: 0.01319 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 234 | Classification loss: 0.00006 | Regression loss: 0.00330 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 235 | Classification loss: 0.00009 | Regression loss: 0.00111 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 236 | Classification loss: 0.00001 | Regression loss: 0.00328 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 237 | Classification loss: 0.00001 | Regression loss: 0.00219 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 238 | Classification loss: 0.00003 | Regression loss: 0.00198 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 239 | Classification loss: 0.00002 | Regression loss: 0.00161 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 240 | Classification loss: 0.00012 | Regression loss: 0.00192 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 241 | Classification loss: 0.00000 | Regression loss: 0.00191 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 242 | Classification loss: 0.00001 | Regression loss: 0.00250 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 243 | Classification loss: 0.00009 | Regression loss: 0.00218 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 244 | Classification loss: 0.00001 | Regression loss: 0.00431 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 245 | Classification loss: 0.00002 | Regression loss: 0.00109 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 246 | Classification loss: 0.00001 | Regression loss: 0.00201 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 247 | Classification loss: 0.00004 | Regression loss: 0.00716 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 248 | Classification loss: 0.00003 | Regression loss: 0.00241 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 249 | Classification loss: 0.00002 | Regression loss: 0.00196 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 250 | Classification loss: 0.00003 | Regression loss: 0.00203 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 251 | Classification loss: 0.00001 | Regression loss: 0.00318 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 252 | Classification loss: 0.00003 | Regression loss: 0.00174 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 253 | Classification loss: 0.00003 | Regression loss: 0.00835 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 254 | Classification loss: 0.00001 | Regression loss: 0.00333 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 255 | Classification loss: 0.00011 | Regression loss: 0.00948 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 256 | Classification loss: 0.00018 | Regression loss: 0.00338 | Running loss: 0.00476\n",
            "Epoch: 53 | Iteration: 257 | Classification loss: 0.00005 | Regression loss: 0.00625 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 258 | Classification loss: 0.00004 | Regression loss: 0.00291 | Running loss: 0.00477\n",
            "Epoch: 53 | Iteration: 259 | Classification loss: 0.00000 | Regression loss: 0.00106 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 260 | Classification loss: 0.00000 | Regression loss: 0.00141 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 261 | Classification loss: 0.00008 | Regression loss: 0.00220 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 262 | Classification loss: 0.00005 | Regression loss: 0.00127 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 263 | Classification loss: 0.00003 | Regression loss: 0.00242 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 264 | Classification loss: 0.00005 | Regression loss: 0.00531 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 265 | Classification loss: 0.00002 | Regression loss: 0.00601 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 266 | Classification loss: 0.00001 | Regression loss: 0.00133 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 267 | Classification loss: 0.00010 | Regression loss: 0.00216 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 268 | Classification loss: 0.00000 | Regression loss: 0.00306 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 269 | Classification loss: 0.00000 | Regression loss: 0.00158 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 270 | Classification loss: 0.00009 | Regression loss: 0.00251 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 271 | Classification loss: 0.00009 | Regression loss: 0.00240 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 272 | Classification loss: 0.00015 | Regression loss: 0.00958 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 273 | Classification loss: 0.00001 | Regression loss: 0.00207 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 274 | Classification loss: 0.00002 | Regression loss: 0.00316 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 275 | Classification loss: 0.00004 | Regression loss: 0.00269 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 276 | Classification loss: 0.00006 | Regression loss: 0.00239 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 277 | Classification loss: 0.00002 | Regression loss: 0.00189 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 278 | Classification loss: 0.00004 | Regression loss: 0.00214 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 279 | Classification loss: 0.00001 | Regression loss: 0.00141 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 280 | Classification loss: 0.00013 | Regression loss: 0.00494 | Running loss: 0.00457\n",
            "Epoch: 53 | Iteration: 281 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00456\n",
            "Epoch: 53 | Iteration: 282 | Classification loss: 0.00005 | Regression loss: 0.00352 | Running loss: 0.00451\n",
            "Epoch: 53 | Iteration: 283 | Classification loss: 0.00013 | Regression loss: 0.04141 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 284 | Classification loss: 0.00017 | Regression loss: 0.00429 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 285 | Classification loss: 0.00011 | Regression loss: 0.00338 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 286 | Classification loss: 0.00004 | Regression loss: 0.00393 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 287 | Classification loss: 0.00002 | Regression loss: 0.00267 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 288 | Classification loss: 0.00000 | Regression loss: 0.00245 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 289 | Classification loss: 0.00026 | Regression loss: 0.02216 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 290 | Classification loss: 0.00018 | Regression loss: 0.00797 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 291 | Classification loss: 0.00000 | Regression loss: 0.00377 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 292 | Classification loss: 0.00007 | Regression loss: 0.00426 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 293 | Classification loss: 0.00016 | Regression loss: 0.00832 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 294 | Classification loss: 0.00006 | Regression loss: 0.00150 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 295 | Classification loss: 0.00002 | Regression loss: 0.00244 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 296 | Classification loss: 0.00001 | Regression loss: 0.00095 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 297 | Classification loss: 0.00008 | Regression loss: 0.00749 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 298 | Classification loss: 0.00011 | Regression loss: 0.01287 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 299 | Classification loss: 0.00006 | Regression loss: 0.00187 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 300 | Classification loss: 0.00002 | Regression loss: 0.00288 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 301 | Classification loss: 0.00003 | Regression loss: 0.00283 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 302 | Classification loss: 0.00009 | Regression loss: 0.00453 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 303 | Classification loss: 0.00001 | Regression loss: 0.00272 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 304 | Classification loss: 0.00002 | Regression loss: 0.00222 | Running loss: 0.00466\n",
            "Epoch: 53 | Iteration: 305 | Classification loss: 0.00003 | Regression loss: 0.00185 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 306 | Classification loss: 0.00003 | Regression loss: 0.00188 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 307 | Classification loss: 0.00006 | Regression loss: 0.00395 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 308 | Classification loss: 0.00003 | Regression loss: 0.00272 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 309 | Classification loss: 0.00001 | Regression loss: 0.00268 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 310 | Classification loss: 0.00002 | Regression loss: 0.00232 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 311 | Classification loss: 0.00003 | Regression loss: 0.00438 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 312 | Classification loss: 0.00022 | Regression loss: 0.00992 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 313 | Classification loss: 0.00002 | Regression loss: 0.00239 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 314 | Classification loss: 0.00011 | Regression loss: 0.00438 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 315 | Classification loss: 0.00003 | Regression loss: 0.00423 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 316 | Classification loss: 0.00004 | Regression loss: 0.00191 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 317 | Classification loss: 0.00007 | Regression loss: 0.00262 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 318 | Classification loss: 0.00010 | Regression loss: 0.00716 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 319 | Classification loss: 0.00004 | Regression loss: 0.00282 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 320 | Classification loss: 0.00012 | Regression loss: 0.00363 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 321 | Classification loss: 0.00009 | Regression loss: 0.01271 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 322 | Classification loss: 0.00000 | Regression loss: 0.00134 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 323 | Classification loss: 0.00008 | Regression loss: 0.00287 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 324 | Classification loss: 0.00001 | Regression loss: 0.00158 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 325 | Classification loss: 0.00001 | Regression loss: 0.00243 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 326 | Classification loss: 0.00002 | Regression loss: 0.00201 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 327 | Classification loss: 0.00014 | Regression loss: 0.00303 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 328 | Classification loss: 0.00008 | Regression loss: 0.00515 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 329 | Classification loss: 0.00004 | Regression loss: 0.00535 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 330 | Classification loss: 0.00001 | Regression loss: 0.00176 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 331 | Classification loss: 0.00008 | Regression loss: 0.00510 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 332 | Classification loss: 0.00000 | Regression loss: 0.00120 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 333 | Classification loss: 0.00012 | Regression loss: 0.00399 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 334 | Classification loss: 0.00006 | Regression loss: 0.00512 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 335 | Classification loss: 0.00060 | Regression loss: 0.01898 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 336 | Classification loss: 0.00005 | Regression loss: 0.00287 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 337 | Classification loss: 0.00006 | Regression loss: 0.00452 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 338 | Classification loss: 0.00000 | Regression loss: 0.00141 | Running loss: 0.00462\n",
            "Epoch: 53 | Iteration: 339 | Classification loss: 0.00002 | Regression loss: 0.00244 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 340 | Classification loss: 0.00005 | Regression loss: 0.00333 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 341 | Classification loss: 0.00004 | Regression loss: 0.01660 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 342 | Classification loss: 0.00016 | Regression loss: 0.00882 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 343 | Classification loss: 0.00015 | Regression loss: 0.00383 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 344 | Classification loss: 0.00001 | Regression loss: 0.00275 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 345 | Classification loss: 0.00002 | Regression loss: 0.00333 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 346 | Classification loss: 0.00000 | Regression loss: 0.00156 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 347 | Classification loss: 0.00004 | Regression loss: 0.00277 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 348 | Classification loss: 0.00002 | Regression loss: 0.00236 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 349 | Classification loss: 0.00015 | Regression loss: 0.00379 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 350 | Classification loss: 0.00001 | Regression loss: 0.00345 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 351 | Classification loss: 0.00005 | Regression loss: 0.00385 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 352 | Classification loss: 0.00004 | Regression loss: 0.00302 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 353 | Classification loss: 0.00003 | Regression loss: 0.00168 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 354 | Classification loss: 0.00039 | Regression loss: 0.02034 | Running loss: 0.00463\n",
            "Epoch: 53 | Iteration: 355 | Classification loss: 0.00002 | Regression loss: 0.00285 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 356 | Classification loss: 0.00002 | Regression loss: 0.00130 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 357 | Classification loss: 0.00004 | Regression loss: 0.00339 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 358 | Classification loss: 0.00000 | Regression loss: 0.00118 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 359 | Classification loss: 0.00004 | Regression loss: 0.00209 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 360 | Classification loss: 0.00003 | Regression loss: 0.00481 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 361 | Classification loss: 0.00008 | Regression loss: 0.00153 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 362 | Classification loss: 0.00003 | Regression loss: 0.00184 | Running loss: 0.00461\n",
            "Epoch: 53 | Iteration: 363 | Classification loss: 0.00000 | Regression loss: 0.00242 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 364 | Classification loss: 0.00011 | Regression loss: 0.00351 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 365 | Classification loss: 0.00001 | Regression loss: 0.00194 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 366 | Classification loss: 0.00001 | Regression loss: 0.00224 | Running loss: 0.00450\n",
            "Epoch: 53 | Iteration: 367 | Classification loss: 0.00069 | Regression loss: 0.03042 | Running loss: 0.00455\n",
            "Epoch: 53 | Iteration: 368 | Classification loss: 0.00000 | Regression loss: 0.00185 | Running loss: 0.00455\n",
            "Epoch: 53 | Iteration: 369 | Classification loss: 0.00001 | Regression loss: 0.01800 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 370 | Classification loss: 0.00018 | Regression loss: 0.01050 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 371 | Classification loss: 0.00006 | Regression loss: 0.00582 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 372 | Classification loss: 0.00002 | Regression loss: 0.00168 | Running loss: 0.00460\n",
            "Epoch: 53 | Iteration: 373 | Classification loss: 0.00002 | Regression loss: 0.00183 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 374 | Classification loss: 0.00001 | Regression loss: 0.00134 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 375 | Classification loss: 0.00001 | Regression loss: 0.00176 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 376 | Classification loss: 0.00005 | Regression loss: 0.00357 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 377 | Classification loss: 0.00002 | Regression loss: 0.00322 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 378 | Classification loss: 0.00001 | Regression loss: 0.00321 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 379 | Classification loss: 0.00004 | Regression loss: 0.00189 | Running loss: 0.00459\n",
            "Epoch: 53 | Iteration: 380 | Classification loss: 0.00003 | Regression loss: 0.00157 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 381 | Classification loss: 0.00005 | Regression loss: 0.00409 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 382 | Classification loss: 0.00002 | Regression loss: 0.00294 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 383 | Classification loss: 0.00003 | Regression loss: 0.00289 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 384 | Classification loss: 0.00007 | Regression loss: 0.00279 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 385 | Classification loss: 0.00005 | Regression loss: 0.00362 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 386 | Classification loss: 0.00002 | Regression loss: 0.00201 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 387 | Classification loss: 0.00001 | Regression loss: 0.00234 | Running loss: 0.00458\n",
            "Epoch: 53 | Iteration: 388 | Classification loss: 0.00015 | Regression loss: 0.06275 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 389 | Classification loss: 0.00000 | Regression loss: 0.00183 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 390 | Classification loss: 0.00005 | Regression loss: 0.00304 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 391 | Classification loss: 0.00005 | Regression loss: 0.00533 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 392 | Classification loss: 0.00001 | Regression loss: 0.00384 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 393 | Classification loss: 0.00049 | Regression loss: 0.00945 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 394 | Classification loss: 0.00013 | Regression loss: 0.00393 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 395 | Classification loss: 0.00006 | Regression loss: 0.00219 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 396 | Classification loss: 0.00001 | Regression loss: 0.00145 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 397 | Classification loss: 0.00101 | Regression loss: 0.01119 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 398 | Classification loss: 0.00006 | Regression loss: 0.00559 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 399 | Classification loss: 0.00008 | Regression loss: 0.00555 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 400 | Classification loss: 0.00002 | Regression loss: 0.00267 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 401 | Classification loss: 0.00003 | Regression loss: 0.00355 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 402 | Classification loss: 0.00001 | Regression loss: 0.00149 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 403 | Classification loss: 0.00009 | Regression loss: 0.00368 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 404 | Classification loss: 0.00004 | Regression loss: 0.00935 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 405 | Classification loss: 0.00008 | Regression loss: 0.00211 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 406 | Classification loss: 0.00002 | Regression loss: 0.00270 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 407 | Classification loss: 0.00001 | Regression loss: 0.00235 | Running loss: 0.00468\n",
            "Epoch: 53 | Iteration: 408 | Classification loss: 0.00008 | Regression loss: 0.00713 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 409 | Classification loss: 0.00008 | Regression loss: 0.00470 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 410 | Classification loss: 0.00010 | Regression loss: 0.00614 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 411 | Classification loss: 0.00004 | Regression loss: 0.00207 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 412 | Classification loss: 0.00031 | Regression loss: 0.00462 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 413 | Classification loss: 0.00005 | Regression loss: 0.00378 | Running loss: 0.00467\n",
            "Epoch: 53 | Iteration: 414 | Classification loss: 0.00009 | Regression loss: 0.00395 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 415 | Classification loss: 0.00002 | Regression loss: 0.00224 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 416 | Classification loss: 0.00000 | Regression loss: 0.00195 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 417 | Classification loss: 0.00001 | Regression loss: 0.00378 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 418 | Classification loss: 0.00016 | Regression loss: 0.00582 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 419 | Classification loss: 0.00008 | Regression loss: 0.00275 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 420 | Classification loss: 0.00001 | Regression loss: 0.00223 | Running loss: 0.00464\n",
            "Epoch: 53 | Iteration: 421 | Classification loss: 0.00001 | Regression loss: 0.00419 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 422 | Classification loss: 0.00001 | Regression loss: 0.00251 | Running loss: 0.00465\n",
            "Epoch: 53 | Iteration: 423 | Classification loss: 0.00116 | Regression loss: 0.04481 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 424 | Classification loss: 0.00013 | Regression loss: 0.00200 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 425 | Classification loss: 0.00014 | Regression loss: 0.00536 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 426 | Classification loss: 0.00001 | Regression loss: 0.00238 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 427 | Classification loss: 0.00000 | Regression loss: 0.00126 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 428 | Classification loss: 0.00005 | Regression loss: 0.00251 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 429 | Classification loss: 0.00007 | Regression loss: 0.00501 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 430 | Classification loss: 0.00003 | Regression loss: 0.00413 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 431 | Classification loss: 0.00001 | Regression loss: 0.00163 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 432 | Classification loss: 0.00006 | Regression loss: 0.00164 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 433 | Classification loss: 0.00003 | Regression loss: 0.01389 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 434 | Classification loss: 0.00007 | Regression loss: 0.00146 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 435 | Classification loss: 0.00001 | Regression loss: 0.00179 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 436 | Classification loss: 0.00001 | Regression loss: 0.00258 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 437 | Classification loss: 0.00008 | Regression loss: 0.00682 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 438 | Classification loss: 0.00001 | Regression loss: 0.00334 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 439 | Classification loss: 0.00002 | Regression loss: 0.00293 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 440 | Classification loss: 0.00001 | Regression loss: 0.02120 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 441 | Classification loss: 0.00012 | Regression loss: 0.00378 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 442 | Classification loss: 0.00007 | Regression loss: 0.00485 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 443 | Classification loss: 0.00002 | Regression loss: 0.00196 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 444 | Classification loss: 0.00001 | Regression loss: 0.00201 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 445 | Classification loss: 0.00005 | Regression loss: 0.00577 | Running loss: 0.00475\n",
            "Epoch: 53 | Iteration: 446 | Classification loss: 0.00000 | Regression loss: 0.00183 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 447 | Classification loss: 0.00014 | Regression loss: 0.00285 | Running loss: 0.00473\n",
            "Epoch: 53 | Iteration: 448 | Classification loss: 0.00001 | Regression loss: 0.00145 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 449 | Classification loss: 0.00051 | Regression loss: 0.01245 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 450 | Classification loss: 0.00002 | Regression loss: 0.00134 | Running loss: 0.00474\n",
            "Epoch: 53 | Iteration: 451 | Classification loss: 0.00012 | Regression loss: 0.00365 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 452 | Classification loss: 0.00002 | Regression loss: 0.00281 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 453 | Classification loss: 0.00001 | Regression loss: 0.00222 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 454 | Classification loss: 0.00001 | Regression loss: 0.00242 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 455 | Classification loss: 0.00001 | Regression loss: 0.00228 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 456 | Classification loss: 0.00002 | Regression loss: 0.00196 | Running loss: 0.00472\n",
            "Epoch: 53 | Iteration: 457 | Classification loss: 0.00004 | Regression loss: 0.00120 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 458 | Classification loss: 0.00007 | Regression loss: 0.00213 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 459 | Classification loss: 0.00000 | Regression loss: 0.00265 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 460 | Classification loss: 0.00011 | Regression loss: 0.00680 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 461 | Classification loss: 0.00003 | Regression loss: 0.00404 | Running loss: 0.00471\n",
            "Epoch: 53 | Iteration: 462 | Classification loss: 0.00001 | Regression loss: 0.00184 | Running loss: 0.00469\n",
            "Epoch: 53 | Iteration: 463 | Classification loss: 0.00000 | Regression loss: 0.00338 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 464 | Classification loss: 0.00014 | Regression loss: 0.00554 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 465 | Classification loss: 0.00001 | Regression loss: 0.00418 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 466 | Classification loss: 0.00002 | Regression loss: 0.00197 | Running loss: 0.00470\n",
            "Epoch: 53 | Iteration: 467 | Classification loss: 0.00002 | Regression loss: 0.00362 | Running loss: 0.00470\n",
            "Evaluating dataset\n",
            "136/136\n",
            "mAP:\n",
            "monocyte: 0.9918417674481452\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "segmented_neutrophil: 0.6651738698642333\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "abnormal_rbc: 0.35916417058907435\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "lymphocyte: 1.0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "myelocyte: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "neutrophil: 0.45509186304048443\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "basophil: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "band_neutrophil: 0.5400693773238292\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "erythroblast: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "eosinophil: 0\n",
            "Precision:  0.42424242424242425\n",
            "Recall:  0.9032258064516129\n",
            "Epoch: 54 | Iteration: 0 | Classification loss: 0.00001 | Regression loss: 0.00203 | Running loss: 0.00470\n",
            "Epoch: 54 | Iteration: 1 | Classification loss: 0.00003 | Regression loss: 0.00303 | Running loss: 0.00470\n",
            "Epoch: 54 | Iteration: 2 | Classification loss: 0.00000 | Regression loss: 0.00188 | Running loss: 0.00470\n",
            "Epoch: 54 | Iteration: 3 | Classification loss: 0.00003 | Regression loss: 0.00162 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 4 | Classification loss: 0.00006 | Regression loss: 0.00359 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 5 | Classification loss: 0.00004 | Regression loss: 0.00209 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 6 | Classification loss: 0.00002 | Regression loss: 0.00353 | Running loss: 0.00468\n",
            "Epoch: 54 | Iteration: 7 | Classification loss: 0.00011 | Regression loss: 0.00311 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 8 | Classification loss: 0.00003 | Regression loss: 0.00263 | Running loss: 0.00468\n",
            "Epoch: 54 | Iteration: 9 | Classification loss: 0.00020 | Regression loss: 0.01939 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 10 | Classification loss: 0.00003 | Regression loss: 0.00232 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 11 | Classification loss: 0.00010 | Regression loss: 0.00317 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 12 | Classification loss: 0.00003 | Regression loss: 0.00218 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 13 | Classification loss: 0.00002 | Regression loss: 0.00292 | Running loss: 0.00471\n",
            "Epoch: 54 | Iteration: 14 | Classification loss: 0.00001 | Regression loss: 0.00220 | Running loss: 0.00463\n",
            "Epoch: 54 | Iteration: 15 | Classification loss: 0.00051 | Regression loss: 0.02022 | Running loss: 0.00467\n",
            "Epoch: 54 | Iteration: 16 | Classification loss: 0.00001 | Regression loss: 0.00151 | Running loss: 0.00463\n",
            "Epoch: 54 | Iteration: 17 | Classification loss: 0.00005 | Regression loss: 0.04430 | Running loss: 0.00471\n",
            "Epoch: 54 | Iteration: 18 | Classification loss: 0.00001 | Regression loss: 0.00258 | Running loss: 0.00471\n",
            "Epoch: 54 | Iteration: 19 | Classification loss: 0.00002 | Regression loss: 0.00140 | Running loss: 0.00470\n",
            "Epoch: 54 | Iteration: 20 | Classification loss: 0.00009 | Regression loss: 0.00925 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 21 | Classification loss: 0.00006 | Regression loss: 0.00475 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 22 | Classification loss: 0.00001 | Regression loss: 0.00518 | Running loss: 0.00473\n",
            "Epoch: 54 | Iteration: 23 | Classification loss: 0.00002 | Regression loss: 0.00251 | Running loss: 0.00473\n",
            "Epoch: 54 | Iteration: 24 | Classification loss: 0.00003 | Regression loss: 0.00168 | Running loss: 0.00472\n",
            "Epoch: 54 | Iteration: 25 | Classification loss: 0.00004 | Regression loss: 0.00300 | Running loss: 0.00473\n",
            "Epoch: 54 | Iteration: 26 | Classification loss: 0.00004 | Regression loss: 0.00256 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 27 | Classification loss: 0.00001 | Regression loss: 0.00157 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 28 | Classification loss: 0.00006 | Regression loss: 0.00482 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 29 | Classification loss: 0.00018 | Regression loss: 0.00631 | Running loss: 0.00461\n",
            "Epoch: 54 | Iteration: 30 | Classification loss: 0.00003 | Regression loss: 0.00171 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 31 | Classification loss: 0.00006 | Regression loss: 0.00146 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 32 | Classification loss: 0.00001 | Regression loss: 0.00147 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 33 | Classification loss: 0.00003 | Regression loss: 0.00173 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 34 | Classification loss: 0.00003 | Regression loss: 0.00457 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 35 | Classification loss: 0.00018 | Regression loss: 0.01949 | Running loss: 0.00463\n",
            "Epoch: 54 | Iteration: 36 | Classification loss: 0.00001 | Regression loss: 0.00213 | Running loss: 0.00462\n",
            "Epoch: 54 | Iteration: 37 | Classification loss: 0.00000 | Regression loss: 0.00162 | Running loss: 0.00462\n",
            "Epoch: 54 | Iteration: 38 | Classification loss: 0.00010 | Regression loss: 0.00812 | Running loss: 0.00463\n",
            "Epoch: 54 | Iteration: 39 | Classification loss: 0.00003 | Regression loss: 0.00435 | Running loss: 0.00463\n",
            "Epoch: 54 | Iteration: 40 | Classification loss: 0.00000 | Regression loss: 0.00206 | Running loss: 0.00463\n",
            "Epoch: 54 | Iteration: 41 | Classification loss: 0.00000 | Regression loss: 0.00227 | Running loss: 0.00461\n",
            "Epoch: 54 | Iteration: 42 | Classification loss: 0.00001 | Regression loss: 0.00232 | Running loss: 0.00461\n",
            "Epoch: 54 | Iteration: 43 | Classification loss: 0.00001 | Regression loss: 0.00240 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 44 | Classification loss: 0.00001 | Regression loss: 0.00167 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 45 | Classification loss: 0.00001 | Regression loss: 0.00162 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 46 | Classification loss: 0.00005 | Regression loss: 0.00305 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 47 | Classification loss: 0.00007 | Regression loss: 0.00212 | Running loss: 0.00455\n",
            "Epoch: 54 | Iteration: 48 | Classification loss: 0.00002 | Regression loss: 0.00414 | Running loss: 0.00456\n",
            "Epoch: 54 | Iteration: 49 | Classification loss: 0.00004 | Regression loss: 0.00470 | Running loss: 0.00456\n",
            "Epoch: 54 | Iteration: 50 | Classification loss: 0.00004 | Regression loss: 0.00156 | Running loss: 0.00455\n",
            "Epoch: 54 | Iteration: 51 | Classification loss: 0.00002 | Regression loss: 0.00191 | Running loss: 0.00455\n",
            "Epoch: 54 | Iteration: 52 | Classification loss: 0.00005 | Regression loss: 0.00176 | Running loss: 0.00455\n",
            "Epoch: 54 | Iteration: 53 | Classification loss: 0.00004 | Regression loss: 0.00669 | Running loss: 0.00456\n",
            "Epoch: 54 | Iteration: 54 | Classification loss: 0.00001 | Regression loss: 0.00200 | Running loss: 0.00453\n",
            "Epoch: 54 | Iteration: 55 | Classification loss: 0.00010 | Regression loss: 0.00760 | Running loss: 0.00454\n",
            "Epoch: 54 | Iteration: 56 | Classification loss: 0.00010 | Regression loss: 0.00820 | Running loss: 0.00454\n",
            "Epoch: 54 | Iteration: 57 | Classification loss: 0.00077 | Regression loss: 0.01832 | Running loss: 0.00457\n",
            "Epoch: 54 | Iteration: 58 | Classification loss: 0.00004 | Regression loss: 0.00600 | Running loss: 0.00458\n",
            "Epoch: 54 | Iteration: 59 | Classification loss: 0.00002 | Regression loss: 0.00373 | Running loss: 0.00458\n",
            "Epoch: 54 | Iteration: 60 | Classification loss: 0.00009 | Regression loss: 0.00541 | Running loss: 0.00457\n",
            "Epoch: 54 | Iteration: 61 | Classification loss: 0.00025 | Regression loss: 0.00296 | Running loss: 0.00456\n",
            "Epoch: 54 | Iteration: 62 | Classification loss: 0.00000 | Regression loss: 0.01688 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 63 | Classification loss: 0.00001 | Regression loss: 0.00355 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 64 | Classification loss: 0.00004 | Regression loss: 0.00192 | Running loss: 0.00458\n",
            "Epoch: 54 | Iteration: 65 | Classification loss: 0.00001 | Regression loss: 0.00289 | Running loss: 0.00458\n",
            "Epoch: 54 | Iteration: 66 | Classification loss: 0.00009 | Regression loss: 0.00288 | Running loss: 0.00458\n",
            "Epoch: 54 | Iteration: 67 | Classification loss: 0.00003 | Regression loss: 0.00512 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 68 | Classification loss: 0.00002 | Regression loss: 0.00202 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 69 | Classification loss: 0.00005 | Regression loss: 0.00247 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 70 | Classification loss: 0.00014 | Regression loss: 0.00266 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 71 | Classification loss: 0.00004 | Regression loss: 0.00118 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 72 | Classification loss: 0.00011 | Regression loss: 0.00247 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 73 | Classification loss: 0.00002 | Regression loss: 0.03516 | Running loss: 0.00464\n",
            "Epoch: 54 | Iteration: 74 | Classification loss: 0.00005 | Regression loss: 0.00512 | Running loss: 0.00465\n",
            "Epoch: 54 | Iteration: 75 | Classification loss: 0.00018 | Regression loss: 0.00880 | Running loss: 0.00465\n",
            "Epoch: 54 | Iteration: 76 | Classification loss: 0.00003 | Regression loss: 0.00348 | Running loss: 0.00466\n",
            "Epoch: 54 | Iteration: 77 | Classification loss: 0.00004 | Regression loss: 0.00294 | Running loss: 0.00466\n",
            "Epoch: 54 | Iteration: 78 | Classification loss: 0.00019 | Regression loss: 0.00995 | Running loss: 0.00467\n",
            "Epoch: 54 | Iteration: 79 | Classification loss: 0.00003 | Regression loss: 0.00174 | Running loss: 0.00467\n",
            "Epoch: 54 | Iteration: 80 | Classification loss: 0.00005 | Regression loss: 0.01338 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 81 | Classification loss: 0.00000 | Regression loss: 0.00234 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 82 | Classification loss: 0.00002 | Regression loss: 0.00333 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 83 | Classification loss: 0.00005 | Regression loss: 0.00375 | Running loss: 0.00470\n",
            "Epoch: 54 | Iteration: 84 | Classification loss: 0.00001 | Regression loss: 0.00240 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 85 | Classification loss: 0.00002 | Regression loss: 0.00241 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 86 | Classification loss: 0.00009 | Regression loss: 0.00435 | Running loss: 0.00470\n",
            "Epoch: 54 | Iteration: 87 | Classification loss: 0.00003 | Regression loss: 0.00252 | Running loss: 0.00469\n",
            "Epoch: 54 | Iteration: 88 | Classification loss: 0.00004 | Regression loss: 0.00168 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 89 | Classification loss: 0.00002 | Regression loss: 0.00276 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 90 | Classification loss: 0.00000 | Regression loss: 0.00189 | Running loss: 0.00459\n",
            "Epoch: 54 | Iteration: 91 | Classification loss: 0.00001 | Regression loss: 0.00427 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 92 | Classification loss: 0.00001 | Regression loss: 0.00146 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 93 | Classification loss: 0.00000 | Regression loss: 0.00414 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 94 | Classification loss: 0.00025 | Regression loss: 0.00242 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 95 | Classification loss: 0.00003 | Regression loss: 0.00175 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 96 | Classification loss: 0.00002 | Regression loss: 0.00165 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 97 | Classification loss: 0.00002 | Regression loss: 0.00223 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 98 | Classification loss: 0.00002 | Regression loss: 0.00187 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 99 | Classification loss: 0.00003 | Regression loss: 0.00631 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 100 | Classification loss: 0.00004 | Regression loss: 0.00541 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 101 | Classification loss: 0.00003 | Regression loss: 0.00154 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 102 | Classification loss: 0.00009 | Regression loss: 0.00333 | Running loss: 0.00460\n",
            "Epoch: 54 | Iteration: 103 | Classification loss: 0.00005 | Regression loss: 0.00456 | Running loss: 0.00461\n",
            "Epoch: 54 | Iteration: 104 | Classification loss: 0.00099 | Regression loss: 0.03292 | Running loss: 0.00467\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "0ded2cb331351ed1c13e44f0b111baa034532819e730db98a9d049a64313c247"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}